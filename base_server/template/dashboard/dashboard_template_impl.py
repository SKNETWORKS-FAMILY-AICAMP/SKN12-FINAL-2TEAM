from datetime import datetime, timezone, timedelta
import traceback

import aiohttp
from typing import Any, List
from template.base.base_template import BaseTemplate
from template.base.template_config import AppConfig
from template.dashboard.common.dashboard_serialize import (
    DashboardMainRequest, DashboardMainResponse,
    DashboardAlertsRequest, DashboardAlertsResponse,
    DashboardPerformanceRequest, DashboardPerformanceResponse,
    SecuritiesLoginRequest, SecuritiesLoginResponse,
    PriceRequest, PriceResponse,
    StockRecommendationRequest, StockRecommendationResponse,
    EconomicCalendarRequest, EconomicCalendarResponse,
    MarketRiskPremiumRequest, MarketRiskPremiumResponse
)
from template.dashboard.common.dashboard_model import AssetSummary, StockHolding, MarketAlert, MarketOverview
from service.service_container import ServiceContainer
from service.core.logger import Logger
from service.llm.AIChat.BasicTools.NewsTool import NewsTool
from service.llm.AIChat.BasicTools.MarketDataTool import MarketDataTool
import os, re, json, asyncio, uuid, time

class DashboardTemplateImpl(BaseTemplate):
    def __init__(self):
        super().__init__()
        self.app_config: AppConfig | None = None

    def init(self, config: AppConfig):
        # í…œí”Œë¦¿ ì´ˆê¸°í™” ì‹œ ì „ì²´ ì•± ì„¤ì • ë³´ê´€
        try:
            self.app_config = config
            Logger.info("DashboardTemplateImpl initialized with AppConfig")
        except Exception as e:
            Logger.warn(f"DashboardTemplateImpl init: failed to set app_config: {e}")

    async def on_dashboard_main_req(self, client_session, request: DashboardMainRequest):
        """ëŒ€ì‹œë³´ë“œ ë©”ì¸ ë°ì´í„° ìš”ì²­ ì²˜ë¦¬"""
        response = DashboardMainResponse()
        response.sequence = request.sequence
        
        Logger.info(f"Dashboard main request: period={request.chart_period}")
        
        try:
            # ì„¸ì…˜ì—ì„œ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì„¸ì…˜ ê²€ì¦ì€ template_serviceì—ì„œ ì´ë¯¸ ì™„ë£Œ)
            account_db_key = getattr(client_session.session, 'account_db_key', 0)
            shard_id = getattr(client_session.session, 'shard_id', 1)
            
            db_service = ServiceContainer.get_database_service()
            
            # 1. ëŒ€ì‹œë³´ë“œ ë©”ì¸ ë°ì´í„° ì¡°íšŒ DB í”„ë¡œì‹œì € í˜¸ì¶œ
            dashboard_result = await db_service.call_shard_procedure(
                shard_id,
                "fp_get_dashboard_main",
                (account_db_key, True, request.chart_period)  # include_chart=True
            )
            
            if not dashboard_result or len(dashboard_result) < 4:
                response.errorCode = 2002
                Logger.info("Dashboard main data not found")
                return response
            
            # 2. DB ê²°ê³¼ ì²˜ë¦¬
            asset_data = dashboard_result[0][0] if dashboard_result[0] else {}
            holdings_data = dashboard_result[1] if len(dashboard_result) > 1 else []
            alerts_data = dashboard_result[2] if len(dashboard_result) > 2 else []
            market_data = dashboard_result[3] if len(dashboard_result) > 3 else []
            chart_data = dashboard_result[4] if len(dashboard_result) > 4 else []
            
            # 3. ìì‚° ìš”ì•½ ì •ë³´ ìƒì„±
            asset_summary = AssetSummary(
                total_assets=float(asset_data.get('total_assets', 0.0)),
                cash_balance=float(asset_data.get('cash_balance', 0.0)),
                stock_value=float(asset_data.get('stock_value', 0.0)),
                total_return=float(asset_data.get('total_return', 0.0)),
                return_rate=float(asset_data.get('return_rate', 0.0)),
                currency=asset_data.get('currency', 'KRW')
            )
            
            # 4. ë³´ìœ  ì¢…ëª© ì •ë³´ ìƒì„±
            holdings = []
            for holding in holdings_data:
                holdings.append(StockHolding(
                    symbol=holding.get('symbol'),
                    name=holding.get('name'),
                    quantity=int(holding.get('quantity', 0)),
                    avg_price=float(holding.get('avg_price', 0.0)),
                    current_price=float(holding.get('current_price', 0.0)),
                    market_value=float(holding.get('market_value', 0.0)),
                    unrealized_pnl=float(holding.get('unrealized_pnl', 0.0)),
                    return_rate=round(float(holding.get('return_rate', 0.0)), 2)
                ))
            
            # 5. ìµœê·¼ ì•Œë¦¼ ì •ë³´ ìƒì„±
            recent_alerts = []
            for alert in alerts_data:
                recent_alerts.append(MarketAlert(
                    alert_id=alert.get('alert_id'),
                    type=alert.get('type'),
                    title=alert.get('title'),
                    message=alert.get('message'),
                    severity=alert.get('severity', 'INFO'),
                    created_at=str(alert.get('created_at')),
                    symbol=alert.get('symbol', '')
                ))
            
            # 6. ì‹œì¥ ê°œìš” ì •ë³´ ìƒì„±
            market_overview = []
            for market in market_data:
                market_overview.append(MarketOverview(
                    symbol=market.get('symbol'),
                    name=market.get('name'),
                    current_price=float(market.get('current_price', 0.0)),
                    change_amount=float(market.get('change_amount', 0.0)),
                    change_rate=float(market.get('change_rate', 0.0)),
                    volume=int(market.get('volume', 0))
                ))
            
            # 7. í¬íŠ¸í´ë¦¬ì˜¤ ì°¨íŠ¸ ë°ì´í„° ì²˜ë¦¬ (ì‹œê°„ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™”)
            portfolio_chart = []
            if chart_data:
                for chart_point in chart_data:
                    portfolio_chart.append({
                        "date": str(chart_point.get('date')),               # ë‚ ì§œ
                        "value": float(chart_point.get('total_value', 0.0)), # í¬íŠ¸í´ë¦¬ì˜¤ ì´ ê°€ì¹˜
                        "return_rate": float(chart_point.get('return_rate', 0.0)) # ìˆ˜ìµë¥ 
                    })
            
            # 8. ìì‚° ë°°ë¶„ ì°¨íŠ¸ ë°ì´í„° ìƒì„± (ì¢…ëª©ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘)
            allocation_chart = []
            total_stock_value = sum(float(h.get('market_value', 0)) for h in holdings_data)
            if total_stock_value > 0:
                for holding in holdings_data[:5]:  # ìƒìœ„ 5ê°œ ì¢…ëª©ë§Œ í‘œì‹œ
                    allocation_chart.append({
                        "symbol": holding.get('symbol'),                    # ì¢…ëª© ì½”ë“œ
                        "name": holding.get('name'),                       # ì¢…ëª©ëª…
                        "value": float(holding.get('market_value', 0.0)),  # ì‹œì¥ ê°€ì¹˜
                        "percentage": round(float(holding.get('market_value', 0.0)) / total_stock_value * 100, 1) # ë¹„ì¤‘
                    })
            
            # 9. Response ë°ì´í„° ì„¤ì •
            response.errorCode = 0
            response.asset_summary = asset_summary
            response.holdings = holdings
            response.portfolio_chart = portfolio_chart    # ì°¨íŠ¸ ë°ì´í„° í™œì„±í™”
            response.allocation_chart = allocation_chart  # ì°¨íŠ¸ ë°ì´í„° í™œì„±í™”  
            response.recent_alerts = recent_alerts
            response.market_overview = market_overview
            
            Logger.info(f"Dashboard main data retrieved for account_db_key={account_db_key}")
            
        except Exception as e:
            response.errorCode = 1000
            Logger.error(f"Dashboard main error: {e}")
        
        return response

    async def on_dashboard_alerts_req(self, client_session, request: DashboardAlertsRequest):
        """ì•Œë¦¼ ëª©ë¡ ìš”ì²­ ì²˜ë¦¬"""
        response = DashboardAlertsResponse()
        response.sequence = request.sequence
        
        Logger.info(f"Dashboard alerts request: page={request.page}, type={request.alert_type}")
        
        try:
            account_db_key = client_session.session.account_db_key
            shard_id = client_session.session.shard_id
            
            db_service = ServiceContainer.get_database_service()
            
            # 1. ì•Œë¦¼ ëª©ë¡ ì¡°íšŒ (ëŒ€ì‹œë³´ë“œ ì•Œë¦¼ í…Œì´ë¸”ì—ì„œ)
            # ì‹¤ì œë¡œëŠ” ë³„ë„ì˜ fp_get_dashboard_alerts í”„ë¡œì‹œì €ê°€ í•„ìš”í•˜ì§€ë§Œ
            # ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ëŒ€ì‹œë³´ë“œ ë©”ì¸ ë°ì´í„°ì—ì„œ ì•Œë¦¼ ì •ë³´ë¥¼ í™œìš©
            
            dashboard_result = await db_service.call_shard_procedure(
                shard_id,
                "fp_get_dashboard_main",
                (account_db_key, False, "1D")  # chart ë°ì´í„°ëŠ” ë¶ˆí•„ìš”
            )
            
            alerts = []
            if dashboard_result and len(dashboard_result) > 2:
                alerts_data = dashboard_result[2]  # ì•Œë¦¼ ë°ì´í„°ëŠ” 3ë²ˆì§¸ ê²°ê³¼ì…‹
                
                for alert_data in alerts_data:
                    # íƒ€ì… í•„í„°ë§ ì ìš©
                    if request.alert_type and request.alert_type != "ALL":
                        if alert_data.get('type') != request.alert_type:
                            continue
                    
                    alerts.append(MarketAlert(
                        alert_id=alert_data.get('alert_id'),
                        type=alert_data.get('type'),
                        title=alert_data.get('title'),
                        message=alert_data.get('message'),
                        severity=alert_data.get('severity', 'INFO'),
                        created_at=str(alert_data.get('created_at')),
                        symbol=alert_data.get('symbol', '')
                    ))
            
            # í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
            start_idx = (request.page - 1) * request.limit
            end_idx = start_idx + request.limit
            paginated_alerts = alerts[start_idx:end_idx]
            
            # ì•ˆì½ìŒ ì•Œë¦¼ ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            unread_count = len([a for a in alerts if a.severity in ['WARNING', 'ERROR']])
            
            response.errorCode = 0
            response.alerts = paginated_alerts
            response.total_count = len(alerts)
            response.unread_count = unread_count
            
        except Exception as e:
            response.errorCode = 1000
            Logger.error(f"Dashboard alerts error: {e}")
        
        return response

    async def on_dashboard_performance_req(self, client_session, request: DashboardPerformanceRequest):
        """ì„±ê³¼ ë¶„ì„ ìš”ì²­ ì²˜ë¦¬"""
        response = DashboardPerformanceResponse()
        response.sequence = request.sequence
        
        Logger.info(f"Dashboard performance request: period={request.period}")
        
        try:
            account_db_key = client_session.session.account_db_key
            shard_id = client_session.session.shard_id
            
            db_service = ServiceContainer.get_database_service()
            
            # 1. ì„±ê³¼ ë¶„ì„ ë°ì´í„° ì¡°íšŒ (í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ í…Œì´ë¸”ì—ì„œ)
            # ì‹¤ì œë¡œëŠ” fp_get_performance_analysis í”„ë¡œì‹œì €ê°€ í•„ìš”í•˜ì§€ë§Œ
            # ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ë°ì´í„°ë¥¼ í™œìš©
            
            # í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ë°ì´í„° ì¡°íšŒ
            performance_result = await db_service.call_shard_procedure(
                shard_id,
                "fp_get_portfolio_performance",
                (account_db_key, request.period)
            )
            
            if not performance_result:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                response.portfolio_return = 0.0
                response.benchmark_return = 0.0
                response.sharpe_ratio = 0.0
                response.max_drawdown = 0.0
                response.volatility = 0.0
                response.performance_chart = []
                response.errorCode = 0
                return response
            
            # 2. ì„±ê³¼ ì§€í‘œ ê³„ì‚°
            perf_data = performance_result[0] if performance_result else {}
            
            portfolio_return = float(perf_data.get('return_rate', 0.0))
            benchmark_return = float(perf_data.get('benchmark_return', 0.0))
            sharpe_ratio = float(perf_data.get('sharpe_ratio', 0.0))
            max_drawdown = float(perf_data.get('max_drawdown', 0.0))
            volatility = float(perf_data.get('volatility', 0.0))
            
            # 3. ì„±ê³¼ ì°¨íŠ¸ ë°ì´í„° ìƒì„±
            performance_chart = []
            if len(performance_result) > 1:
                chart_data = performance_result[1:]
                for chart_point in chart_data:
                    performance_chart.append({
                        "date": str(chart_point.get('date')),
                        "portfolio_value": float(chart_point.get('total_value', 0.0)),
                        "return_rate": float(chart_point.get('return_rate', 0.0)),
                        "benchmark_value": float(chart_point.get('total_value', 0.0)) * (1 + benchmark_return / 100)
                    })
            
            response.portfolio_return = round(portfolio_return, 2)
            response.benchmark_return = round(benchmark_return, 2)
            response.sharpe_ratio = round(sharpe_ratio, 2)
            response.max_drawdown = round(max_drawdown, 2)
            response.volatility = round(volatility, 2)
            response.performance_chart = performance_chart
            response.errorCode = 0
            
        except Exception as e:
            response.errorCode = 1000
            Logger.error(f"Dashboard performance error: {e}")
        
        return response

    async def on_dashboard_oauth_req(self, client_session, request: SecuritiesLoginRequest):
        """OAuth ì¸ì¦ ìš”ì²­ ì²˜ë¦¬"""
        print(f"ğŸ“¥ OAuth body received: {request.model_dump_json()}")

        account_db_key = client_session.session.account_db_key
        db_service = ServiceContainer.get_database_service()
        Logger.debug(f"Dashboard OAuth request: account_db_key={account_db_key}")

        # ê¸°ë³¸ê°’ ì„¤ì •
        sequence = request.sequence

        # API í‚¤ ì¡°íšŒ
        result = await db_service.call_global_procedure(
            "fp_get_api_keys",
            (account_db_key,)
        )
        Logger.debug(f"API keys result: {result}")

        if not result:
            return SecuritiesLoginResponse(
                result="fail",
                message="API í‚¤ ì¡°íšŒ ì‹¤íŒ¨",
                app_key="",
                sequence=sequence,
                errorCode=9007
            )

        api_data = result[0]
        try:
            appkey = api_data.get('korea_investment_app_key', '')
            appsecret = api_data.get('korea_investment_app_secret', '')

            url = "https://openapi.koreainvestment.com:9443/oauth2/tokenP"
            payload = {
                "grant_type": "client_credentials",
                "appkey": appkey,
                "appsecret": appsecret
            }

            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url,
                    json=payload,
                    headers={"Content-Type": "application/json; charset=utf-8"}
                ) as resp:
                    if resp.status != 200:
                        error_text = await resp.text()
                        Logger.error(f"ğŸ” OAuth ì¸ì¦ ì‹¤íŒ¨: {error_text}")
                        return SecuritiesLoginResponse(
                            result="fail",
                            message="í•œêµ­íˆ¬ìì¦ê¶Œ OAuth ì¸ì¦ ì‹¤íŒ¨",
                            app_key=appkey,
                            sequence=sequence,
                            errorCode=5001
                        )

                    data = await resp.json()
                    token = data.get("access_token")
                    Logger.info(f"âœ… OAuth í† í° ë°œê¸‰ ì„±ê³µ: {token}")

                    # ì‚¬ìš©ìë³„ Redis ì €ì¥ (ê³„ì • ë‹¨ìœ„ë¡œ í† í° ìºì‹œ)
                    try:
                        cache_service = ServiceContainer.get_cache_service()
                        async with cache_service.get_client() as redis_client:
                            # í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: user:{account_db_key}:korea_investment:access_token
                            user_prefix = f"user:{account_db_key}:korea_investment"
                            expires_in = int(data.get("expires_in", 0)) if str(data.get("expires_in", "")).isdigit() else 0
                            # ë§Œë£ŒëŠ” ì‘ë‹µ TTLì—ì„œ 60ì´ˆ ë²„í¼, ìµœì†Œ 5ë¶„ ë³´ì¥
                            ttl_seconds = max(expires_in - 60, 300) if expires_in > 0 else 23 * 3600
                            await redis_client.set_string(f"{user_prefix}:access_token", token, expire=ttl_seconds)
                            await redis_client.set_string(f"{user_prefix}:issued_at", datetime.utcnow().isoformat(), expire=ttl_seconds)
                            Logger.info(f"âœ… Redisì— ì‚¬ìš©ìë³„ OAuth í† í° ì €ì¥ ì™„ë£Œ (account={account_db_key}, ttl={ttl_seconds}s)")
                    except Exception as cache_e:
                        Logger.warn(f"âš ï¸ OAuth í† í° Redis ì €ì¥ ì‹¤íŒ¨: {cache_e}")

            return SecuritiesLoginResponse(
                result="success",
                message="OAuth ì¸ì¦ ì„±ê³µ",
                app_key=appkey,
                sequence=sequence,
                errorCode=0
            )

        except Exception as e:
            Logger.error(f"ğŸ”¥ Dashboard OAuth error: {e}")
            return SecuritiesLoginResponse(
                result="fail",
                message=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}",
                app_key="",
                sequence=sequence,
                errorCode=1000
            )
    async def on_dashboard_price_us_req(self, client_session, request: PriceRequest):
        """ë¯¸êµ­ ë‚˜ìŠ¤ë‹¥ ì¢…ê°€ ì¡°íšŒ ìš”ì²­ ì²˜ë¦¬ (í•œíˆ¬ì¦ REST API ì‚¬ìš©)"""
        Logger.info(f"ğŸ“¥ ë¯¸êµ­ ì¢…ê°€ ìš”ì²­: {request.model_dump_json()}")

        ticker = request.ticker.upper()
        db_service = ServiceContainer.get_database_service()

        Logger.debug(f"ğŸ” DBì—ì„œ API í‚¤ ì¡°íšŒ ì‹œì‘: account_db_key={client_session.session.account_db_key}")

        # DBì—ì„œ ì•±í‚¤, ì•±ì‹œí¬ë¦¿, í† í° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        result = await db_service.call_global_procedure(
            "fp_get_api_keys", (client_session.session.account_db_key,)
        )

        Logger.debug(f"ğŸ“¦ DB ì¡°íšŒ ê²°ê³¼: {result}")

        if not result:
            Logger.error("âŒ API í‚¤ ì¡°íšŒ ì‹¤íŒ¨ (DBì—ì„œ ê²°ê³¼ ì—†ìŒ)")
            return PriceResponse(
                result="fail",
                message="API í‚¤ ì¡°íšŒ ì‹¤íŒ¨",
                ticker=ticker,
                price=0,
                change=0,
                change_pct=0,
                volume=0,
                timestamp="",
                errorCode=9007
            )

        keys = result[0]
        appkey = keys.get("korea_investment_app_key", "")
        app_secret = keys.get("korea_investment_app_secret", "")

        # ìš°ì„ ìˆœìœ„: ì‚¬ìš©ìë³„ Redis ì €ì¥ í† í° â†’ DB ì €ì¥ í† í°(í´ë°±)
        token = ""
        try:
            cache_service = ServiceContainer.get_cache_service()
            async with cache_service.get_client() as redis_client:
                user_prefix = f"user:{client_session.session.account_db_key}:korea_investment"
                redis_token = await redis_client.get_string(f"{user_prefix}:access_token")
                if redis_token:
                    token = redis_token
                    Logger.info("âœ… Redisì—ì„œ ì‚¬ìš©ìë³„ OAuth í† í° ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            Logger.warn(f"âš ï¸ Redisì—ì„œ ì‚¬ìš©ìë³„ í† í° ì¡°íšŒ ì‹¤íŒ¨: {e}")

        if not token:
            # í´ë°±: DB ì»¬ëŸ¼ ê°’ ì‚¬ìš©
            token = keys.get("korea_investment_access_token", "")
            if token:
                Logger.info("â„¹ï¸ Redis í† í° ì—†ìŒ â†’ DB ì €ì¥ í† í° ì‚¬ìš©")

        Logger.debug(f"ğŸ”‘ ì¡°íšŒëœ ì•±í‚¤: {appkey}, ì•±ì‹œí¬ë¦¿: {app_secret}, í† í° ìœ ë¬´: {'Y' if token else 'N'}")

        if not token:
            Logger.error("âŒ OAuth í† í°ì´ ì—†ìŒ")
            return PriceResponse(
                result="fail",
                message="OAuth í† í° ì—†ìŒ",
                ticker=ticker,
                price=0,
                change=0,
                change_pct=0,
                volume=0,
                timestamp="",
                errorCode=9008
            )

        # í•œíˆ¬ì¦ í•´ì™¸ì£¼ì‹ ì‹œì„¸ REST API ìš”ì²­
        url = "https://openapi.koreainvestment.com:9443/uapi/overseas-price/v1/quotations/price"
        params = {
            "AUTH": "",
            "EXCD": "NAS",  # ë‚˜ìŠ¤ë‹¥
            "SYMB": ticker  # ì¢…ëª© í‹°ì»¤
        }
        headers = {
            "authorization": f"Bearer {token}",
            "appkey": appkey,
            "appsecret": app_secret,
            "tr_id": "HHDFS00000300",  # ë¯¸êµ­ ì‹¤ì‹œê°„ ì‹œì„¸
            "custtype": "P",  # ê°œì¸
            "Content-Type": "application/json"
        }

        Logger.info(f"ğŸŒ í•œíˆ¬ì¦ ì‹œì„¸ ìš”ì²­ ì¤€ë¹„: url={url}, params={params}, headers={headers}")

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params, headers=headers) as resp:
                    Logger.info(f"ğŸ“¡ HTTP ìš”ì²­ ì „ì†¡ë¨ (status={resp.status})")

                    if resp.status != 200:
                        text = await resp.text()
                        Logger.error(f"ğŸ”´ ì‹œì„¸ ìš”ì²­ ì‹¤íŒ¨: status={resp.status}, body={text}")
                        return PriceResponse(
                            result="fail",
                            message="ì‹œì„¸ ìš”ì²­ ì‹¤íŒ¨",
                            ticker=ticker,
                            price=0,
                            change=0,
                            change_pct=0,
                            volume=0,
                            timestamp="",
                            errorCode=5001
                        )

                    data = await resp.json()
                    Logger.debug(f"ğŸ“¥ API ì‘ë‹µ JSON: {data}")

                    output = data.get("output", {})
                    Logger.debug(f"ğŸ“¦ output ë°ì´í„°: {output}")

                    # ì‘ë‹µ í‚¤ ê°€ë³€ì„± ì²˜ë¦¬: diff/chg, tvol/pvol, ctime ë¯¸ì œê³µ ì‹œ UTC now
                    change_value = output.get("chg")
                    if change_value is None:
                        change_value = output.get("diff", 0)
                    volume_value = output.get("tvol")
                    if volume_value is None:
                        volume_value = output.get("pvol", 0)

                    return PriceResponse(
                        result="success",
                        message="ì‹œì„¸ ìš”ì²­ ì„±ê³µ",
                        ticker=ticker,
                        price=float(output.get("last", 0)),
                        change=float(change_value or 0),
                        change_pct=float(output.get("rate", 0)),
                        volume=float(volume_value or 0),
                        timestamp=output.get("ctime", datetime.utcnow().isoformat()),
                        errorCode=0
                    )

        except Exception as e:
            Logger.error(f"ğŸ”¥ ì‹œì„¸ ì¡°íšŒ ì˜ˆì™¸ ë°œìƒ: {e}\n{traceback.format_exc()}")
            return PriceResponse(
                result="fail",
                message=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}",
                ticker=ticker,
                price=0,
                change=0,
                change_pct=0,
                volume=0,
                timestamp="",
                errorCode=1000
            )

    async def on_stock_recommendation_req(self, client_session, request: StockRecommendationRequest):
        """AIChat ì˜ì¡´ ì—†ì´ ë™ì‘í•˜ëŠ” ì¢…ëª© ì¶”ì²œ íŒŒì´í”„ë¼ì¸ (ë‰´ìŠ¤/ê±°ì‹œ/ì¬ë¬´ ì§ì ‘ í˜¸ì¶œ)

        ë‹¨ê³„:
        1) ìŠ¤íƒ€ì¼ë³„ í›„ë³´ í‹°ì»¤ ëª©ë¡ ì¤€ë¹„(ê¸°ë³¸ ë‚´ì¥, í•„ìš” ì‹œ í™˜ê²½/ìš”ì²­ì— ë”°ë¼ í™•ì¥)
        2) ê° í‹°ì»¤ ìµœì‹  ë‰´ìŠ¤(GNews) ìˆ˜ì§‘
        3) ê±°ì‹œì§€í‘œ(FRED: S&P500, NASDAQ, VIX) ìˆ˜ì§‘ ë° ìš”ì•½
        4) (ì˜µì…˜) FMP ì¬ë¬´ì§€í‘œ ì¼ë¶€ ì¡°íšŒí•´ íŒíŠ¸ë¡œ í™œìš©
        5) ë‹¨ë… LLM(ChatOpenAI)ë¡œ ìƒìœ„ 3ê°œ ì„ ë³„â†’ìµœì¢… 1ê°œ ì„ ì •(ì—†ìœ¼ë©´ íœ´ë¦¬ìŠ¤í‹±)
        6) {date,ticker,reason,report} í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        """
        # â”€â”€ DEBUG helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        TRACE_ID = getattr(request, "trace_id", None) or uuid.uuid4().hex[:8]
        DEBUG = bool(getattr(request, "debug", False) or os.getenv("DEBUG_STOCK_REC", "0") == "1")
        MAX_LOG = int(os.getenv("STOCK_REC_MAX_LOG_CHARS", "1200"))

        def clip(s: str, n: int = MAX_LOG) -> str:
            if not isinstance(s, str):
                try:
                    s = str(s)
                except Exception:
                    return "<non-str>"
            return s if len(s) <= n else f"{s[:n]} â€¦ <clipped {len(s)-n} chars>"

        _SECRET_PAT = re.compile(r"(sk-[A-Za-z0-9]{10,}|api[_-]?key\s*=\s*['\"][^'\"]+['\"])", flags=re.IGNORECASE)

        def redact(s: str) -> str:
            return _SECRET_PAT.sub("***REDACTED***", s or "")

        def dbg(msg: str, **kw):
            if DEBUG:
                extra = f" | {kw}" if kw else ""
                Logger.debug(f"[stock-rec][{TRACE_ID}] {msg}{extra}")

        def step_timer():
            t0 = time.perf_counter()
            return lambda name: (name, time.perf_counter() - t0)

        Logger.info(f"ğŸ“¥ ì£¼ì‹ ì¶”ì²œ ìš”ì²­(standalone): {request.model_dump_json()}")

        response = StockRecommendationResponse(result="pending", recommendations=[], message="")
        response.sequence = request.sequence

        tick = step_timer()
        timings = {}

        try:
            # AppConfig ìš°ì„  â†’ í™˜ê²½ë³€ìˆ˜ í´ë°± ë°©ì‹ìœ¼ë¡œ API í‚¤ í™•ë³´ ë° LLM ì§ì ‘ êµ¬ì„±
            def get_key(name: str) -> str:
                try:
                    if self.app_config and getattr(self.app_config, "llmConfig", None):
                        val = self.app_config.llmConfig.API_Key.get(name)
                        if val:
                            return val
                except Exception:
                    pass
                return os.getenv(name, "")

            llm = None
            try:
                from langchain_openai import ChatOpenAI  # type: ignore
                # ê¸°ë³¸ê°’
                openai_key: str | None = os.getenv("OPENAI_API_KEY") or None
                openai_model: str | None = os.getenv("OPENAI_MODEL") or None
                base_url: str | None = None
                temperature = 0.2
                timeout = 30

                # AppConfig ê¸°ë°˜ ì„¤ì • ìš°ì„ 
                if self.app_config and getattr(self.app_config, "llmConfig", None):
                    try:
                        prov_id = self.app_config.llmConfig.default_provider
                        prov = self.app_config.llmConfig.providers.get(prov_id)
                        if prov:
                            openai_key = openai_key or prov.api_key
                            openai_model = "gpt-4o-mini"
                            base_url = getattr(prov, "base_url", None) or base_url
                            if isinstance(prov.temperature, (int, float)) and prov.temperature is not None:
                                temperature = float(prov.temperature)
                            if isinstance(prov.timeout, int) and prov.timeout is not None:
                                timeout = int(prov.timeout)
                    except Exception:
                        pass

                # ìµœì¢… í‚¤ í™•ì¸ í›„ LLM ìƒì„± (íŒŒë¼ë¯¸í„°ëª…ì€ ê¸°ì¡´ ì„œë¹„ìŠ¤ êµ¬í˜„ê³¼ ë™ì¼í•˜ê²Œ openai_api_key ì‚¬ìš©)
                if openai_key:
                    if base_url:
                        llm = ChatOpenAI(model=openai_model or "gpt-4o-mini", temperature=temperature, timeout=timeout, openai_api_key=openai_key, base_url=base_url)
                    else:
                        llm = ChatOpenAI(model=openai_model or "gpt-4o-mini", temperature=temperature, timeout=timeout, openai_api_key=openai_key)
            except Exception:
                llm = None

            NEWSAPI_KEY = get_key("NEWSAPI_KEY")
            FMP_API_KEY = get_key("FMP_API_KEY")
            FRED_API_KEY = get_key("FRED_API_KEY")

            market = (request.market or "NASDAQ").upper()
            today = datetime.now(timezone.utc).date().isoformat()

            # â”€â”€ 1) í›„ë³´ í‹°ì»¤ (LLMìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ 10ê°œ ìƒì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            styles = ["CONSERVATIVE", "GROWTH", "VALUE"]
            prompts = ["ì£¼ì‹ ì‹œì¥ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì €ëŠ” ë³€ë™ì„±ì´ ë‚®ê³  ê¾¸ì¤€í•œ ìˆ˜ìµì„ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” ì•ˆì •ì ì¸(Conservative) íˆ¬ì","í˜ì‹  ê¸°ìˆ ê³¼ ë¯¸ë˜ ì‚°ì—… íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ë²¤ì²˜ ìºí”¼íƒˆë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì €ëŠ” ë‹¨ê¸°ì ì¸ ë³€ë™ì„±ì„ ê°ìˆ˜í•˜ë”ë¼ë„ ë†’ì€ ìë³¸ ìˆ˜ìµë¥ ì„ ëª©í‘œë¡œ í•˜ëŠ” ì„±ì¥ì£¼(Growth Stock)ì— íˆ¬ì","ì›Œë Œ ë²„í•ì˜ íˆ¬ì ì² í•™ì„ ë”°ë¥´ëŠ” ê°€ì¹˜ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì €ëŠ” í˜„ì¬ ê¸°ì—…ì˜ ë‚´ì¬ ê°€ì¹˜ì— ë¹„í•´ ì €í‰ê°€ë˜ì–´ ìˆëŠ” ê°€ì¹˜ì£¼(Value Stock)ë¥¼ ë°œêµ´í•˜ì—¬ ì¥ê¸°ì ì¸ ê´€ì ì—ì„œ íˆ¬ì"]
            style_to_tickers: dict[str, list[str]] = {}

            # ì‹¬ë³¼ ê²€ì¦: AAPL, MSFT, BRK.B ë“± í—ˆìš©
            _SYMBOL_RE = re.compile(r'^[A-Z]{1,5}(?:\.[A-Z]{1,2})?$')
            # "tickers": [ ... ] ë¸”ë¡ì„ ë„“ê²Œ ì¡ì•„ ì¶”ì¶œ
            _TICKERS_BLOCK_RE = re.compile(r'"tickers"\s*:\s*\[(.*?)\]', re.S | re.I)

            def _strip_code_fences(s: str) -> str:
                # ```json ... ``` í˜¹ì€ ``` ... ``` ì œê±°
                m = re.findall(r"```(?:json)?\s*(.*?)\s*```", s, flags=re.S | re.I)
                return m[0] if m else s

            def _try_json(s: str):
                try:
                    return json.loads(s)
                except Exception:
                    return None

            def parse_ticker_list(raw: Any) -> list[str]:
                """
                LLM ì‘ë‹µì´ ë¬¸ìì—´/ë”•ì…”ë„ˆë¦¬/ë©”ì‹œì§€ê°ì²´(out.content ë³´ìœ ) ë“± ì–´ë–¤ í˜•íƒœë“ 
                tickersë¥¼ ìµœëŒ€ 10ê°œê¹Œì§€ ì •ì œí•´ ë°˜í™˜.
                """
                # 0) ë©”ì‹œì§€ ê°ì²´ì—ì„œ content ìš°ì„  ì¶”ì¶œ
                if hasattr(raw, "content"):
                    raw = getattr(raw, "content") or raw
                # 1) ë”•ì…”ë„ˆë¦¬ë©´ ë°”ë¡œ ì ‘ê·¼
                if isinstance(raw, dict):
                    arr = raw.get("tickers")
                    return _normalize_tickers(arr)

                # 2) ë¬¸ìì—´ë¡œ ìºìŠ¤íŒ…
                s = str(raw)

                # 3) ì½”ë“œíœìŠ¤ ì œê±° í›„ JSON ì‹œë„
                s_clean = _strip_code_fences(s).strip()
                obj = _try_json(s_clean)
                if isinstance(obj, dict) and isinstance(obj.get("tickers"), list):
                    return _normalize_tickers(obj["tickers"])

                # 4) ì›ë¬¸ ì „ì²´ë¥¼ JSONìœ¼ë¡œë„ ì‹œë„ (ì¼ë¶€ ëª¨ë¸ì´ ì½”ë“œíœìŠ¤ ì—†ì´ ìˆœìˆ˜ JSONì„ ì¤„ ë•Œ)
                obj2 = _try_json(s)
                if isinstance(obj2, dict) and isinstance(obj2.get("tickers"), list):
                    return _normalize_tickers(obj2["tickers"])

                # 5) ì •ê·œì‹ìœ¼ë¡œ "tickers":[ ... ] ë¸”ë¡ì—ì„œ í›„ë³´ ì¶”ì¶œ
                m = _TICKERS_BLOCK_RE.search(s)
                if m:
                    inside = m.group(1).upper()
                    # ë”°ì˜´í‘œ ìœ ë¬´/ì‰¼í‘œ/ê³µë°± ì„ì—¬ë„ ì‹¬ë³¼ íŒ¨í„´ìœ¼ë¡œ ê±¸ëŸ¬ëƒ„
                    candidates = re.findall(r'[A-Z]{1,5}(?:\.[A-Z]{1,2})?', inside)
                    if candidates:
                        return _normalize_tickers(candidates)

                # 6) ë§ˆì§€ë§‰ ì•ˆì „ë§: ë³¸ë¬¸ ì „ì²´ì—ì„œ ì‹¬ë³¼ íŒ¨í„´ ìŠ¤ìº”
                candidates = re.findall(r'[A-Z]{1,5}(?:\.[A-Z]{1,2})?', s.upper())
                return _normalize_tickers(candidates)

            def _normalize_tickers(arr, limit: int = 10) -> list[str]:
                if not isinstance(arr, list):
                    return []
                out: list[str] = []
                seen = set()
                for t in arr:
                    if not isinstance(t, str):
                        continue
                    sym = t.strip().upper()
                    if not sym or not _SYMBOL_RE.fullmatch(sym):
                        continue
                    if sym in seen:
                        continue
                    seen.add(sym)
                    out.append(sym)
                    if len(out) >= limit:
                        break
                return out
            def pick_unique(seq: list[str], k: int, banned: set[str] | None = None) -> list[str]:
                """seqì—ì„œ ì•ì—ì„œë¶€í„° ì¤‘ë³µ/ê¸ˆì§€(banned) ì—†ì´ ìµœëŒ€ kê°œë¥¼ ë½‘ì•„ ë°˜í™˜."""
                banned = banned or set()
                out: list[str] = []
                seen: set[str] = set()
                for t in seq:
                    u = (t or "").strip().upper()
                    if not u or u in banned or u in seen:
                        continue
                    out.append(u)
                    seen.add(u)
                    if len(out) >= k:
                        break
                return out

            # ë£¨í”„ ëŒê¸° ì „ì— í•œ ì¤„ ì¶”ê°€
            used_tickers: set[str] = set()
            TARGET_PER_STYLE = 10  # ê¸°ì¡´ì²˜ëŸ¼ 10ê°œë¥¼ ìƒí•œìœ¼ë¡œ ìœ ì§€

            for style, prompt in zip(styles, prompts):
                tickers: list[str] = []

                # â”€â”€ ê¸°ì¡´ 1-a, 1-b, í´ë°± ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                try:
                    from openai import OpenAI  # type: ignore
                    openai_key_cfg = os.getenv("OPENAI_API_KEY") or None
                    openai_model_cfg = os.getenv("OPENAI_SEARCH_MODEL") or None
                    base_url_cfg: str | None = None
                    if self.app_config and getattr(self.app_config, "llmConfig", None):
                        prov_id = self.app_config.llmConfig.default_provider
                        prov = self.app_config.llmConfig.providers.get(prov_id)
                        if prov:
                            openai_key_cfg = openai_key_cfg or prov.api_key
                            base_url_cfg = getattr(prov, "base_url", None) or base_url_cfg
                    search_model = openai_model_cfg or os.getenv("OPENAI_MODEL_SEARCH_DEFAULT", "gpt-4.1")
                    if openai_key_cfg:
                        client = OpenAI(api_key=openai_key_cfg, base_url=base_url_cfg)
                        prompt_tickers_ws = (
                            f"You are a professional equity analyst. Using up-to-date web search, "
                            f"select 10 promising US {market} tickers for the category {style}. "
                            'Return strictly JSON only: {"tickers":["AAPL", ...]} with UPPERCASE tickers. '
                            "Do not include any explanation. Consider liquidity and recency."
                        )
                        ws = client.responses.create(
                            model=search_model,
                            tools=[{"type": "web_search_preview"}],
                            tool_choice={"type": "web_search_preview"},
                            input=prompt_tickers_ws,
                        )
                        raw = getattr(ws, "output_text", None)
                        if not raw:
                            try:
                                outputs = getattr(ws, "output", [])
                                if outputs:
                                    for item in outputs:
                                        if getattr(item, "type", "") == "message":
                                            contents = getattr(item, "content", [])
                                            for c in contents:
                                                if getattr(c, "type", "") == "output_text":
                                                    raw = getattr(c, "text", None)
                                                    if raw:
                                                        break
                                            if raw:
                                                break
                            except Exception:
                                raw = None
                        if isinstance(raw, str) and raw.strip():
                            tickers = parse_ticker_list(raw)
                except Exception:
                    pass

                if not tickers and llm is not None:
                    try:
                        prompt_tickers = (
                            f"ë‹¤ìŒ ì¹´í…Œê³ ë¦¬({style})ì— ì í•©í•œ ë¯¸êµ­ ë‚˜ìŠ¤ë‹¥ì— ìœ ë§ í‹°ì»¤ 10ê°œë¥¼ ì„ íƒ. "
                            f"{prompt}í•˜ê¸° ì¢‹ì€ ì£¼ì‹ ì‹œì¥ì„ ë¶„ì„í•˜ê³ , ìœ ë§ í‹°ì»¤ 10ê°œë¥¼ ì„ íƒí•˜ê³  "
                            'ì˜¤ì§ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë¼. í˜•ì‹: {"tickers":["AAPL", ...]}'
                        )
                        print(f"llmì´ ì‹œë„ í•œë‹¤.")
                        out = llm.invoke(prompt_tickers)
                        print(f"llmì´ ì´ë ‡ê²Œ ë§í•¨. : -- {out}")
                        tickers = parse_ticker_list(out)
                    except Exception:
                        tickers = []

                if not tickers:
                    fallback: dict[str, list[str]] = {
                        "CONSERVATIVE": ["AAPL","MSFT","GOOGL","AVGO","COST","PEP","KO","JNJ","PG","V"],
                        "GROWTH": ["NVDA","TSLA","AMD","SMCI","PLTR","SHOP","MDB","CRWD","SNOW","NET"],
                        "VALUE": ["AMZN","META","NFLX","ADBE","INTC","ORCL","CSCO","IBM","QCOM","TXN"],
                    }
                    print("LLM ì‹¤íŒ¨/ë¯¸ì‚¬ìš© ì‹œ ê°„ë‹¨ í´ë°±")
                    tickers = fallback.get(style, [])[:TARGET_PER_STYLE]

                final_list = pick_unique(tickers, TARGET_PER_STYLE, banned=used_tickers)
                style_to_tickers[style] = final_list
                used_tickers.update(final_list)

            timings["step1_candidates"] = tick("step1_candidates")[1]
            tick = step_timer()

            # â”€â”€ helpers: ì™¸ë¶€í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            async def fetch_gnews(query: str, k: int = 5) -> list[dict]:
                if not NEWSAPI_KEY:
                    return []
                url = "https://gnews.io/api/v4/search"
                params = {"q": query, "lang": "en", "token": NEWSAPI_KEY, "max": k}
                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, params=params, timeout=10) as resp:
                            if resp.status != 200:
                                return []
                            data = await resp.json()
                            articles = data.get("articles", [])
                            out = []
                            for a in articles:
                                out.append({
                                    "title": a.get("title", ""),
                                    "url": a.get("url", ""),
                                    "date": (a.get("publishedAt", "") or "")[:10],
                                })
                            return out
                except Exception:
                    return []

            async def fetch_fred_latest(series_id: str) -> float:
                if not FRED_API_KEY:
                    return 0.0
                url = "https://api.stlouisfed.org/fred/series/observations"
                params = {
                    "series_id": series_id,
                    "api_key": FRED_API_KEY,
                    "file_type": "json",
                    "sort_order": "desc",
                    "limit": 1,
                }
                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, params=params, timeout=10) as resp:
                            if resp.status != 200:
                                return 0.0
                            data = await resp.json()
                            obs = (data.get("observations") or [])
                            if not obs:
                                return 0.0
                            v = obs[0].get("value")
                            try:
                                return float(v)
                            except Exception:
                                return 0.0
                except Exception:
                    return 0.0

            async def fetch_fmp_metrics(ticker: str) -> dict:
                if not FMP_API_KEY:
                    return {}
                base = "https://financialmodelingprep.com/api/v3"
                params = {"apikey": FMP_API_KEY, "period": "annual", "limit": 4}
                endpoints = [
                    (f"{base}/key-metrics/{ticker}", {}),
                    (f"{base}/ratios/{ticker}", {}),
                    (f"{base}/income-statement/{ticker}", {}),
                ]
                out: dict[str, Any] = {}
                try:
                    async with aiohttp.ClientSession() as session:
                        for url, extra in endpoints:
                            p = params.copy(); p.update(extra)
                            async with session.get(url, params=p, timeout=10) as resp:
                                if resp.status != 200:
                                    continue
                                try:
                                    out[url.rsplit("/", 1)[-1]] = await resp.json()
                                except Exception:
                                    pass
                except Exception:
                    pass
                return out

            # â”€â”€ 2) ë‰´ìŠ¤ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            ticker_news: dict[str, list[dict]] = {}
            flat_tickers = [t for arr in style_to_tickers.values() for t in arr]
            dbg("news_fetch_start", total_symbols=len(flat_tickers))
            t_news = step_timer()
            news_results = await asyncio.gather(*[fetch_gnews(t, 5) for t in flat_tickers], return_exceptions=True)
            timings["step2_news_fetch"] = t_news("news_fetch")[1]
            idx = 0
            for style in styles:
                for t in style_to_tickers.get(style, []):
                    res = news_results[idx]; idx += 1
                    if isinstance(res, Exception):
                        ticker_news[t] = []
                    else:
                        ticker_news[t] = res or []

            # â”€â”€ 3) ê±°ì‹œì§€í‘œ ìˆ˜ì§‘(FRED) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            t_macro = step_timer()
            sp500, nasdaq, vix = await asyncio.gather(
                fetch_fred_latest("SP500"),
                fetch_fred_latest("NASDAQCOM"),
                fetch_fred_latest("VIXCLS"),
            )
            macro_brief = "\n".join([
                f"S&P 500: {sp500:.2f}" if sp500 else "S&P 500: N/A",
                f"NASDAQ: {nasdaq:.2f}" if nasdaq else "NASDAQ: N/A",
                f"VIX: {vix:.2f}" if vix else "VIX: N/A",
            ])
            timings["step3_macro_fetch"] = t_macro("macro_fetch")[1]
            tick = step_timer()

            # â”€â”€ 4) (ì˜µì…˜) ì¬ë¬´ ë©”íŠ¸ë¦­ ì¼ë¶€ ì¡°íšŒ(ë³‘ë ¬, ì‹¤íŒ¨ í—ˆìš©) â”€â”€â”€â”€â”€
            t_fin = step_timer()
            fin_map: dict[str, dict] = {}
            if FMP_API_KEY:
                fin_results = await asyncio.gather(*[fetch_fmp_metrics(t) for t in flat_tickers], return_exceptions=True)
                j = 0
                for t in flat_tickers:
                    r = fin_results[j]; j += 1
                    if not isinstance(r, Exception):
                        fin_map[t] = r
            timings["step4_financials_fetch"] = t_fin("fin_fetch")[1]
            tick = step_timer()

            # â”€â”€ 5) ìƒìœ„ 3ê°œ ì„ ë³„ â†’ ìµœì¢… 1ê°œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            def build_news_lines(tk: str) -> str:
                items = ticker_news.get(tk, [])[:5]
                return "; ".join([i.get("title", "") for i in items if i.get("title")])

            def heuristic_pick_top3(cands: list[str]) -> list[dict]:
                # ë§¤ìš° ë‹¨ìˆœí•œ íœ´ë¦¬ìŠ¤í‹±: ë‰´ìŠ¤ ì œëª© ê¸¸ì´/ê°€ì§“ìˆ˜ ê¸°ë°˜ ê°€ì¤‘ì¹˜
                scored = []
                for tkr in cands:
                    titles = [n.get("title", "") for n in ticker_news.get(tkr, [])]
                    score = sum(min(len(s), 120) for s in titles[:5])
                    scored.append((score, tkr))
                scored.sort(reverse=True)
                return [{"ticker": t, "reason": "ìµœê·¼ ë‰´ìŠ¤ ë…¸ì¶œ/í™œë™ëŸ‰ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ìŒ"} for _, t in scored[:3]]

            def safe_json_loads(text: str):
                if text is None:
                    return None
                try:
                    return json.loads(text)
                except Exception:
                    start = text.find("{"); end = text.rfind("}")
                    if start != -1 and end != -1 and end > start:
                        try:
                            return json.loads(text[start:end+1])
                        except Exception:
                            return None
                    return None

            def is_valid_hex_color(value: str) -> bool:
                try:
                    return bool(re.fullmatch(r"#([0-9A-Fa-f]{6})", str(value)))
                except Exception:
                    return False

            def pick_brand_color(ticker: str) -> str:
                t = (ticker or "").upper()
                brand = {
                    "AAPL": "#0EA5E9",  # Apple blue-ish
                    "MSFT": "#2563EB",
                    "GOOGL": "#EA4335",
                    "GOOG": "#EA4335",
                    "AVGO": "#DC2626",
                    "COST": "#1D4ED8",
                    "NVDA": "#22C55E",
                    "TSLA": "#EF4444",
                    "AMD": "#F97316",
                    "SMCI": "#3B82F6",
                    "PLTR": "#64748B",
                    "AMZN": "#F59E0B",
                    "META": "#2563EB",
                    "NFLX": "#DC2626",
                    "ADBE": "#EF4444",
                    "INTC": "#1E3A8A",
                }
                return brand.get(t, "#1f2937")

            style_top3: dict[str, list[dict]] = {}
            for style in styles:
                cands = style_to_tickers.get(style, [])
                if not cands:
                    style_top3[style] = []
                    continue
                if llm is None:
                    style_top3[style] = heuristic_pick_top3(cands)
                    continue

                news_snippets = [f"- {t}: {build_news_lines(t)}" for t in cands]
                prompt = (
                    "ì•„ë˜ í›„ë³´ í‹°ì»¤ì™€ ìµœì‹  ë‰´ìŠ¤ ì œëª©ì„ ì°¸ê³ í•˜ì—¬ ì¹´í…Œê³ ë¦¬ {style} ê´€ì ì—ì„œ ìƒìœ„ 3ê°œë¥¼ ê³ ë¥´ê³ , "
                    "ê° ì„ íƒ ì´ìœ ë¥¼ í•œ ì¤„ë¡œ ì„¤ëª…í•˜ë¼. ì˜¤ì§ JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µ. í˜•ì‹: "
                    '[{{"ticker":"TSLA","reason":"..."}}, ...]'
                ).format(style=style)
                full = f"{prompt}\n\n" + "\n".join(news_snippets)
                try:
                    out = llm.invoke(full)
                    raw = getattr(out, "content", "") if out is not None else ""
                    parsed = safe_json_loads(raw) or []
                    top3: list[dict] = []
                    if isinstance(parsed, list):
                        for it in parsed:
                            if isinstance(it, dict) and it.get("ticker"):
                                top3.append({
                                    "ticker": str(it["ticker"]).upper(),
                                    "reason": str(it.get("reason", "")).strip(),
                                })
                            if len(top3) == 3:
                                break
                    if not top3:
                        top3 = heuristic_pick_top3(cands)
                    style_top3[style] = top3[:3]
                except Exception:
                    style_top3[style] = heuristic_pick_top3(cands)

            timings["step5_pick_top3"] = tick("pick_top3")[1]
            tick = step_timer()

            finals: list[dict] = []
            for style in styles:
                triples = style_top3.get(style, [])
                if not triples:
                    continue
                if llm is None:
                    pick = triples[0]
                    finals.append({
                        "date": today,
                        "ticker": pick["ticker"],
                        "reason": pick.get("reason", ""),
                        "report": "ê±°ì‹œì§€í‘œì™€ ìµœê·¼ ë‰´ìŠ¤ ë…¸ì¶œì„ ì°¸ê³ í•œ ë‹¨ìˆœ ì¶”ì²œì…ë‹ˆë‹¤.",
                        "color": pick_brand_color(pick["ticker"]),
                    })
                    continue

                triple_text = "\n".join([f"- {x['ticker']}: {x.get('reason','')}" for x in triples])
                prompt = (
                    "ë‹¤ìŒ 3ê°œ í›„ë³´ ì¤‘ì—ì„œ {style} ê´€ì ì—ì„œ ìµœì¢… 1ê°œ í‹°ì»¤ë¥¼ ê³ ë¥´ê³ , "
                    "ì„ ì • ì‚¬ìœ (2~3ë¬¸ì¥)ì™€ ê°„ë‹¨í•œ ì• ë„ë¦¬ìŠ¤íŠ¸ ë ˆí¬íŠ¸(ë§ˆí¬ë‹¤ìš´) ìš”ì•½(8~12ë¬¸ì¥)ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë¼. "
                    "ê±°ì‹œ ì§€í‘œë¥¼ ì°¸ê³ í•˜ë¼. ì˜¤ì§ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë˜, í•´ë‹¹ ê¸°ì—…ê³¼ ì–´ìš¸ë¦¬ëŠ” ëŒ€í‘œ ìƒ‰ìƒì„ í¬í•¨í•´ì„œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ: "
                    '{{"ticker":"TSLA","reason":"...","report":"...","color":"#000000"}}'
                ).format(style=style)
                user_block = f"[ê±°ì‹œ ìš”ì•½]\n{macro_brief}\n\n[í›„ë³´]\n{triple_text}"
                full = f"{prompt}\n\n{user_block}"
                try:
                    out = llm.invoke(full)
                    raw = getattr(out, "content", "") if out is not None else ""
                    data3 = safe_json_loads(raw) or {}
                    ticker = str(data3.get("ticker") or (triples[0]["ticker"] if triples else "AAPL")).upper()
                    reason = str(data3.get("reason") or (triples[0].get("reason") if triples else "ê¸°ë³¸ ì¶”ì²œ")).strip()
                    report = str(data3.get("report") or "ìµœê·¼ ë‰´ìŠ¤ì™€ ê±°ì‹œì§€í‘œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ì´ ì¶”ì²œì…ë‹ˆë‹¤.").strip()
                    raw_color = data3.get("color")
                    color = raw_color if isinstance(raw_color, str) and is_valid_hex_color(raw_color) else pick_brand_color(ticker)
                    finals.append({"date": today, "ticker": ticker, "reason": reason, "report": report, "color": color})
                except Exception:
                    pick = triples[0]
                    finals.append({
                        "date": today,
                        "ticker": pick["ticker"],
                        "reason": pick.get("reason", ""),
                        "report": "ê±°ì‹œì§€í‘œì™€ ìµœê·¼ ë‰´ìŠ¤ ë…¸ì¶œì„ ì°¸ê³ í•œ ë‹¨ìˆœ ì¶”ì²œì…ë‹ˆë‹¤.",
                        "color": pick_brand_color(pick["ticker"]),
                    })

            # ì‘ë‹µ êµ¬ì„±
            response.result = "success"
            response.recommendations = finals
            response.message = f"{market} ì‹œì¥ ë‹¨ë… AI ì¶”ì²œ ì™„ë£Œ"
            response.errorCode = 0

            timings["step6_final"] = tick("final")[1]
            total_ms = sum(v for v in timings.values())
            try:
                timings_ms = {k: round(v * 1000, 1) for k, v in timings.items()}
                Logger.info(
                    f"âœ… Standalone ì¶”ì²œ ì™„ë£Œ[{TRACE_ID}] styles={len(styles)} picks={len(finals)} "
                    f"timings(ms)={timings_ms} total_ms={round(total_ms * 1000, 1)}"
                )
            except Exception:
                Logger.info(
                    f"âœ… Standalone ì¶”ì²œ ì™„ë£Œ[{TRACE_ID}] picks={len(finals)} total_ms={round(total_ms * 1000, 1)}"
                )

        except Exception as e:
            Logger.error(f"ğŸ”¥ Standalone ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜[{TRACE_ID}]: {e}\n{traceback.format_exc()}")
            response.result = "fail"
            response.message = f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"
            response.errorCode = 1000

        return response

    async def on_economic_calendar_req(self, client_session, request: EconomicCalendarRequest):
        """ê²½ì œ ì¼ì • ìš”ì²­ ì²˜ë¦¬ (FMP API ì‚¬ìš©)"""
        Logger.info(f"ğŸ“¥ ê²½ì œ ì¼ì • ìš”ì²­: {request.model_dump_json()}")

        response = EconomicCalendarResponse()
        response.sequence = request.sequence

        try:
            # ì„¤ì • íŒŒì¼ì—ì„œ FMP API í‚¤ ê°€ì ¸ì˜¤ê¸°
            fmp_api_key = ""
            Logger.info(f"ğŸ” app_config í™•ì¸: {self.app_config is not None}")
            
            if self.app_config:
                Logger.info(f"ğŸ” app_config ì†ì„±ë“¤: {dir(self.app_config)}")
                if hasattr(self.app_config, 'llmConfig'):
                    Logger.info(f"ğŸ” llmConfig í™•ì¸: {self.app_config.llmConfig}")
                    if hasattr(self.app_config.llmConfig, 'API_Key'):
                        Logger.info(f"ğŸ” API_Key í™•ì¸: {self.app_config.llmConfig.API_Key}")
                        fmp_api_key = self.app_config.llmConfig.API_Key.get("FMP_API_KEY", "")
                        Logger.info(f"ğŸ”‘ FMP API í‚¤: {'ìˆìŒ' if fmp_api_key else 'ì—†ìŒ'} ({fmp_api_key[:10] if fmp_api_key else 'N/A'}...)")
                    else:
                        Logger.warn("âš ï¸ llmConfigì— API_Key ì†ì„± ì—†ìŒ")
                else:
                    Logger.warn("âš ï¸ app_configì— llmConfig ì†ì„± ì—†ìŒ")
            else:
                Logger.warn("âš ï¸ app_configê°€ None")

            if not fmp_api_key:
                # í™˜ê²½ë³€ìˆ˜ì—ì„œ í´ë°± ì‹œë„
                import os
                fmp_api_key = os.getenv("FMP_API_KEY", "")
                Logger.info(f"ğŸ” í™˜ê²½ë³€ìˆ˜ì—ì„œ FMP API í‚¤ ì¡°íšŒ: {'ìˆìŒ' if fmp_api_key else 'ì—†ìŒ'}")

            if not fmp_api_key:
                Logger.warn("âŒ FMP API í‚¤ ì—†ìŒ - ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
                response.result = "success"
                response.events = self._get_dummy_events(request.days)
                response.message = "FMP API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë”ë¯¸ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
                response.source = "ë”ë¯¸ ë°ì´í„°"
                response.errorCode = 0
                return response

            # FMP API í˜¸ì¶œ
            events = await self._fetch_fmp_economic_calendar(fmp_api_key, request.days)
            
            response.result = "success"
            response.events = events
            response.message = "ê²½ì œ ì¼ì • ì¡°íšŒ ì„±ê³µ"
            response.source = "FMP API"
            response.errorCode = 0

        except Exception as e:
            Logger.error(f"ğŸ”¥ ê²½ì œ ì¼ì • ì¡°íšŒ ì˜¤ë¥˜: {e}")
            response.result = "fail"
            response.events = self._get_dummy_events(request.days)
            response.message = f"API ì˜¤ë¥˜ë¡œ ì¸í•´ ë”ë¯¸ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤: {str(e)}"
            response.source = "ë”ë¯¸ ë°ì´í„° (ì˜¤ë¥˜ í´ë°±)"
            response.errorCode = 1000

        return response

    async def on_market_risk_premium_req(self, client_session, request: MarketRiskPremiumRequest):
        """ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ìš”ì²­ ì²˜ë¦¬ (FMP API ì‚¬ìš©)"""
        Logger.info(f"ğŸ“¥ ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ìš”ì²­: {request.model_dump_json()}")

        response = MarketRiskPremiumResponse()
        response.sequence = request.sequence

        try:
            # ì„¤ì • íŒŒì¼ì—ì„œ FMP API í‚¤ ê°€ì ¸ì˜¤ê¸°
            fmp_api_key = ""
            if self.app_config and hasattr(self.app_config, 'llmConfig') and hasattr(self.app_config.llmConfig, 'API_Key'):
                fmp_api_key = self.app_config.llmConfig.API_Key.get("FMP_API_KEY", "")
            
            if not fmp_api_key:
                # í™˜ê²½ë³€ìˆ˜ì—ì„œ í´ë°± ì‹œë„
                import os
                fmp_api_key = os.getenv("FMP_API_KEY", "")

            if not fmp_api_key:
                Logger.warn("âŒ FMP API í‚¤ ì—†ìŒ - ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
                response.result = "success"
                response.premiums = self._get_dummy_market_risk_premiums(request.countries)
                response.message = "FMP API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë”ë¯¸ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
                response.source = "ë”ë¯¸ ë°ì´í„°"
                response.errorCode = 0
                return response

            # FMP API í˜¸ì¶œ
            premiums = await self._fetch_fmp_market_risk_premiums(fmp_api_key, request.countries)
            
            response.result = "success"
            response.premiums = premiums
            response.message = "ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ì¡°íšŒ ì„±ê³µ"
            response.source = "FMP API"
            response.lastUpdated = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            response.errorCode = 0

        except Exception as e:
            Logger.error(f"ğŸ”¥ ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            response.result = "fail"
            response.premiums = self._get_dummy_market_risk_premiums(request.countries)
            response.message = f"API ì˜¤ë¥˜ë¡œ ì¸í•´ ë”ë¯¸ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤: {str(e)}"
            response.source = "ë”ë¯¸ ë°ì´í„° (ì˜¤ë¥˜ í´ë°±)"
            response.errorCode = 1000

        return response

    async def _fetch_fmp_economic_calendar(self, fmp_api_key: str, days: int) -> list:
        """FMP APIì—ì„œ ê²½ì œ ì¼ì • ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹± ì ìš©)"""
        try:
            # ìºì‹œ í‚¤ ìƒì„± (ë‚ ì§œì™€ ì¼ìˆ˜ ê¸°ë°˜)
            cache_key = f"economic_calendar_{days}_{datetime.now().strftime('%Y-%m-%d')}"
            
            # ìºì‹œëœ ë°ì´í„°ê°€ ìˆê³  10ë¶„ ì´ë‚´ë¼ë©´ ë°˜í™˜
            if hasattr(self, '_economic_calendar_cache'):
                cached_data = self._economic_calendar_cache.get(cache_key)
                if cached_data and (datetime.now() - cached_data['timestamp']).total_seconds() < 600:  # 10ë¶„
                    Logger.info(f"ğŸ’¾ ìºì‹œëœ ê²½ì œ ì¼ì • ë°ì´í„° ì‚¬ìš© (ê²½ê³¼: {(datetime.now() - cached_data['timestamp']).total_seconds():.0f}ì´ˆ)")
                    return cached_data['data']
            else:
                self._economic_calendar_cache = {}

            # ì˜¤ëŠ˜ë¶€í„° ì§€ì •ëœ ì¼ìˆ˜ í›„ê¹Œì§€ì˜ ë‚ ì§œ ê³„ì‚° (ìµœëŒ€ 90ì¼)
            today = datetime.now()
            end_date = today.replace(day=today.day + min(days, 90))
            
            from_date = today.strftime("%Y-%m-%d")
            to_date = end_date.strftime("%Y-%m-%d")

            Logger.info(f"ğŸŒ FMP API í˜¸ì¶œ ì¤€ë¹„: from={from_date}, to={to_date}")

            # FMP API í˜¸ì¶œ (ê³µì‹ ì˜ˆì‹œì™€ ë™ì¼í•œ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
            url = "https://financialmodelingprep.com/api/v3/economic_calendar"
            params = {
                "from": from_date,
                "to": to_date,
                "apikey": fmp_api_key
            }

            Logger.info(f"ğŸŒ FMP API í˜¸ì¶œ: {url}")
            Logger.info(f"ğŸ“‹ íŒŒë¼ë¯¸í„°: {params}")

            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params, timeout=30) as resp:
                    Logger.info(f"ğŸ“¡ FMP API ì‘ë‹µ ìƒíƒœ: {resp.status}")
                    Logger.info(f"ğŸ“¡ FMP API ì‘ë‹µ í—¤ë”: {dict(resp.headers)}")
                    
                    if resp.status == 429:
                        Logger.warn("âš ï¸ FMP API ë ˆì´íŠ¸ ë¦¬ë°‹ ë„ë‹¬ - ìºì‹œëœ ë°ì´í„° ë˜ëŠ” ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
                        # ìºì‹œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë°˜í™˜, ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„°
                        if hasattr(self, '_economic_calendar_cache') and self._economic_calendar_cache.get(cache_key):
                            return self._economic_calendar_cache[cache_key]['data']
                        return self._get_dummy_events(days)
                    
                    if resp.status != 200:
                        error_text = await resp.text()
                        Logger.error(f"ğŸ”´ FMP API í˜¸ì¶œ ì‹¤íŒ¨: status={resp.status}, body={error_text}")
                        raise Exception(f"FMP API í˜¸ì¶œ ì‹¤íŒ¨: {resp.status}")
                    
                    data = await resp.json()
                    Logger.info(f"ğŸ“¥ FMP API ì‘ë‹µ ë°ì´í„° íƒ€ì…: {type(data)}")
                    Logger.info(f"ğŸ“¥ FMP API ì‘ë‹µ ë°ì´í„° ê¸¸ì´: {len(data) if isinstance(data, list) else 'not list'}")
                    
                    if isinstance(data, list) and len(data) > 0:
                        Logger.info(f"ğŸ“¥ FMP API ì²« ë²ˆì§¸ í•­ëª©: {data[0]}")
                    
                    if not isinstance(data, list):
                        Logger.warn("âš ï¸ FMP API ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜ - ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
                        return self._get_dummy_events(days)
                    
                    # FMP API ì‘ë‹µì„ ìš°ë¦¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì •í™•í•œ í•„ë“œëª… ì‚¬ìš©)
                    events = []
                    for item in data:
                        try:
                            Logger.debug(f"ğŸ” FMP API í•­ëª© íŒŒì‹±: {item}")
                            
                            # ë‚ ì§œ íŒŒì‹± - ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
                            raw_date = item.get("date", "")
                            Logger.debug(f"ğŸ“… ì›ë³¸ ë‚ ì§œ: {raw_date}")
                            
                            event_date = None
                            if raw_date:
                                try:
                                    # "2024-12-18 09:30:00" í˜•ì‹
                                    if " " in raw_date:
                                        event_date = datetime.strptime(raw_date, "%Y-%m-%d %H:%M:%S")
                                    # "2024-12-18" í˜•ì‹
                                    elif "-" in raw_date:
                                        event_date = datetime.strptime(raw_date, "%Y-%m-%d")
                                    else:
                                        Logger.warn(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë‚ ì§œ í˜•ì‹: {raw_date}")
                                        continue
                                except Exception as e:
                                    Logger.warn(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {raw_date}, ì—ëŸ¬: {e}")
                                    continue
                            
                            if not event_date:
                                Logger.warn(f"âš ï¸ ìœ íš¨í•œ ë‚ ì§œ ì—†ìŒ: {raw_date}")
                                continue
                            
                            # í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (UTC+9)
                            event_date = event_date.replace(tzinfo=None)  # timezone ì •ë³´ ì œê±°
                            
                            event = {
                                "date": event_date.strftime("%mì›” %dì¼"),
                                "time": event_date.strftime("%H:%M"),
                                "country": self._get_country_name(item.get("country", "")),
                                "event": item.get("event", "ê²½ì œ ì§€í‘œ"),
                                "impact": self._get_impact_level(item.get("impact", "")),
                                "previous": str(item.get("previous", "N/A")),
                                "forecast": str(item.get("estimate", "N/A")),  # estimate í•„ë“œ ì‚¬ìš©
                                "actual": str(item.get("actual", "")) if item.get("actual") is not None else None,
                                "currency": item.get("currency", ""),
                                "change": str(item.get("change", "N/A")) if item.get("change") is not None else "N/A",
                                "changePercentage": str(item.get("changePercentage", "N/A")) if item.get("changePercentage") is not None else "N/A"
                            }
                            
                            Logger.debug(f"âœ… ë³€í™˜ëœ ì´ë²¤íŠ¸: {event}")
                            events.append(event)
                            
                        except Exception as e:
                            Logger.warn(f"âš ï¸ ì´ë²¤íŠ¸ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}, item={item}")
                            continue

                    Logger.info(f"âœ… FMP API ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {len(events)}ê°œ ì´ë²¤íŠ¸")

                    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (High > Medium > Low)
                    impact_order = {"High": 3, "Medium": 2, "Low": 1}
                    events.sort(key=lambda x: impact_order.get(x["impact"], 0), reverse=True)
                    
                    # ìµœëŒ€ 8ê°œ ì´ë²¤íŠ¸ë§Œ ë°˜í™˜
                    limited_events = events[:8]
                    Logger.info(f"ğŸ¯ ìµœì¢… ì´ë²¤íŠ¸: {len(limited_events)}ê°œ (ì •ë ¬ ë° ì œí•œ ì ìš©)")
                    
                    # ìºì‹œì— ì €ì¥
                    self._economic_calendar_cache[cache_key] = {
                        'data': limited_events,
                        'timestamp': datetime.now()
                    }
                    Logger.info(f"ğŸ’¾ ê²½ì œ ì¼ì • ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ")
                    
                    return limited_events

        except Exception as e:
            Logger.error(f"ğŸ”¥ FMP API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ìºì‹œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë°˜í™˜
            if hasattr(self, '_economic_calendar_cache') and self._economic_calendar_cache.get(cache_key):
                Logger.info(f"ğŸ’¾ ì—ëŸ¬ ë°œìƒìœ¼ë¡œ ìºì‹œëœ ë°ì´í„° ë°˜í™˜")
                return self._economic_calendar_cache[cache_key]['data']
            raise e

    def _get_country_name(self, country_code: str) -> str:
        """êµ­ê°€ ì½”ë“œë¥¼ í•œêµ­ì–´ êµ­ê°€ëª…ìœ¼ë¡œ ë³€í™˜"""
        country_names = {
            "US": "ë¯¸êµ­",
            "JP": "ì¼ë³¸", 
            "CN": "ì¤‘êµ­",
            "KR": "í•œêµ­",
            "EU": "ìœ ëŸ½ì—°í•©",
            "GB": "ì˜êµ­",
            "DE": "ë…ì¼",
            "FR": "í”„ë‘ìŠ¤",
            "CA": "ìºë‚˜ë‹¤",
            "AU": "í˜¸ì£¼"
        }
        return country_names.get(country_code, country_code)

    def _get_impact_level(self, impact: str) -> str:
        """FMP APIì˜ impact ê°’ì„ ìš°ë¦¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not impact:
            return "Low"
        
        impact_lower = impact.lower()
        if "high" in impact_lower or "ë†’ìŒ" in impact_lower:
            return "High"
        elif "medium" in impact_lower or "ë³´í†µ" in impact_lower:
            return "Medium"
        else:
            return "Low"

    def _get_dummy_events(self, days: int) -> list:
        """ë”ë¯¸ ê²½ì œ ì¼ì • ë°ì´í„° ìƒì„± (í˜„ì¬ ë‚ ì§œ ê¸°ì¤€)"""
        today = datetime.now()
        events = []
        
        # ì£¼ìš” ê²½ì œ ì§€í‘œë“¤
        indicators = [
            {"name": "ë¹„ë†ì—… ê³ ìš©ì§€í‘œ", "country": "ë¯¸êµ­", "impact": "High", "previous": "187K", "forecast": "180K"},
            {"name": "ISM ì œì¡°ì—… ì§€ìˆ˜", "country": "ë¯¸êµ­", "impact": "Medium", "previous": "49.0", "forecast": "49.5"},
            {"name": "ì†Œë¹„ì ë¬¼ê°€ì§€ìˆ˜(CPI)", "country": "ë¯¸êµ­", "impact": "High", "previous": "3.2%", "forecast": "3.1%"},
            {"name": "ì—°ë°©ê¸°ê¸ˆ ê¸ˆë¦¬", "country": "ë¯¸êµ­", "impact": "High", "previous": "5.50%", "forecast": "5.50%"},
            {"name": "ì†Œë§¤ íŒë§¤", "country": "ë¯¸êµ­", "impact": "Medium", "previous": "0.3%", "forecast": "0.2%"},
            {"name": "ì£¼íƒ íŒë§¤", "country": "ë¯¸êµ­", "impact": "Low", "previous": "6.5M", "forecast": "6.6M"},
            {"name": "GDP ì„±ì¥ë¥ ", "country": "ë¯¸êµ­", "impact": "High", "previous": "2.1%", "forecast": "2.0%"},
            {"name": "ê¸°ì—… ìˆ˜ìµ", "country": "ë¯¸êµ­", "impact": "Medium", "previous": "N/A", "forecast": "N/A"}
        ]
        
        for i, indicator in enumerate(indicators[:8]):  # ìµœëŒ€ 8ê°œ
            # ì˜¤ëŠ˜ë¶€í„° iì¼ í›„
            event_date = today + timedelta(days=i)
            
            event = {
                "date": event_date.strftime("%mì›” %dì¼"),
                "time": "09:30" if i % 2 == 0 else "14:00",  # ë²ˆê°ˆì•„ê°€ë©° ì‹œê°„ ì„¤ì •
                "country": indicator["country"],
                "event": indicator["name"],
                "impact": indicator["impact"],
                "previous": indicator["previous"],
                "forecast": indicator["forecast"],
                "actual": None,  # ë”ë¯¸ ë°ì´í„°ëŠ” ì‹¤ì œê°’ ì—†ìŒ
                "currency": "USD",
                "change": "N/A",
                "changePercentage": "N/A"
            }
            events.append(event)
        
        Logger.info(f"ğŸ­ ë”ë¯¸ ê²½ì œ ì¼ì • ë°ì´í„° ìƒì„±: {len(events)}ê°œ (í˜„ì¬ ë‚ ì§œ ê¸°ì¤€)")
        return events

    async def _fetch_fmp_market_risk_premiums(self, fmp_api_key: str, countries: List[str]) -> list:
        """FMP APIì—ì„œ ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            Logger.info(f"ğŸŒ FMP ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ API í˜¸ì¶œ ì¤€ë¹„")

            # FMP API í˜¸ì¶œ
            url = "https://financialmodelingprep.com/stable/market-risk-premium"
            params = {
                "apikey": fmp_api_key
            }

            Logger.info(f"ğŸŒ FMP API í˜¸ì¶œ: {url}")

            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params, timeout=30) as resp:
                    Logger.info(f"ğŸ“¡ FMP API ì‘ë‹µ ìƒíƒœ: {resp.status}")
                    
                    if resp.status == 429:
                        Logger.warn("âš ï¸ FMP API ë ˆì´íŠ¸ ë¦¬ë°‹ ë„ë‹¬ - ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
                        return self._get_dummy_market_risk_premiums(countries)
                    
                    if resp.status != 200:
                        error_text = await resp.text()
                        Logger.error(f"ğŸ”´ FMP API í˜¸ì¶œ ì‹¤íŒ¨: status={resp.status}, body={error_text}")
                        raise Exception(f"FMP API í˜¸ì¶œ ì‹¤íŒ¨: {resp.status}")
                    
                    data = await resp.json()
                    Logger.info(f"ğŸ“¥ FMP API ì‘ë‹µ ë°ì´í„°: {len(data) if isinstance(data, list) else 'not list'}ê°œ í•­ëª©")
                    
                    if not isinstance(data, list):
                        Logger.warn("âš ï¸ FMP API ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜ - ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
                        return self._get_dummy_market_risk_premiums(countries)
                    
                    # ìš”ì²­ëœ êµ­ê°€ë“¤ë§Œ í•„í„°ë§
                    filtered_premiums = []
                    for item in data:
                        country_code = item.get("country", "")
                        if country_code in countries:
                            premium = {
                                "country": self._get_country_name(country_code),
                                "countryCode": country_code,
                                "continent": item.get("continent", ""),
                                "countryRiskPremium": round(float(item.get("countryRiskPremium", 0)), 2),
                                "totalEquityRiskPremium": round(float(item.get("totalEquityRiskPremium", 0)), 2)
                            }
                            filtered_premiums.append(premium)
                    
                    Logger.info(f"âœ… FMP API ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {len(filtered_premiums)}ê°œ êµ­ê°€")
                    return filtered_premiums

        except Exception as e:
            Logger.error(f"ğŸ”¥ FMP API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise e

    def _get_dummy_market_risk_premiums(self, countries: List[str]) -> list:
        """ë”ë¯¸ ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ë°ì´í„° ìƒì„±"""
        dummy_data = {
            "US": {"countryRiskPremium": 0.0, "totalEquityRiskPremium": 4.6},
            "KR": {"countryRiskPremium": 1.2, "totalEquityRiskPremium": 5.8},
            "JP": {"countryRiskPremium": 0.8, "totalEquityRiskPremium": 5.4},
            "CN": {"countryRiskPremium": 1.5, "totalEquityRiskPremium": 6.1},
            "EU": {"countryRiskPremium": 0.5, "totalEquityRiskPremium": 5.1}
        }
        
        premiums = []
        for country_code in countries:
            if country_code in dummy_data:
                premium = {
                    "country": self._get_country_name(country_code),
                    "countryCode": country_code,
                    "continent": "Asia" if country_code in ["KR", "JP", "CN"] else "North America" if country_code == "US" else "Europe",
                    "countryRiskPremium": dummy_data[country_code]["countryRiskPremium"],
                    "totalEquityRiskPremium": dummy_data[country_code]["totalEquityRiskPremium"]
                }
                premiums.append(premium)
        
        Logger.info(f"ğŸ­ ë”ë¯¸ ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ë°ì´í„° ìƒì„±: {len(premiums)}ê°œ êµ­ê°€")
        return premiums
