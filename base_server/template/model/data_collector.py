"""
ë¯¸êµ­ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ
yfinanceë¥¼ ì‚¬ìš©í•´ ê±°ë˜ëŸ‰ ìƒìœ„ 100ê°œ ì¢…ëª©ì˜ 3ë…„ì¹˜ OHLCV ë°ì´í„° ìˆ˜ì§‘
User-Agent í—¤ë”ì™€ ì§€ì—°ì‹œê°„ì„ ì¶”ê°€í•˜ì—¬ Rate Limiting ë°©ì§€
"""

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import requests
import random

class StockDataCollector:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # User-Agent í—¤ë” ì„¤ì • (ë¸Œë¼ìš°ì €ë¡œ ìœ„ì¥í•˜ì—¬ Rate Limiting ë°©ì§€)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Referer': 'https://finance.yahoo.com/',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
        }
        
        # requests ì„¸ì…˜ ì„¤ì • (ì§ì ‘ API í˜¸ì¶œìš©)
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
        # yfinance ì„¸ì…˜ ì„¤ì • (429 ì˜¤ë¥˜ ë°©ì§€)
        import yfinance as yf
        yf.pdr_override()  # pandas_datareader override
        
        # ìš”ì²­ ê°„ ì§€ì—°ì‹œê°„ ì„¤ì • (ì´ˆ) - 429 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì¦ê°€
        self.request_delay = (2.0, 4.0)  # 2-4ì´ˆ ëœë¤ ì§€ì—° (ê¸°ì¡´ 0.5-1.5ì´ˆì—ì„œ ì¦ê°€)
        self.retry_attempts = 5  # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€ (ê¸°ì¡´ 3íšŒì—ì„œ 5íšŒ)
        self.max_concurrent_requests = 1  # ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (ìˆœì°¨ ì²˜ë¦¬)
        
        # ë¯¸êµ­ ì£¼ì‹ ê±°ë˜ëŸ‰ ìƒìœ„ 100ê°œ ì¢…ëª© (ì˜ˆì‹œ - ì‹¤ì œë¡œëŠ” ë™ì ìœ¼ë¡œ ê°€ì ¸ì™€ì•¼ í•¨)
        self.top_100_symbols = [
            "AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "TSLA", "META", "NFLX", "AMD", "INTC",
            "ADBE", "CRM", "PYPL", "AVGO", "TXN", "QCOM", "COST", "SBUX", "INTU", "AMGN",
            "GILD", "MDLZ", "BKNG", "ADP", "VRTX", "FISV", "CSX", "REGN", "ATVI", "MELI",
            "ASML", "MU", "AMAT", "LRCX", "ADI", "MCHP", "KLAC", "SNPS", "CDNS", "PDD",
            "ORLY", "CTAS", "FAST", "PAYX", "VRSK", "DXCM", "BIIB", "ILMN", "WDAY", "EXC",
            "EA", "CTSH", "DLTR", "KDP", "CRWD", "ZM", "TEAM", "OKTA", "DDOG", "SNOW",
            "NET", "TWLO", "ZS", "PLTR", "U", "RBLX", "PATH", "COIN", "HOOD", "AFRM",
            "SQ", "SHOP", "UBER", "LYFT", "DASH", "ABNB", "PINS", "SNAP", "SPOT", "ZG",
            "ETSY", "ROKU", "NTNX", "FSLY", "ESTC", "MDB", "VEEV", "CZR", "TTWO", "WDC",
            "STX", "SWKS", "MRVL", "ON", "MPWR", "ENTG", "TER", "ALGN", "IDXX", "ANSS"
        ]
    
    def _add_request_delay(self):
        """ìš”ì²­ ê°„ ëœë¤ ì§€ì—°ì‹œê°„ ì¶”ê°€"""
        delay = random.uniform(*self.request_delay)
        time.sleep(delay)
    
    def get_stock_data(self, symbol: str, period: str = "3y") -> Optional[pd.DataFrame]:
        """
        íŠ¹ì • ì¢…ëª©ì˜ OHLCV ë°ì´í„° ìˆ˜ì§‘ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            symbol: ì£¼ì‹ ì‹¬ë³¼ (e.g., "AAPL")
            period: ë°ì´í„° ê¸°ê°„ ("3y" = 3ë…„)
            
        Returns:
            pandas DataFrame with OHLCV data
        """
        for attempt in range(self.retry_attempts):
            try:
                # ìš”ì²­ ì „ ì§€ì—°ì‹œê°„ ì¶”ê°€
                if attempt > 0:
                    self.logger.info(f"Retrying {symbol} (attempt {attempt + 1}/{self.retry_attempts})")
                    # ì¬ì‹œë„ ì‹œ ë” ê¸´ ì§€ì—°ì‹œê°„
                    time.sleep(random.uniform(2, 5))
                else:
                    self._add_request_delay()
                
                stock = yf.Ticker(symbol)
                data = stock.history(period=period)
                
                if data.empty:
                    self.logger.warning(f"No data found for symbol: {symbol}")
                    return None
                
                # ì‹¤ì œ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸ ë° ë¡œê·¸
                self.logger.info(f"Original columns for {symbol}: {list(data.columns)}")
                
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (OHLCV)
                required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
                
                # ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì„ íƒ
                available_columns = [col for col in required_columns if col in data.columns]
                if len(available_columns) < 5:
                    self.logger.error(f"Missing required columns for {symbol}. Available: {available_columns}")
                    return None
                
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                data = data[available_columns].copy()
                data['Symbol'] = symbol
                data.reset_index(inplace=True)
                
                self.logger.info(f"âœ… Successfully collected data for {symbol}: {len(data)} records")
                return data
                
            except Exception as e:
                error_msg = str(e).lower()
                if "429" in error_msg or "too many requests" in error_msg or "expecting value" in error_msg:
                    # 429 ì˜¤ë¥˜ ì‹œ exponential backoff ì ìš©
                    backoff_time = min(60, (2 ** attempt) * 5)  # 5, 10, 20, 40, 60ì´ˆ
                    self.logger.warning(f"ğŸš¨ Rate limit hit for {symbol}, attempt {attempt + 1}/{self.retry_attempts}")
                    self.logger.info(f"â±ï¸ Applying exponential backoff: waiting {backoff_time}s")
                    time.sleep(backoff_time)
                    
                    if attempt == self.retry_attempts - 1:
                        self.logger.error(f"âŒ Rate limit exceeded for {symbol} after {self.retry_attempts} attempts")
                        return None
                else:
                    self.logger.error(f"âŒ Error collecting data for {symbol}: {str(e)}")
                    if attempt == self.retry_attempts - 1:
                        return None
        
        return None
    
    def get_recent_data(self, symbol: str, days: int = 60) -> Optional[pd.DataFrame]:
        """
        íŠ¹ì • ì¢…ëª©ì˜ ìµœê·¼ Nì¼ ë°ì´í„° ìˆ˜ì§‘ (ì¶”ë¡ ìš©, ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            symbol: ì£¼ì‹ ì‹¬ë³¼
            days: ìˆ˜ì§‘í•  ì¼ìˆ˜ (ê¸°ë³¸ 60ì¼)
            
        Returns:
            pandas DataFrame with recent OHLCV data
        """
        for attempt in range(self.retry_attempts):
            try:
                # ìš”ì²­ ì „ ì§€ì—°ì‹œê°„ ì¶”ê°€
                if attempt > 0:
                    self.logger.info(f"Retrying recent data for {symbol} (attempt {attempt + 1}/{self.retry_attempts})")
                    time.sleep(random.uniform(2, 5))
                else:
                    self._add_request_delay()
                
                end_date = datetime.now()
                start_date = end_date - timedelta(days=days + 10)  # ì—¬ìœ ë¶„ ì¶”ê°€
                
                stock = yf.Ticker(symbol)
                data = stock.history(start=start_date, end=end_date)
                
                if data.empty:
                    self.logger.warning(f"No recent data found for symbol: {symbol}")
                    return None
                
                # ì‹¤ì œ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸ ë° ë¡œê·¸
                self.logger.info(f"Original columns for {symbol}: {list(data.columns)}")
                
                # ìµœê·¼ Nì¼ë§Œ ì„ íƒ
                data = data.tail(days)
                
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (OHLCV)
                required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
                
                # ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì„ íƒ
                available_columns = [col for col in required_columns if col in data.columns]
                if len(available_columns) < 5:
                    self.logger.error(f"Missing required columns for {symbol}. Available: {available_columns}")
                    return None
                
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                data = data[available_columns].copy()
                data['Symbol'] = symbol
                data.reset_index(inplace=True)
                
                self.logger.info(f"âœ… Successfully collected recent data for {symbol}: {len(data)} records")
                return data
                
            except Exception as e:
                error_msg = str(e).lower()
                if "429" in error_msg or "too many requests" in error_msg:
                    self.logger.warning(f"Rate limit hit for recent data {symbol}, attempt {attempt + 1}/{self.retry_attempts}")
                    if attempt == self.retry_attempts - 1:
                        self.logger.error(f"âŒ Rate limit exceeded for recent data {symbol} after {self.retry_attempts} attempts")
                        return None
                else:
                    self.logger.error(f"âŒ Error collecting recent data for {symbol}: {str(e)}")
                    if attempt == self.retry_attempts - 1:
                        return None
        
        return None
    
    def collect_batch_data(self, symbols: List[str], max_workers: int = 1) -> Dict[str, pd.DataFrame]:
        """
        ì—¬ëŸ¬ ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜ì§‘ (429 ì˜¤ë¥˜ ë°©ì§€)
        
        Args:
            symbols: ìˆ˜ì§‘í•  ì¢…ëª© ë¦¬ìŠ¤íŠ¸
            max_workers: ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (ìˆœì°¨ ì²˜ë¦¬ë¡œ ë³€ê²½)
            
        Returns:
            Dict[symbol, DataFrame]
        """
        results = {}
        
        self.logger.info(f"ğŸ”„ Starting sequential collection for {len(symbols)} symbols (429 ì˜¤ë¥˜ ë°©ì§€)")
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì œê±° â†’ ìˆœì°¨ ì²˜ë¦¬ë¡œ ë³€ê²½ (429 ì˜¤ë¥˜ ë°©ì§€)
        for i, symbol in enumerate(symbols):
            self.logger.info(f"ğŸ“Š Processing {symbol} ({i+1}/{len(symbols)})")
            
            try:
                data = self.get_stock_data(symbol)
                if data is not None:
                    results[symbol] = data
                    self.logger.info(f"âœ… Success: {symbol} - Shape: {data.shape}")
                else:
                    self.logger.warning(f"âŒ Failed to collect data for {symbol}")
                    
            except Exception as e:
                self.logger.error(f"âŒ Exception collecting {symbol}: {str(e)}")
            
            # ê° ìš”ì²­ í›„ ì§€ì—°ì‹œê°„ ì¶”ê°€ (429 ì˜¤ë¥˜ ë°©ì§€)
            if i < len(symbols) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´
                delay = random.uniform(*self.request_delay)
                self.logger.info(f"â±ï¸ Waiting {delay:.1f}s before next request...")
                time.sleep(delay)
        
        success_rate = len(results) / len(symbols) * 100 if symbols else 0
        self.logger.info(f"ğŸ¯ Sequential collection completed: {len(results)}/{len(symbols)} symbols ({success_rate:.1f}% success rate)")
        return results
    
    def collect_top_100_data(self) -> Dict[str, pd.DataFrame]:
        """
        ê±°ë˜ëŸ‰ ìƒìœ„ 100ê°œ ì¢…ëª©ì˜ 3ë…„ì¹˜ ë°ì´í„° ìˆ˜ì§‘ (Rate Limiting ìµœì í™”)
        
        Returns:
            Dict[symbol, DataFrame]
        """
        self.logger.info("ğŸš€ Starting collection of top 100 stocks data with rate limiting protection...")
        
        # ë°°ì¹˜ë³„ë¡œ ìˆ˜ì§‘ (API ì œí•œ ê³ ë ¤í•˜ì—¬ ì‘ì€ ë°°ì¹˜ í¬ê¸°)
        batch_size = 10  # 20 â†’ 10ìœ¼ë¡œ ì¶•ì†Œ
        all_results = {}
        total_batches = (len(self.top_100_symbols) + batch_size - 1) // batch_size
        
        for i in range(0, len(self.top_100_symbols), batch_size):
            batch_num = i // batch_size + 1
            batch_symbols = self.top_100_symbols[i:i+batch_size]
            
            self.logger.info(f"ğŸ“¦ Collecting batch {batch_num}/{total_batches}: {batch_symbols}")
            
            batch_results = self.collect_batch_data(batch_symbols, max_workers=2)  # worker ìˆ˜ë„ ì¤„ì„
            all_results.update(batch_results)
            
            # ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„ ì¦ê°€ (Rate Limiting ë°©ì§€)
            if i + batch_size < len(self.top_100_symbols):  # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ì•„ë‹ˆë©´
                wait_time = random.uniform(3, 7)  # 3-7ì´ˆ ëœë¤ ëŒ€ê¸°
                self.logger.info(f"â³ Waiting {wait_time:.1f} seconds before next batch...")
                time.sleep(wait_time)
        
        success_rate = len(all_results) / len(self.top_100_symbols) * 100
        self.logger.info(f"ğŸ‰ Completed data collection: {len(all_results)}/{len(self.top_100_symbols)} symbols ({success_rate:.1f}% success rate)")
        return all_results
    
    def save_data_to_csv(self, data_dict: Dict[str, pd.DataFrame], output_dir: str = "data"):
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            data_dict: ì¢…ëª©ë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            output_dir: ì €ì¥ ë””ë ‰í† ë¦¬
        """
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        # ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ì €ì¥
        all_data = []
        for symbol, df in data_dict.items():
            all_data.append(df)
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            output_file = os.path.join(output_dir, "stock_data_3y.csv")
            combined_df.to_csv(output_file, index=False)
            self.logger.info(f"Saved combined data to {output_file}: {len(combined_df)} records")
            
            # ê° ì¢…ëª©ë³„ë¡œë„ ì €ì¥
            for symbol, df in data_dict.items():
                symbol_file = os.path.join(output_dir, f"{symbol}_3y.csv")
                df.to_csv(symbol_file, index=False)
        
        self.logger.info(f"Data saved to {output_dir} directory")


def quick_column_test():
    """ë¹ ë¥¸ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸ í…ŒìŠ¤íŠ¸"""
    import yfinance as yf
    
    print("ğŸ” Quick column structure test...")
    
    try:
        # yfinance ê¸°ë³¸ ë™ì‘ ì‚¬ìš© (ì„¸ì…˜ ì„¤ì • ì—†ìŒ)
        ticker = yf.Ticker("AAPL")
        data = ticker.history(period="5d")
        
        print(f"âœ… Data shape: {data.shape}")
        print(f"âœ… Columns: {list(data.columns)}")
        print(f"âœ… Index: {data.index.name}")
        print("âœ… Sample data:")
        print(data.head(2))
        return True
        
    except Exception as e:
        print(f"âŒ Quick test failed: {e}")
        print("ğŸ”§ Trying to install curl_cffi...")
        
        # curl_cffi ì„¤ì¹˜ ì‹œë„
        import subprocess
        import sys
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "curl_cffi"])
            print("âœ… curl_cffi installed, retrying...")
            
            # ì¬ì‹œë„
            ticker = yf.Ticker("AAPL")
            data = ticker.history(period="5d")
            
            print(f"âœ… Data shape: {data.shape}")
            print(f"âœ… Columns: {list(data.columns)}")
            return True
            
        except Exception as e2:
            print(f"âŒ Still failed after curl_cffi install: {e2}")
            return False

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ë¹ ë¥¸ ì»¬ëŸ¼ í…ŒìŠ¤íŠ¸ ë¨¼ì €
    if not quick_column_test():
        print("âŒ Column test failed, exiting...")
        exit(1)
    
    print("\n" + "="*50)
    
    # ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    collector = StockDataCollector()
    
    print("ğŸ§ª Testing data collection with rate limiting protection...")
    
    # í…ŒìŠ¤íŠ¸ìš© ì†Œìˆ˜ ì¢…ëª© ë¨¼ì € ì‹œë„
    test_symbols = ["AAPL", "MSFT", "GOOGL"]
    print(f"Testing with symbols: {test_symbols}")
    
    # ë‹¨ì¼ ì¢…ëª© í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ Single symbol test:")
    test_data = collector.get_recent_data("AAPL", 10)
    if test_data is not None:
        print(f"âœ… Single test passed: {len(test_data)} records for AAPL")
        print("Data columns:", list(test_data.columns))
        print(test_data.head(3))
    else:
        print("âŒ Single test failed")
        exit(1)
    
    # ì†Œê·œëª¨ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
    print(f"\n2ï¸âƒ£ Small batch test:")
    test_batch_data = collector.collect_batch_data(test_symbols)
    if test_batch_data:
        print(f"âœ… Batch test passed: {len(test_batch_data)} symbols collected")
        for symbol, df in test_batch_data.items():
            print(f"  - {symbol}: {len(df)} records")
    else:
        print("âŒ Batch test failed")
        exit(1)
    
    # ì‚¬ìš©ì ì„ íƒ
    print(f"\n3ï¸âƒ£ Options:")
    print("A. Collect all top 100 stocks (will take 30-60 minutes)")
    print("B. Collect test data only and proceed to next step")
    print("C. Exit")
    
    choice = input("Choose option (A/B/C): ").upper()
    
    if choice == "A":
        print("ğŸš€ Starting full data collection...")
        data = collector.collect_top_100_data()
        collector.save_data_to_csv(data)
        print(f"âœ… Data collection completed for {len(data)} symbols")
    elif choice == "B":
        print("ğŸ“Š Saving test data...")
        collector.save_data_to_csv(test_batch_data)
        print("âœ… Test data saved. You can now proceed to model training!")
    else:
        print("ğŸ‘‹ Exiting...")
        exit(0)