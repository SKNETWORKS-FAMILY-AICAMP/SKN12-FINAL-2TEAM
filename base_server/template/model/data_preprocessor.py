"""
ì£¼ì‹ ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ
OHLCV ë°ì´í„°ì—ì„œ MA(5,20,60)ì™€ Bollinger Band ê³„ì‚°
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import logging
from sklearn.preprocessing import MinMaxScaler
import warnings
warnings.filterwarnings('ignore')

# ğŸš€ ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ import
from advanced_features import AdvancedFeatureEngineering

class StockDataPreprocessor:
    def __init__(self, use_log_transform: bool = True):
        self.logger = logging.getLogger(__name__)
        
        # ğŸ”§ ë¡œê·¸ ë³€í™˜ ì„¤ì • (2ë‹¨ê³„ í•´ê²°ì±…)
        self.use_log_transform = use_log_transform
        self.price_columns = ['Open', 'High', 'Low', 'Close']  # ë¡œê·¸ ë³€í™˜ ëŒ€ìƒ ì»¬ëŸ¼
        self.ma_columns = ['MA_5', 'MA_20', 'MA_60']  # ì´ë™í‰ê· ë„ ë¡œê·¸ ë³€í™˜ ëŒ€ìƒ
        self.bb_price_columns = ['BB_Upper', 'BB_Middle', 'BB_Lower']  # ë³¼ë¦°ì € ë°´ë“œë„ ë¡œê·¸ ë³€í™˜ ëŒ€ìƒ
        
        # í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì¼€ì¼ëŸ¬ ì‹œìŠ¤í…œ
        self.global_scaler = MinMaxScaler()      # ì „ì—­ í”¼ì²˜ ìŠ¤ì¼€ì¼ëŸ¬ (fallbackìš©)
        self.global_target_scaler = MinMaxScaler()  # ì „ì—­ íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ (fallbackìš©)
        self.symbol_scalers = {}  # ì¢…ëª©ë³„ ê°œë³„ í”¼ì²˜ ìŠ¤ì¼€ì¼ëŸ¬ (ìš°ì„  ì‚¬ìš©)
        self.target_scalers = {}  # ì¢…ëª©ë³„ ê°œë³„ íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ (ìš°ì„  ì‚¬ìš©)
        
        # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ìŠ¤ì¼€ì¼ëŸ¬ (ì‚¬ìš© ì•ˆí•¨)
        self.scaler = MinMaxScaler()
        
        # ğŸš€ ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì´ˆê¸°í™”
        self.advanced_features = AdvancedFeatureEngineering()
        self.advanced_features_enabled = False  # ê¸°ë³¸ê°’: ë¹„í™œì„±í™” (í˜¸í™˜ì„±)
        
        if self.use_log_transform:
            self.logger.info("Log transformation enabled for price scaling")
    
    # ============================================================================
    # ë¡œê·¸ ë³€í™˜ í•¨ìˆ˜ë“¤ (2ë‹¨ê³„ í•´ê²°ì±…)
    # ============================================================================
    
    def apply_log_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ê°€ê²© ê´€ë ¨ ì»¬ëŸ¼ì— ë¡œê·¸ ë³€í™˜ ì ìš©
        
        Args:
            df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            ë¡œê·¸ ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„
        """
        if not self.use_log_transform:
            return df
        
        df_transformed = df.copy()
        
        # ê°€ê²© ì»¬ëŸ¼ë“¤ì— ë¡œê·¸ ë³€í™˜ ì ìš© (ì‘ì€ ê°’ ì²˜ë¦¬ë¥¼ ìœ„í•´ +1)
        for col in self.price_columns:
            if col in df_transformed.columns:
                df_transformed[col] = np.log(df_transformed[col] + 1)
        
        # ì´ë™í‰ê·  ì»¬ëŸ¼ë“¤ì—ë„ ë¡œê·¸ ë³€í™˜ ì ìš©
        for col in self.ma_columns:
            if col in df_transformed.columns:
                df_transformed[col] = np.log(df_transformed[col] + 1)
        
        # ë³¼ë¦°ì € ë°´ë“œ ì»¬ëŸ¼ë“¤ì—ë„ ë¡œê·¸ ë³€í™˜ ì ìš©
        for col in self.bb_price_columns:
            if col in df_transformed.columns:
                df_transformed[col] = np.log(df_transformed[col] + 1)
        
        self.logger.info(f"Applied log transformation to price columns")
        return df_transformed
    
    def apply_inverse_log_transform(self, values: np.ndarray, is_price_data: bool = True) -> np.ndarray:
        """
        ë¡œê·¸ ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜
        
        Args:
            values: ë¡œê·¸ ë³€í™˜ëœ ê°’ë“¤
            is_price_data: ê°€ê²© ë°ì´í„° ì—¬ë¶€ (ê°€ê²©ì´ ì•„ë‹Œ ë°ì´í„°ëŠ” ì—­ë³€í™˜í•˜ì§€ ì•ŠìŒ)
            
        Returns:
            ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³µì›ëœ ê°’ë“¤
        """
        if not self.use_log_transform or not is_price_data:
            return values
        
        # exp ë³€í™˜ í›„ -1 (log(x+1)ì˜ ì—­ë³€í™˜)
        restored_values = np.exp(values) - 1
        
        # ìŒìˆ˜ê°’ ë³´ì • (ê°€ê²©ì€ í•­ìƒ ì–‘ìˆ˜ì—¬ì•¼ í•¨)
        restored_values = np.maximum(restored_values, 0.01)
        
        self.logger.debug(f"Applied inverse log transformation")
        return restored_values
    
    def log_transform_single_value(self, value: float) -> float:
        """ë‹¨ì¼ ê°’ì— ë¡œê·¸ ë³€í™˜ ì ìš©"""
        if not self.use_log_transform:
            return value
        return np.log(value + 1)
    
    def inverse_log_transform_single_value(self, value: float) -> float:
        """ë‹¨ì¼ ê°’ì— ë¡œê·¸ ì—­ë³€í™˜ ì ìš©"""
        if not self.use_log_transform:
            return value
        return max(np.exp(value) - 1, 0.01)
    
    def calculate_moving_averages(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì´ë™í‰ê· ì„  ê³„ì‚° (MA 5, 20, 60)
        
        Args:
            df: OHLCV ë°ì´í„°í”„ë ˆì„
            
        Returns:
            MAê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
        """
        df_copy = df.copy()
        
        # ì´ë™í‰ê· ì„  ê³„ì‚°
        df_copy['MA_5'] = df_copy['Close'].rolling(window=5).mean()
        df_copy['MA_20'] = df_copy['Close'].rolling(window=20).mean()
        df_copy['MA_60'] = df_copy['Close'].rolling(window=60).mean()
        
        # ì´ˆê¸° NaN ê°’ ì œê±°ë¥¼ ìœ„í•´ forward fill ì‚¬ìš©
        df_copy['MA_5'] = df_copy['MA_5'].fillna(method='bfill')
        df_copy['MA_20'] = df_copy['MA_20'].fillna(method='bfill')
        df_copy['MA_60'] = df_copy['MA_60'].fillna(method='bfill')
        
        self.logger.info(f"Calculated moving averages for {len(df_copy)} records")
        return df_copy
    
    def calculate_bollinger_bands(self, df: pd.DataFrame, window: int = 20, num_std: float = 2.0) -> pd.DataFrame:
        """
        ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
        
        Args:
            df: OHLCV ë°ì´í„°í”„ë ˆì„
            window: ì´ë™í‰ê·  ìœˆë„ìš° (ê¸°ë³¸ 20ì¼)
            num_std: í‘œì¤€í¸ì°¨ ë°°ìˆ˜ (ê¸°ë³¸ 2.0)
            
        Returns:
            ë³¼ë¦°ì € ë°´ë“œê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
        """
        df_copy = df.copy()
        
        # 20ì¼ ì´ë™í‰ê·  (ì¤‘ì‹¬ì„ )
        df_copy['BB_Middle'] = df_copy['Close'].rolling(window=window).mean()
        
        # 20ì¼ ì´ë™í‘œì¤€í¸ì°¨
        rolling_std = df_copy['Close'].rolling(window=window).std()
        
        # ìƒí•œì„ ê³¼ í•˜í•œì„ 
        df_copy['BB_Upper'] = df_copy['BB_Middle'] + (rolling_std * num_std)
        df_copy['BB_Lower'] = df_copy['BB_Middle'] - (rolling_std * num_std)
        
        # %B ê³„ì‚° (í˜„ì¬ ê°€ê²©ì´ ë°´ë“œ ë‚´ì—ì„œ ì–´ë””ì— ìœ„ì¹˜í•˜ëŠ”ì§€)
        df_copy['BB_Width'] = df_copy['BB_Upper'] - df_copy['BB_Lower']
        df_copy['BB_Percent'] = (df_copy['Close'] - df_copy['BB_Lower']) / (df_copy['BB_Upper'] - df_copy['BB_Lower'])
        
        # ì´ˆê¸° NaN ê°’ ì²˜ë¦¬
        bb_columns = ['BB_Middle', 'BB_Upper', 'BB_Lower', 'BB_Width', 'BB_Percent']
        for col in bb_columns:
            df_copy[col] = df_copy[col].fillna(method='bfill')
        
        self.logger.info(f"Calculated Bollinger Bands for {len(df_copy)} records")
        return df_copy
    
    def add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ (RSI, MACD ë“±)
        
        Args:
            df: OHLCV ë°ì´í„°í”„ë ˆì„
            
        Returns:
            ê¸°ìˆ ì  ì§€í‘œê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
        """
        df_copy = df.copy()
        
        # RSI ê³„ì‚°
        df_copy['RSI'] = self.calculate_rsi(df_copy['Close'])
        
        # MACD ê³„ì‚°
        macd_data = self.calculate_macd(df_copy['Close'])
        df_copy['MACD'] = macd_data['MACD']
        df_copy['MACD_Signal'] = macd_data['Signal']
        df_copy['MACD_Histogram'] = macd_data['Histogram']
        
        # ê°€ê²© ë³€í™”ìœ¨
        df_copy['Price_Change'] = df_copy['Close'].pct_change()
        df_copy['Volume_Change'] = df_copy['Volume'].pct_change()
        
        # ë³€ë™ì„± ì§€í‘œ
        df_copy['Volatility'] = df_copy['Price_Change'].rolling(window=20).std()
        
        # NaN ê°’ ì²˜ë¦¬
        numeric_cols = df_copy.select_dtypes(include=[np.number]).columns
        df_copy[numeric_cols] = df_copy[numeric_cols].fillna(method='bfill').fillna(method='ffill')
        
        # ğŸš€ ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ì„ íƒì  í™œì„±í™”)
        if self.advanced_features_enabled:
            df_copy = self.advanced_features.add_all_advanced_features(df_copy)
            self.logger.info("ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì ìš©ë¨ (42ê°œ í”¼ì²˜ ëª¨ë“œ)")
        else:
            self.logger.info("ê¸°ë³¸ í”¼ì²˜ë§Œ ì‚¬ìš© (18ê°œ í”¼ì²˜ ëª¨ë“œ - í˜¸í™˜ì„±)")
        
        # ğŸ”§ ë¡œê·¸ ë³€í™˜ ì ìš© (2ë‹¨ê³„ í•´ê²°ì±…)
        df_copy = self.apply_log_transform(df_copy)
        
        feature_count = len(df_copy.columns)
        self.logger.info(f"âœ… Added technical indicators + advanced features: {feature_count} total features for {len(df_copy)} records")
        return df_copy
    
    def calculate_rsi(self, prices: pd.Series, window: int = 14) -> pd.Series:
        """RSI ê³„ì‚°"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Dict[str, pd.Series]:
        """MACD ê³„ì‚°"""
        exp_fast = prices.ewm(span=fast).mean()
        exp_slow = prices.ewm(span=slow).mean()
        macd = exp_fast - exp_slow
        signal_line = macd.ewm(span=signal).mean()
        histogram = macd - signal_line
        
        return {
            'MACD': macd,
            'Signal': signal_line,
            'Histogram': histogram
        }
    
    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            df: ì›ë³¸ OHLCV ë°ì´í„°í”„ë ˆì„
            
        Returns:
            ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        """
        self.logger.info(f"Starting preprocessing for {len(df)} records")
        
        # 1. ì´ë™í‰ê· ì„  ê³„ì‚°
        df_processed = self.calculate_moving_averages(df)
        
        # 2. ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
        df_processed = self.calculate_bollinger_bands(df_processed)
        
        # 3. ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
        df_processed = self.add_technical_indicators(df_processed)
        
        # 4. ë°ì´í„° ì •ë ¬ (ë‚ ì§œìˆœ)
        if 'Date' in df_processed.columns:
            df_processed = df_processed.sort_values('Date').reset_index(drop=True)
        
        self.logger.info(f"Preprocessing completed. Final shape: {df_processed.shape}")
        return df_processed
    
    def create_sequences(self, df: pd.DataFrame, symbol: str, sequence_length: int = 60, prediction_length: int = 5) -> Tuple[np.ndarray, np.ndarray]:
        """
        LSTM í•™ìŠµìš© ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± (ì¢…ëª©ë³„ ê°œë³„ ì •ê·œí™”)
        
        Args:
            df: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
            symbol: ì¢…ëª© ì‹¬ë³¼ (ê°œë³„ ì •ê·œí™”ìš©)
            sequence_length: ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ (60ì¼)
            prediction_length: ì˜ˆì¸¡ ê¸¸ì´ (5ì¼)
            
        Returns:
            (X, y) - ì…ë ¥ ì‹œí€€ìŠ¤ì™€ íƒ€ê²Ÿ ì‹œí€€ìŠ¤
        """
        # ğŸš€ í”¼ì²˜ ì„ íƒ (ê³ ê¸‰ í”¼ì²˜ í™œì„±í™” ì—¬ë¶€ì— ë”°ë¼)
        if self.advanced_features_enabled:
            # ê³ ê¸‰ í”¼ì²˜ í¬í•¨ (42ê°œ)
            feature_columns = [
                # ê¸°ë³¸ OHLCV (5ê°œ)
                'Open', 'High', 'Low', 'Close', 'Volume',
                
                # ì´ë™í‰ê·  ë° ì¶”ì„¸ (8ê°œ)
                'MA_5', 'MA_20', 'MA_60', 'ADX', 'DI_Plus', 'DI_Minus', 'PSAR', 'PSAR_Trend',
                
                # ë³¼ë¦°ì € ë°´ë“œ ë° ë³€ë™ì„± (7ê°œ)
                'BB_Upper', 'BB_Middle', 'BB_Lower', 'BB_Percent', 'BB_Width', 'ATR', 'ATR_Ratio',
                
                # ëª¨ë©˜í…€ ì§€í‘œ (8ê°œ)
                'RSI', 'Stoch_K', 'Stoch_D', 'Williams_R', 'CCI', 'MFI', 'ROC_10', 'Price_Momentum',
                
                # ê±°ë˜ëŸ‰ ì§€í‘œ (4ê°œ)
                'OBV_Ratio', 'CMF', 'Volume_Profile', 'Volume_Momentum',
                
                # ì‹œì¥ ì²´ì œ ë° ë¯¸ì‹œêµ¬ì¡° (6ê°œ)
                'Vol_Regime', 'Trend_Strength', 'VWAP', 'PV_Corr', 'Intraday_Range', 'Price_ZScore',
                
                # ê¸°ì¡´ ê¸°ìˆ ì§€í‘œ (4ê°œ)
                'MACD', 'MACD_Signal', 'Price_Change', 'Volatility'
            ]
        else:
            # ê¸°ë³¸ í”¼ì²˜ë§Œ (18ê°œ - í˜¸í™˜ì„±)
            feature_columns = [
                'Open', 'High', 'Low', 'Close', 'Volume',
                'MA_5', 'MA_20', 'MA_60',
                'BB_Upper', 'BB_Middle', 'BB_Lower', 'BB_Percent', 'BB_Width',
                'RSI', 'MACD', 'MACD_Signal', 'Price_Change', 'Volatility'
            ]
        
        # íƒ€ê²Ÿì€ ë‹¤ìŒ 5ì¼ì˜ Close, BB_Upper, BB_Lower
        target_columns = ['Close', 'BB_Upper', 'BB_Lower']
        
        # í”¼ì²˜ ë°ì´í„° ì¤€ë¹„
        feature_data = df[feature_columns].values
        target_data = df[target_columns].values
        
        # ì¢…ëª©ë³„ ê°œë³„ ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ë° í”¼ì²˜ ì •ê·œí™”
        if symbol not in self.symbol_scalers:
            self.symbol_scalers[symbol] = MinMaxScaler()
        
        feature_data_scaled = self.symbol_scalers[symbol].fit_transform(feature_data)
        
        # ì¢…ëª©ë³„ ê°œë³„ íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ë° íƒ€ê²Ÿ ì •ê·œí™”
        if symbol not in self.target_scalers:
            self.target_scalers[symbol] = MinMaxScaler()
        
        target_data_scaled = self.target_scalers[symbol].fit_transform(target_data)
        
        X, y = [], []
        
        for i in range(len(feature_data_scaled) - sequence_length - prediction_length + 1):
            # ì…ë ¥: ê³¼ê±° 60ì¼ì˜ ëª¨ë“  í”¼ì²˜ (ì •ê·œí™”ë¨)
            X.append(feature_data_scaled[i:(i + sequence_length)])
            
            # íƒ€ê²Ÿ: ë‹¤ìŒ 5ì¼ì˜ Close, BB_Upper, BB_Lower (ì •ê·œí™”ë¨)
            y.append(target_data_scaled[(i + sequence_length):(i + sequence_length + prediction_length)])
        
        X = np.array(X)
        y = np.array(y)
        
        self.logger.info(f"Created sequences for {symbol} - X shape: {X.shape}, y shape: {y.shape}")
        self.logger.info(f"  Feature range: [{feature_data_scaled.min():.3f}, {feature_data_scaled.max():.3f}]")
        self.logger.info(f"  Target range: [{target_data_scaled.min():.3f}, {target_data_scaled.max():.3f}]")
        
        return X, y
    
    def inverse_transform_predictions(self, predictions: np.ndarray, symbol: str) -> np.ndarray:
        """
        ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ì„ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
        
        Args:
            predictions: ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ (batch_size, prediction_length, num_targets)
            symbol: ì¢…ëª© ì‹¬ë³¼
            
        Returns:
            ì—­ë³€í™˜ëœ ì˜ˆì¸¡ê°’
        """
        # 3D â†’ 2D ë³€í™˜
        original_shape = predictions.shape
        predictions_2d = predictions.reshape(-1, predictions.shape[-1])
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì—­ë³€í™˜: ì¢…ëª©ë³„ â†’ ì „ì—­ íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ ìˆœì„œë¡œ ì‹œë„
        if symbol in self.target_scalers:
            # ìš°ì„ ìˆœìœ„ 1: ì¢…ëª©ë³„ íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©
            predictions_scaled_back = self.target_scalers[symbol].inverse_transform(predictions_2d)
            self.logger.info(f"Using symbol-specific target scaler for {symbol}")
        else:
            # ìš°ì„ ìˆœìœ„ 2: ì „ì—­ íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©
            try:
                predictions_scaled_back = self.global_target_scaler.inverse_transform(predictions_2d)
                self.logger.info(f"Using global target scaler for {symbol}")
            except Exception as e:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ì—­ë³€í™˜ ì—†ì´ ê·¸ëŒ€ë¡œ ë°˜í™˜
                self.logger.warning(f"No suitable target scaler for {symbol}, returning normalized predictions: {e}")
                predictions_scaled_back = predictions_2d
        
        # ğŸ”§ ë¡œê·¸ ì—­ë³€í™˜ ì ìš© (2ë‹¨ê³„ í•´ê²°ì±…)
        predictions_original = self.apply_inverse_log_transform(predictions_scaled_back, is_price_data=True)
        
        # ì›ë˜ shapeë¡œ ë³µì›
        predictions_original = predictions_original.reshape(original_shape)
        
        self.logger.info(f"Applied log inverse transform for {symbol}")
        return predictions_original
    
    def preprocess_for_inference(self, df: pd.DataFrame, symbol: str = "DEFAULT") -> np.ndarray:
        """
        ì¶”ë¡ ìš© ë°ì´í„° ì „ì²˜ë¦¬
        
        Args:
            df: ìµœê·¼ 60ì¼ OHLCV ë°ì´í„°
            symbol: ì£¼ì‹ ì‹¬ë³¼ (ì¢…ëª©ë³„ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©)
            
        Returns:
            ì •ê·œí™”ëœ ì‹œí€€ìŠ¤ ë°ì´í„°
        """
        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì ìš©
        df_processed = self.preprocess_data(df)
        
        # ğŸš€ í”¼ì²˜ ì„ íƒ (ê³ ê¸‰ í”¼ì²˜ í™œì„±í™” ì—¬ë¶€ì— ë”°ë¼)
        if self.advanced_features_enabled:
            # ê³ ê¸‰ í”¼ì²˜ í¬í•¨ (42ê°œ)
            feature_columns = [
                # ê¸°ë³¸ OHLCV (5ê°œ)
                'Open', 'High', 'Low', 'Close', 'Volume',
                
                # ì´ë™í‰ê·  ë° ì¶”ì„¸ (8ê°œ)
                'MA_5', 'MA_20', 'MA_60', 'ADX', 'DI_Plus', 'DI_Minus', 'PSAR', 'PSAR_Trend',
                
                # ë³¼ë¦°ì € ë°´ë“œ ë° ë³€ë™ì„± (7ê°œ)
                'BB_Upper', 'BB_Middle', 'BB_Lower', 'BB_Percent', 'BB_Width', 'ATR', 'ATR_Ratio',
                
                # ëª¨ë©˜í…€ ì§€í‘œ (8ê°œ)
                'RSI', 'Stoch_K', 'Stoch_D', 'Williams_R', 'CCI', 'MFI', 'ROC_10', 'Price_Momentum',
                
                # ê±°ë˜ëŸ‰ ì§€í‘œ (4ê°œ)
                'OBV_Ratio', 'CMF', 'Volume_Profile', 'Volume_Momentum',
                
                # ì‹œì¥ ì²´ì œ ë° ë¯¸ì‹œêµ¬ì¡° (6ê°œ)
                'Vol_Regime', 'Trend_Strength', 'VWAP', 'PV_Corr', 'Intraday_Range', 'Price_ZScore',
                
                # ê¸°ì¡´ ê¸°ìˆ ì§€í‘œ (4ê°œ)
                'MACD', 'MACD_Signal', 'Price_Change', 'Volatility'
            ]
        else:
            # ê¸°ë³¸ í”¼ì²˜ë§Œ (18ê°œ - í˜¸í™˜ì„±)
            feature_columns = [
                'Open', 'High', 'Low', 'Close', 'Volume',
                'MA_5', 'MA_20', 'MA_60',
                'BB_Upper', 'BB_Middle', 'BB_Lower', 'BB_Percent', 'BB_Width',
                'RSI', 'MACD', 'MACD_Signal', 'Price_Change', 'Volatility'
            ]
        
        feature_data = df_processed[feature_columns].values
        
        # í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì¼€ì¼ë§: ì¢…ëª©ë³„ â†’ ì „ì—­ ìŠ¤ì¼€ì¼ëŸ¬ ìˆœì„œë¡œ ì‹œë„
        if symbol in self.symbol_scalers:
            # ìš°ì„ ìˆœìœ„ 1: ì¢…ëª©ë³„ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš© (í•™ìŠµëœ ì¢…ëª©)
            feature_data_scaled = self.symbol_scalers[symbol].transform(feature_data)
            self.logger.info(f"Using symbol-specific scaler for {symbol}")
        else:
            # ìš°ì„ ìˆœìœ„ 2: ì „ì—­ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš© (ìƒˆë¡œìš´ ì¢…ëª©)
            try:
                feature_data_scaled = self.global_scaler.transform(feature_data)
                self.logger.info(f"Using global scaler for new symbol: {symbol}")
            except Exception as e:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: í˜„ì¬ ë°ì´í„°ë¡œ ì„ì‹œ ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„±
                self.logger.warning(f"Global scaler failed for {symbol}, creating temporary scaler: {e}")
                temp_scaler = MinMaxScaler()
                feature_data_scaled = temp_scaler.fit_transform(feature_data)
        
        # ë§ˆì§€ë§‰ 60ì¼ë§Œ ì‚¬ìš©
        if len(feature_data_scaled) >= 60:
            sequence = feature_data_scaled[-60:]
        else:
            # 60ì¼ ë¯¸ë§Œì¸ ê²½ìš° íŒ¨ë”©
            sequence = np.pad(feature_data_scaled, 
                            ((60 - len(feature_data_scaled), 0), (0, 0)), 
                            mode='edge')
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        sequence = sequence.reshape(1, 60, -1)
        
        self.logger.info(f"Preprocessed inference data shape: {sequence.shape}")
        return sequence


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    dates = pd.date_range('2021-01-01', periods=200, freq='D')
    sample_data = pd.DataFrame({
        'Date': dates,
        'Open': np.random.randn(200).cumsum() + 100,
        'High': np.random.randn(200).cumsum() + 105,
        'Low': np.random.randn(200).cumsum() + 95,
        'Close': np.random.randn(200).cumsum() + 100,
        'Volume': np.random.randint(1000000, 10000000, 200),
        'Symbol': 'TEST'
    })
    
    preprocessor = StockDataPreprocessor()
    processed_data = preprocessor.preprocess_data(sample_data)
    X, y = preprocessor.create_sequences(processed_data)
    
    print(f"Processed data shape: {processed_data.shape}")
    print(f"Sequence data - X: {X.shape}, y: {y.shape}")
    print("Preprocessing test completed successfully!")