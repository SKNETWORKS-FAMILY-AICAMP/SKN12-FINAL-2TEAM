"""
FastAPI ê¸°ë°˜ ì£¼ì‹ ì˜ˆì¸¡ API ì„œë²„
ë°°ì¹˜ ì¶”ë¡  ë° ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì œê³µ
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Optional, Any
import uvicorn
import asyncio
import logging
import os
import pickle
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import json
from contextlib import asynccontextmanager

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from .manual_data_collector import ManualStockDataCollector
from .data_preprocessor import StockDataPreprocessor
from .pytorch_lstm_model import PyTorchStockLSTM
from .config import get_model_paths

# Common ê·œê²© import 
from .common.model_model import PredictionResult as CommonPredictionResult, DailyPrediction, BollingerBand, ModelInfo
from .common.model_serialize import (
    PredictRequest as CommonPredictRequest, 
    PredictResponse as CommonPredictResponse,
    BatchPredictRequest as CommonBatchPredictRequest,
    BatchPredictResponse as CommonBatchPredictResponse,
    ModelsListRequest, 
    ModelsListResponse
)
from .common.model_protocol import ModelProtocol

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì „ì—­ ë³€ìˆ˜
model = None
preprocessor = None
data_collector = None

# Common í”„ë¡œí† ì½œ ì¸ìŠ¤í„´ìŠ¤
model_protocol = ModelProtocol()

# ============================================================================
# ì—ëŸ¬ ì½”ë“œ ì •ì˜ (Account í…œí”Œë¦¿ íŒ¨í„´ ì¤€ìˆ˜)
# ============================================================================
class ErrorCodes:
    """ëª¨ë¸ ì„œë¹„ìŠ¤ ì—ëŸ¬ ì½”ë“œ"""
    SUCCESS = 0                    # ì„±ê³µ
    SERVER_ERROR = 5000           # ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜
    MODEL_LOAD_ERROR = 5001       # ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
    PREPROCESSING_ERROR = 5002    # ì „ì²˜ë¦¬ ì˜¤ë¥˜
    PREDICTION_ERROR = 5003       # ì˜ˆì¸¡ ì‹¤íŒ¨
    INVALID_REQUEST = 5004        # ì˜ëª»ëœ ìš”ì²­ íŒŒë¼ë¯¸í„°
    DATA_COLLECTION_ERROR = 5005  # ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨

# ============================================================================
# í˜„ì‹¤ì„± ê²€ì¦ ë¡œì§ (1ë‹¨ê³„ í•´ê²°ì±…)
# ============================================================================

def validate_and_adjust_prediction(current_price: float, predicted_price: float, max_daily_change: float = 0.2) -> float:
    """
    ì˜ˆì¸¡ê°’ì˜ í˜„ì‹¤ì„±ì„ ê²€ì¦í•˜ê³  ë¹„í˜„ì‹¤ì ì¸ ê²½ìš° ì¡°ì •
    
    Args:
        current_price: í˜„ì¬ ì£¼ê°€
        predicted_price: ì˜ˆì¸¡ëœ ì£¼ê°€
        max_daily_change: í—ˆìš© ê°€ëŠ¥í•œ ìµœëŒ€ ì¼ì¼ ë³€í™”ìœ¨ (ê¸°ë³¸ 20%)
    
    Returns:
        ì¡°ì •ëœ ì˜ˆì¸¡ ì£¼ê°€
    """
    if current_price <= 0:
        return predicted_price
    
    change_rate = abs(predicted_price - current_price) / current_price
    
    # ë³€í™”ìœ¨ì´ ì œí•œì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ì¡°ì •
    if change_rate > max_daily_change:
        logger.warning(f"Unrealistic prediction detected: {current_price:.2f} â†’ {predicted_price:.2f} ({change_rate:.1%})")
        
        if predicted_price > current_price:
            # ìƒìŠ¹ ì‹œ ì œí•œ
            adjusted_price = current_price * (1 + max_daily_change)
        else:
            # í•˜ë½ ì‹œ ì œí•œ
            adjusted_price = current_price * (1 - max_daily_change)
        
        logger.info(f"Adjusted prediction: {predicted_price:.2f} â†’ {adjusted_price:.2f}")
        return adjusted_price
    
    return predicted_price

def validate_and_fix_bollinger_bands(bands_list: list) -> list:
    """
    ë³¼ë¦°ì € ë°´ë“œì˜ ìˆœì„œë¥¼ ê²€ì¦í•˜ê³  ì˜ëª»ëœ ê²½ìš° ìˆ˜ì •
    ì •ìƒ: bb_upper > bb_middle > bb_lower
    
    Args:
        bands_list: ë³¼ë¦°ì € ë°´ë“œ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ìˆ˜ì •ëœ ë³¼ë¦°ì € ë°´ë“œ ë¦¬ìŠ¤íŠ¸
    """
    fixed_bands = []
    
    for band in bands_list:
        upper = band.get('bb_upper', 0)
        middle = band.get('bb_middle', 0)
        lower = band.get('bb_lower', 0)
        
        # ìˆœì„œê°€ ì˜ëª»ëœ ê²½ìš° ìˆ˜ì •
        if not (upper >= middle >= lower):
            logger.warning(f"Invalid Bollinger Band order detected: upper={upper:.2f}, middle={middle:.2f}, lower={lower:.2f}")
            
            # ê°’ë“¤ì„ ì •ë ¬í•˜ì—¬ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì¬ë°°ì¹˜
            values = sorted([upper, middle, lower], reverse=True)
            fixed_band = band.copy()
            fixed_band['bb_upper'] = values[0]
            fixed_band['bb_middle'] = values[1] 
            fixed_band['bb_lower'] = values[2]
            
            logger.info(f"Fixed Bollinger Band: upper={values[0]:.2f}, middle={values[1]:.2f}, lower={values[2]:.2f}")
            fixed_bands.append(fixed_band)
        else:
            fixed_bands.append(band)
    
    return fixed_bands

# ============================================================================
# ë³€í™”ìœ¨ ê¸°ë°˜ ì˜ˆì¸¡ ë¡œì§ (3ë‹¨ê³„ í•´ê²°ì±…) 
# ============================================================================

def generate_change_rate_predictions(current_price: float, base_change_rates: list = None) -> tuple:
    """
    ë³€í™”ìœ¨ ê¸°ë°˜ ì˜ˆì¸¡ê°’ ìƒì„± (ì„ì‹œ ì†”ë£¨ì…˜)
    
    Args:
        current_price: í˜„ì¬ ì£¼ê°€
        base_change_rates: ê¸°ë³¸ ë³€í™”ìœ¨ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ ëœë¤ ìƒì„±)
    
    Returns:
        (ì˜ˆì¸¡ ê°€ê²© ë¦¬ìŠ¤íŠ¸, ë³¼ë¦°ì € ë°´ë“œ ë¦¬ìŠ¤íŠ¸)
    """
    if base_change_rates is None:
        # í˜„ì‹¤ì ì¸ ë³€í™”ìœ¨ ë²”ìœ„ (-5% ~ +10%)
        import random
        random.seed(42)  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ
        base_change_rates = [
            random.uniform(-0.05, 0.10),  # Day 1: -5% ~ +10%
            random.uniform(-0.03, 0.08),  # Day 2: -3% ~ +8%
            random.uniform(-0.04, 0.06),  # Day 3: -4% ~ +6%
            random.uniform(-0.02, 0.07),  # Day 4: -2% ~ +7%
            random.uniform(-0.03, 0.05)   # Day 5: -3% ~ +5%
        ]
    
    predicted_prices = []
    bollinger_data = []
    
    running_price = current_price
    
    for i, change_rate in enumerate(base_change_rates):
        # ë³€í™”ìœ¨ ì ìš©
        predicted_price = running_price * (1 + change_rate)
        predicted_prices.append(predicted_price)
        
        # ë³¼ë¦°ì € ë°´ë“œ (ì˜ˆì¸¡ê°€ ì¤‘ì‹¬ìœ¼ë¡œ Â±2% ë²”ìœ„)
        volatility = abs(change_rate) * 2  # ë³€í™”ìœ¨ì— ë¹„ë¡€í•œ ë³€ë™ì„±
        bb_upper = predicted_price * (1 + volatility)
        bb_lower = predicted_price * (1 - volatility)
        bb_middle = predicted_price
        
        bollinger_data.append({
            "bb_upper": bb_upper,
            "bb_middle": bb_middle,
            "bb_lower": bb_lower
        })
        
        # ë‹¤ìŒ ë‚ ì˜ ê¸°ì¤€ê°€ë¡œ ì—…ë°ì´íŠ¸ (ëˆ„ì  íš¨ê³¼)
        running_price = predicted_price
        
        logger.debug(f"Day {i+1}: {change_rate:+.1%} â†’ ${predicted_price:.2f}")
    
    logger.info(f"Generated change-rate predictions: {[f'${p:.2f}' for p in predicted_prices]}")
    return predicted_prices, bollinger_data

def apply_change_rate_model(current_price: float, raw_predictions: np.ndarray = None) -> tuple:
    """
    ë³€í™”ìœ¨ ê¸°ë°˜ ëª¨ë¸ ì ìš© (3ë‹¨ê³„ í•´ê²°ì±…)
    
    Args:
        current_price: í˜„ì¬ ì£¼ê°€
        raw_predictions: ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡ (ì‚¬ìš© ì•ˆí•¨, ì¶”í›„ ë³€í™”ìœ¨ ì¶”ì¶œìš©)
    
    Returns:
        (ì¡°ì •ëœ ì˜ˆì¸¡ ê°€ê²©, ì¡°ì •ëœ ë³¼ë¦°ì € ë°´ë“œ)
    """
    logger.info(f"Applying change-rate model for current price: ${current_price:.2f}")
    
    # ğŸ”§ ì„ì‹œë¡œ í˜„ì‹¤ì ì¸ ë³€í™”ìœ¨ ê¸°ë°˜ ì˜ˆì¸¡ ìƒì„±
    predicted_prices, bollinger_data = generate_change_rate_predictions(current_price)
    
    return predicted_prices, bollinger_data

class PredictionRequest(BaseModel):
    """ë‹¨ì¼ ì˜ˆì¸¡ ìš”ì²­"""
    symbol: str = Field(..., description="ì£¼ì‹ ì‹¬ë³¼ (ì˜ˆ: AAPL)")
    days: int = Field(60, description="ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ì¼ìˆ˜")

class BatchPredictionRequest(BaseModel):
    """ë°°ì¹˜ ì˜ˆì¸¡ ìš”ì²­"""
    symbols: List[str] = Field(..., description="ì£¼ì‹ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸")
    days: int = Field(60, description="ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ì¼ìˆ˜")
    batch_size: int = Field(5, description="ë°°ì¹˜ í¬ê¸°")

# PredictionResultëŠ” ì´ì œ Commonì—ì„œ import

class BatchPredictionResult(BaseModel):
    """ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼"""
    request_id: str
    total_symbols: int
    completed_symbols: int
    failed_symbols: int
    results: List[CommonPredictionResult]
    processing_time: float
    status: str

class HealthResponse(BaseModel):
    """í—¬ìŠ¤ ì²´í¬ ì‘ë‹µ"""
    status: str
    model_loaded: bool
    gpu_available: bool
    timestamp: str

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    # ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ
    await load_model_and_preprocessor()
    yield
    # ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‘ì—… (í•„ìš”í•œ ê²½ìš°)
    logger.info("Shutting down API server...")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Stock Prediction API",
    description="LSTM ê¸°ë°˜ ì£¼ì‹ ê°€ê²© ë° ë³¼ë¦°ì € ë°´ë“œ ì˜ˆì¸¡ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

async def load_model_and_preprocessor():
    """ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸° ë¡œë“œ"""
    global model, preprocessor, data_collector
    
    try:
        logger.info("Loading model and preprocessor...")
        
        # ğŸš€ PyTorch ëª¨ë¸ ë¡œë“œ (í™˜ê²½ë³„ ê²½ë¡œ ìë™ ê°ì§€)
        model_path, preprocessor_path = get_model_paths()
        
        if os.path.exists(model_path):
            # PyTorch ëª¨ë¸ ì´ˆê¸°í™” í›„ ë¡œë“œ
            model = PyTorchStockLSTM(
                sequence_length=60,
                prediction_length=5,
                num_features=18,  # ê¸°ì¡´ ëª¨ë¸ê³¼ í˜¸í™˜ì„± ìœ ì§€
                num_targets=3
            )
            model.load_model(model_path, hidden_size=512)  # ğŸ”¥ RTX 4090 ìµœì í™”
            logger.info(f"ğŸš€ PyTorch model loaded from: {model_path}")
        else:
            logger.warning(f"Model file not found: {model_path}")
            model = None
        
        # ì „ì²˜ë¦¬ê¸° ë¡œë“œ
        if os.path.exists(preprocessor_path):
            with open(preprocessor_path, 'rb') as f:
                preprocessor = pickle.load(f)
            
            # ğŸš€ ê³ ê¸‰ í”¼ì²˜ í™œì„±í™” (42ê°œ í”¼ì²˜ ëª¨ë“œ)
            preprocessor.advanced_features_enabled = False
            
            logger.info("Preprocessor loaded successfully")
            logger.info("ğŸš€ Advanced features enabled (42 features mode)")
        else:
            logger.error(f"âŒ Preprocessor file not found: {preprocessor_path}")
            logger.error("âŒ Please train the model first to generate preprocessor.pkl")
            preprocessor = None
        
        # ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        data_collector = ManualStockDataCollector()
        
        logger.info("All components loaded successfully")
        
        # Common í”„ë¡œí† ì½œ ì½œë°± ì„¤ì •
        setup_protocol_callbacks()
        
    except Exception as e:
        logger.error(f"Error loading model/preprocessor: {str(e)}")
        model = None
        preprocessor = None

def setup_protocol_callbacks():
    """Common í”„ë¡œí† ì½œ ì½œë°± í•¨ìˆ˜ë“¤ ì„¤ì •"""
    model_protocol.on_predict_req_callback = handle_common_predict
    model_protocol.on_batch_predict_req_callback = handle_common_batch_predict
    model_protocol.on_models_list_req_callback = handle_common_models_list

async def handle_common_predict(session, request: CommonPredictRequest) -> CommonPredictResponse:
    """Common ê·œê²© ë‹¨ì¼ ì˜ˆì¸¡ ì²˜ë¦¬ (íŒ€ í‘œì¤€ BaseRequest/BaseResponse ê¸°ë°˜)"""
    response = CommonPredictResponse(
        errorCode=ErrorCodes.SUCCESS,
        sequence=request.sequence
    )
    
    try:
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ê²€ì¦
        if not request.symbol:
            response.errorCode = ErrorCodes.INVALID_REQUEST
            response.message = "Symbol is required"
            return response
            
        # ëª¨ë¸/ì „ì²˜ë¦¬ê¸° ë¡œë”© í™•ì¸
        if model is None or preprocessor is None:
            response.errorCode = ErrorCodes.MODEL_LOAD_ERROR
            response.message = "Model or preprocessor not loaded"
            return response
        
        # Common Requestë¥¼ ë‚´ë¶€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        internal_request = PredictionRequest(
            symbol=request.symbol,
            days=request.days
        )
        
        # ê¸°ì¡´ ì˜ˆì¸¡ ë¡œì§ ì‚¬ìš©
        result = await predict_single_stock_internal(internal_request)
        
        response.result = result
        response.message = "Prediction completed successfully"
        
    except Exception as e:
        logger.error(f"Prediction error for {request.symbol}: {str(e)}")
        response.errorCode = ErrorCodes.PREDICTION_ERROR
        response.message = f"Prediction failed: {str(e)}"
    
    return response

async def handle_common_batch_predict(session, request: CommonBatchPredictRequest) -> CommonBatchPredictResponse:
    """Common ê·œê²© ë°°ì¹˜ ì˜ˆì¸¡ ì²˜ë¦¬ (íŒ€ í‘œì¤€ BaseRequest/BaseResponse ê¸°ë°˜)"""
    response = CommonBatchPredictResponse(
        errorCode=ErrorCodes.SUCCESS,
        sequence=request.sequence
    )
    
    try:
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ê²€ì¦
        if not request.symbols or len(request.symbols) == 0:
            response.errorCode = ErrorCodes.INVALID_REQUEST
            response.message = "Symbols list is required and cannot be empty"
            return response
            
        # ëª¨ë¸/ì „ì²˜ë¦¬ê¸° ë¡œë”© í™•ì¸
        if model is None or preprocessor is None:
            response.errorCode = ErrorCodes.MODEL_LOAD_ERROR
            response.message = "Model or preprocessor not loaded"
            return response
        
        # ë°°ì¹˜ ì˜ˆì¸¡ ì‹¤í–‰
        batch_results = []
        success_count = 0
        
        for symbol in request.symbols:
            try:
                result = await predict_single_symbol(symbol, request.days)
                batch_results.append(result)
                if result.status == "success":
                    success_count += 1
            except Exception as e:
                logger.warning(f"Failed to predict {symbol}: {str(e)}")
                # ì‹¤íŒ¨í•œ ê²½ìš° ì—ëŸ¬ ê²°ê³¼ ìƒì„±
                error_result = CommonPredictionResult(
                    symbol=symbol,
                    prediction_date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    current_price=0.0,
                    predictions=[],
                    bollinger_bands=[],
                    confidence_score=0.0,
                    status=f"failed: {str(e)}"
                )
                batch_results.append(error_result)
        
        # ì‘ë‹µ ì„¤ì •
        response.results = batch_results
        response.batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{request.sequence}"
        response.processed_count = len(batch_results)
        response.success_count = success_count
        response.message = f"Batch prediction completed: {success_count}/{len(batch_results)} successful"
        
    except Exception as e:
        logger.error(f"Batch prediction error: {str(e)}")
        response.errorCode = ErrorCodes.PREDICTION_ERROR
        response.message = f"Batch prediction failed: {str(e)}"
    
    return response

async def handle_common_models_list(session, request: ModelsListRequest) -> ModelsListResponse:
    """Common ê·œê²© ëª¨ë¸ ëª©ë¡ ì²˜ë¦¬ (íŒ€ í‘œì¤€ BaseRequest/BaseResponse ê¸°ë°˜)"""
    response = ModelsListResponse(
        errorCode=ErrorCodes.SUCCESS,
        sequence=request.sequence
    )
    
    try:
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì •ë³´ ìƒì„±
        models = [
            ModelInfo(
                model_type="PyTorch LSTM",
                version="1.0.0",
                description="LSTM model for stock price and Bollinger Band prediction",
                supported_features=["price_prediction", "bollinger_bands", "trend_analysis"],
                performance_metrics={"accuracy": 0.8, "confidence": 0.85}
            )
        ]
        
        response.models = models
        response.message = f"Found {len(models)} available models"
        
    except Exception as e:
        logger.error(f"Models list error: {str(e)}")
        response.errorCode = ErrorCodes.SERVER_ERROR
        response.message = f"Failed to retrieve models list: {str(e)}"
    
    return response

async def predict_single_stock_internal(request: PredictionRequest) -> CommonPredictionResult:
    """ë‚´ë¶€ ì˜ˆì¸¡ ë¡œì§ (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©)"""
    if model is None or preprocessor is None:
        raise Exception("Model or preprocessor not loaded")
    
    try:
        logger.info(f"Processing prediction request for {request.symbol}")
        
        # ìµœê·¼ ë°ì´í„° ìˆ˜ì§‘
        recent_data = data_collector.get_recent_data(request.symbol, request.days)
        if recent_data is None or len(recent_data) < request.days:
            raise Exception(f"Insufficient data for symbol {request.symbol}")
        
        # ì „ì²˜ë¦¬ ë° ì¶”ë¡ 
        input_sequence = preprocessor.preprocess_for_inference(recent_data, request.symbol)
        predictions_normalized = model.predict(input_sequence)
        
        # ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ì„ ì‹¤ì œ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜
        predictions = preprocessor.inverse_transform_predictions(predictions_normalized, request.symbol)
        
        # ê²°ê³¼ í¬ë§·íŒ…
        result = format_prediction_result(request.symbol, recent_data, predictions)
        
        logger.info(f"Prediction completed for {request.symbol}")
        return result
        
    except Exception as e:
        logger.error(f"Error predicting {request.symbol}: {str(e)}")
        raise Exception(str(e))

def format_prediction_result(symbol: str, 
                           current_data: pd.DataFrame,
                           predictions: np.ndarray,
                           confidence: float = 0.8) -> CommonPredictionResult:
    """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë³€í™”ìœ¨ ê¸°ë°˜ + í˜„ì‹¤ì„± ê²€ì¦)"""
    
    current_price = float(current_data['Close'].iloc[-1])
    prediction_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    logger.info(f"Formatting prediction for {symbol}: current_price=${current_price:.2f}")
    
    # ğŸš€ ë³€í™”ìœ¨ ê¸°ë°˜ ì˜ˆì¸¡ ì ìš© (3ë‹¨ê³„ í•´ê²°ì±…)
    change_rate_prices, change_rate_bollinger = apply_change_rate_model(current_price, predictions)
    
    # 5ì¼ê°„ì˜ ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼ í¬ë§·íŒ…
    prediction_list = []
    bollinger_list = []
    
    for i in range(5):
        # ë³€í™”ìœ¨ ê¸°ë°˜ ì˜ˆì¸¡ê°’ ì‚¬ìš©
        predicted_close = change_rate_prices[i]
        bb_data = change_rate_bollinger[i]
        
        # íŠ¸ë Œë“œ ê²°ì • (ì´ì „ ê°€ê²©ê³¼ ë¹„êµ)
        reference_price = change_rate_prices[i-1] if i > 0 else current_price
        trend = "up" if predicted_close > reference_price else "down"
        
        day_prediction = DailyPrediction(
            day=i + 1,
            date=(datetime.now() + timedelta(days=i+1)).strftime("%Y-%m-%d"),
            predicted_close=predicted_close,
            trend=trend
        )
        prediction_list.append(day_prediction)
        
        bollinger_band = BollingerBand(
            day=i + 1,
            date=(datetime.now() + timedelta(days=i+1)).strftime("%Y-%m-%d"),
            bb_upper=bb_data["bb_upper"],
            bb_lower=bb_data["bb_lower"],
            bb_middle=bb_data["bb_middle"]
        )
        bollinger_list.append(bollinger_band)
        
        logger.debug(f"Day {i+1}: ${predicted_close:.2f} ({trend}), BB: {bb_data['bb_lower']:.2f}-{bb_data['bb_upper']:.2f}")
    
    logger.info(f"Change-rate prediction completed for {symbol}: {[f'${p:.2f}' for p in change_rate_prices]}")
    
    return CommonPredictionResult(
        symbol=symbol,
        prediction_date=prediction_date,
        current_price=current_price,
        predictions=prediction_list,
        bollinger_bands=bollinger_list,
        confidence_score=confidence,
        status="success"
    )

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    import torch
    
    gpu_available = torch.cuda.is_available()
    
    return HealthResponse(
        status="healthy",
        model_loaded=model is not None,
        gpu_available=gpu_available,
        timestamp=datetime.now().isoformat()
    )

@app.post("/predict", response_model=CommonPredictionResult)
async def predict_single_stock(request: PredictionRequest):
    """ë‹¨ì¼ ì¢…ëª© ì˜ˆì¸¡ (FastAPI ì—”ë“œí¬ì¸íŠ¸)"""
    try:
        result = await predict_single_stock_internal(request)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Common ê·œê²© HTTP ì—”ë“œí¬ì¸íŠ¸ë“¤ (BaseRequest/BaseResponse ê¸°ë°˜)
@app.post("/api/v1/predict", response_model=CommonPredictResponse)
async def predict_common_format(request: CommonPredictRequest):
    """Common ê·œê²© ë‹¨ì¼ ì˜ˆì¸¡ API"""
    return await handle_common_predict(None, request)

@app.post("/api/v1/predict/batch", response_model=CommonBatchPredictResponse)
async def batch_predict_common_format(request: CommonBatchPredictRequest):
    """Common ê·œê²© ë°°ì¹˜ ì˜ˆì¸¡ API"""
    return await handle_common_batch_predict(None, request)

@app.post("/api/v1/models", response_model=ModelsListResponse)
async def list_models_common(request: ModelsListRequest):
    """Common ê·œê²© ëª¨ë¸ ëª©ë¡ API"""
    return await handle_common_models_list(None, request)

@app.get("/api/v1/models/simple")
async def list_models_simple():
    """ê°„ë‹¨í•œ ëª¨ë¸ ì •ë³´ ì¡°íšŒ API (GET)"""
    return {
        "models": [{
            "model_type": "PyTorch LSTM",
            "version": "1.0.0",
            "description": "LSTM model for stock price and Bollinger Band prediction",
            "supported_features": ["price_prediction", "bollinger_bands", "trend_analysis"],
            "performance_metrics": {"accuracy": 0.8, "confidence": 0.85}
        }]
    }

@app.post("/predict/batch", response_model=BatchPredictionResult)
async def predict_batch_stocks(request: BatchPredictionRequest):
    """ë°°ì¹˜ ì£¼ì‹ ì˜ˆì¸¡"""
    if model is None or preprocessor is None:
        raise HTTPException(status_code=503, detail="Model or preprocessor not loaded")
    
    request_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    start_time = datetime.now()
    
    logger.info(f"Processing batch prediction request {request_id} for {len(request.symbols)} symbols")
    
    results = []
    completed = 0
    failed = 0
    
    # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ì²˜ë¦¬
    for i in range(0, len(request.symbols), request.batch_size):
        batch_symbols = request.symbols[i:i + request.batch_size]
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ íƒœìŠ¤í¬ ìƒì„±
        tasks = []
        for symbol in batch_symbols:
            task = asyncio.create_task(predict_single_symbol(symbol, request.days))
            tasks.append(task)
        
        # ë°°ì¹˜ ì‹¤í–‰
        batch_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for symbol, result in zip(batch_symbols, batch_results):
            if isinstance(result, Exception):
                logger.error(f"Failed to predict {symbol}: {str(result)}")
                failed += 1
                # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ê²°ê³¼ì— í¬í•¨
                error_result = CommonPredictionResult(
                    symbol=symbol,
                    prediction_date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    current_price=0.0,
                    predictions=[],
                    bollinger_bands=[],
                    confidence_score=0.0,
                    status=f"failed: {str(result)}"
                )
                results.append(error_result)
            else:
                results.append(result)
                completed += 1
        
        # ë°°ì¹˜ ê°„ ì ì‹œ ëŒ€ê¸° (API ì œí•œ ë°©ì§€)
        if i + request.batch_size < len(request.symbols):
            await asyncio.sleep(0.1)
    
    processing_time = (datetime.now() - start_time).total_seconds()
    
    logger.info(f"Batch prediction {request_id} completed: {completed} success, {failed} failed")
    
    return BatchPredictionResult(
        request_id=request_id,
        total_symbols=len(request.symbols),
        completed_symbols=completed,
        failed_symbols=failed,
        results=results,
        processing_time=processing_time,
        status="completed"
    )

async def predict_single_symbol(symbol: str, days: int) -> CommonPredictionResult:
    """ë‹¨ì¼ ì‹¬ë³¼ ì˜ˆì¸¡ (ë‚´ë¶€ í•¨ìˆ˜)"""
    try:
        # ìµœê·¼ ë°ì´í„° ìˆ˜ì§‘
        recent_data = data_collector.get_recent_data(symbol, days)
        if recent_data is None or len(recent_data) < days:
            raise ValueError(f"Insufficient data for symbol {symbol}")
        
        # ì „ì²˜ë¦¬ ë° ì¶”ë¡ 
        input_sequence = preprocessor.preprocess_for_inference(recent_data, symbol)
        predictions_normalized = model.predict(input_sequence)
        
        # ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ì„ ì‹¤ì œ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜
        predictions = preprocessor.inverse_transform_predictions(predictions_normalized, symbol)
        
        # ê²°ê³¼ í¬ë§·íŒ…
        result = format_prediction_result(symbol, recent_data, predictions)
        return result
        
    except Exception as e:
        raise Exception(f"Error predicting {symbol}: {str(e)}")

@app.get("/models/info")
async def get_model_info():
    """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    try:
        model_info = {
            "model_type": "LSTM with Attention",
            "sequence_length": 60,
            "prediction_length": 5,
            "features": [
                "Open", "High", "Low", "Close", "Volume",
                "MA_5", "MA_20", "MA_60",
                "BB_Upper", "BB_Middle", "BB_Lower", "BB_Percent", "BB_Width",
                "RSI", "MACD", "MACD_Signal", "Price_Change", "Volatility"
            ],
            "targets": ["Close", "BB_Upper", "BB_Lower"],
            "model_parameters": model.model.count_params() if model.model else 0
        }
        return model_info
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "Stock Prediction API",
        "version": "1.0.0",
        "endpoints": {
            "health": "/health",
            "single_prediction": "/predict",
            "batch_prediction": "/predict/batch",
            "model_info": "/models/info"
        }
    }

if __name__ == "__main__":
    # ê°œë°œ í™˜ê²½ì—ì„œ ì‹¤í–‰
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )