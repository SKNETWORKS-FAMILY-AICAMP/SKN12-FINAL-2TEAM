# ğŸ“ 21ì£¼ì°¨ í•™ìŠµ íšŒê³  - LLM ì±—ë´‡ ì•„í‚¤í…ì²˜ ì„¤ê³„

## 1. LLM ê¸°ë°˜ ì±—ë´‡ íˆìŠ¤í† ë¦¬ ì €ì¥ ì•„í‚¤í…ì²˜ ì„¤ê³„

### ğŸ¤” ì˜ì‚¬ê²°ì • ê³¼ì •

#### ê³ ë¯¼í–ˆë˜ ì„ íƒì§€ë“¤

| ì„ íƒì§€ | ì¥ì  | ë‹¨ì  | íŒë‹¨ |
|--------|------|------|------|
| **Redis ë‹¨ë…** | â€¢ ì´ˆê³ ì† ì½ê¸°/ì“°ê¸° (ë©”ëª¨ë¦¬ ê¸°ë°˜)<br>â€¢ ê°„ë‹¨í•œ ì•„í‚¤í…ì²˜ | â€¢ ëŒ€ìš©ëŸ‰ ì €ì¥ ì‹œ ì›” ìˆ˜ë°±ë§Œì› ë¹„ìš©<br>â€¢ ì˜ì†ì„± ë¦¬ìŠ¤í¬ | âŒ ë¹„ìš© íš¨ìœ¨ì„± ë„ˆë¬´ ë‚®ìŒ |
| **MySQL ë‹¨ë…** | â€¢ ì˜êµ¬ ì €ì¥ ë³´ì¥<br>â€¢ ë³µì¡í•œ ì¿¼ë¦¬ ê°€ëŠ¥ | â€¢ ì‹¤ì‹œê°„ ì±„íŒ… ì‘ë‹µì„± ì €í•˜<br>â€¢ ë†’ì€ ë™ì‹œì„± ì‹œ ë³‘ëª© | âŒ ì‚¬ìš©ì ê²½í—˜ í¬ìƒ |
| **Redis + MySQL** | â€¢ ì‹¤ì‹œê°„ì„±ê³¼ ì˜ì†ì„± í™•ë³´<br>â€¢ ê¸°ì¡´ ì¸í”„ë¼ í™œìš© | â€¢ ë°ì´í„° ë™ê¸°í™” í•„ìš”<br>â€¢ ìš´ì˜ ë³µì¡ë„ ì¦ê°€ | âœ… ê°€ì¥ ê· í˜•ì¡íŒ ì„ íƒ |
| **Redis + Elasticsearch** | â€¢ ê°•ë ¥í•œ full-text ê²€ìƒ‰<br>â€¢ ë¶„ì„ ëŒ€ì‹œë³´ë“œ | â€¢ ìƒˆ ì¸í”„ë¼ ë„ì… í•„ìš”<br>â€¢ ë¼ì´ì„ ìŠ¤ ë¹„ìš© | âŒ í˜„ì¬ ê·œëª¨ì— ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§ |

#### ğŸ¯ ìµœì¢… ì„ íƒ: Redis + MySQL í•˜ì´ë¸Œë¦¬ë“œ

**ì„ íƒ ì´ìœ :**
1. base_serverê°€ ì´ë¯¸ ë‘ ì‹œìŠ¤í…œì„ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ ì¤‘
2. Hot/Cold ë°ì´í„° ë¶„ë¦¬ë¡œ ë¹„ìš©ê³¼ ì„±ëŠ¥ ìµœì í™”
3. íŒ€ì´ ì´ë¯¸ ìˆ™ë ¨ëœ ê¸°ìˆ ë¡œ ë¹ ë¥¸ êµ¬í˜„ ê°€ëŠ¥
4. í•„ìš”ì‹œ OpenSearch ì¶”ê°€ ë“± ì ì§„ì  í™•ì¥ ìš©ì´

### ğŸ’» êµ¬í˜„ ì½”ë“œ ì˜ˆì‹œ

#### 1. ChatTemplateImpl í™•ì¥ (Redis + MySQL í•˜ì´ë¸Œë¦¬ë“œ)
```python
# base_server/template/chat/chat_template_impl.py

from template.base.base_template import BaseTemplate
from template.chat.common.chat_serialize import *
from service.core.logger import Logger
from service.service_container import ServiceContainer
from service.cache.cache_service import CacheService
from service.queue.queue_service import QueueService
import json
import uuid
from datetime import datetime

class ChatTemplateImpl(BaseTemplate):
    def __init__(self):
        super().__init__()
    
    async def on_chat_message_send_req(self, client_session, request: ChatMessageSendRequest):
        """LLM ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ë©”ì‹œì§€ ì „ì†¡ ì²˜ë¦¬"""
        response = ChatMessageSendResponse()
        
        try:
            account_db_key = client_session.session.account_db_key
            shard_id = client_session.session.shard_id
            
            # 1. Redisì— ì¦‰ì‹œ ì €ì¥ (ì‹¤ì‹œê°„ ì‘ë‹µì„ ìœ„í•´)
            cache_key = f"chat:user:{account_db_key}:room:{request.room_id}:messages"
            message_data = {
                "message_id": f"msg_{uuid.uuid4().hex[:16]}",
                "room_id": request.room_id,
                "sender_type": "USER",
                "content": request.content,
                "timestamp": datetime.now().isoformat(),
                "metadata": {
                    "include_portfolio": request.include_portfolio,
                    "analysis_symbols": request.analysis_symbols
                }
            }
            
            # Redis Listì— ì¶”ê°€ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)
            async with CacheService.get_client() as client:
                await client.lpush(cache_key, json.dumps(message_data))
                await client.ltrim(cache_key, 0, 99)
                await client.expire(cache_key, 86400)  # 24ì‹œê°„ TTL
            
            # 2. ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì €ì¥
            stream_key = f"stream:{account_db_key}:{request.room_id}"
            stream_data = {
                "status": "active", 
                "started_at": datetime.now().isoformat(),
                "message_id": message_data["message_id"]
            }
            async with CacheService.get_client() as client:
                await client.set_string(stream_key, json.dumps(stream_data), expire=300)
            
            # 3. QueueServiceë¥¼ í†µí•œ ë¹„ë™ê¸° MySQL ì €ì¥
            queue_service = QueueService.get_instance()
            await queue_service.send_message(
                queue_name="chat_persistence",
                payload={
                    "type": "save_user_message",
                    "account_db_key": account_db_key,
                    "shard_id": shard_id,
                    "message_data": message_data
                },
                message_type="chat_save",
                priority=2  # ì¤‘ê°„ ìš°ì„ ìˆœìœ„
            )
            
            response.errorCode = 0
            response.stream_key = stream_key
            response.message_id = message_data["message_id"]
            
            Logger.info(f"Chat message prepared for streaming: {message_data['message_id']}")
            
        except Exception as e:
            Logger.error(f"Chat message send error: {e}")
            response.errorCode = 1000
            
        return response
    
    async def get_recent_messages_hybrid(
        self, 
        account_db_key: int, 
        room_id: str, 
        limit: int = 50
    ) -> list:
        """Redis + MySQL í•˜ì´ë¸Œë¦¬ë“œ ì¡°íšŒ"""
        
        # 1. Redisì—ì„œ ìµœê·¼ ë©”ì‹œì§€ í™•ì¸
        cache_key = f"chat:user:{account_db_key}:room:{room_id}:messages"
        messages = []
        
        try:
            async with CacheService.get_client() as client:
                cached_messages = await client.lrange(cache_key, 0, limit - 1)
                
                for msg_json in cached_messages:
                    messages.append(json.loads(msg_json))
            
            # 2. Redisì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ MySQLì—ì„œ ì¶”ê°€ ë¡œë“œ
            if len(messages) < limit:
                remaining = limit - len(messages)
                db_service = ServiceContainer.get_database_service()
                
                db_messages = await db_service.call_shard_procedure(
                    shard_id=await self._get_user_shard(account_db_key),
                    procedure_name="fp_get_chat_messages",
                    params=(account_db_key, room_id, 1, remaining, None)
                )
                
                # MySQL ë°ì´í„°ë¥¼ Redisì— ìºì‹±
                if db_messages:
                    for msg in db_messages:
                        db_message_data = {
                            "message_id": msg.get('message_id'),
                            "sender_type": msg.get('sender_type'),
                            "content": msg.get('content'),
                            "timestamp": str(msg.get('timestamp')),
                            "metadata": json.loads(msg.get('metadata', '{}'))
                        }
                        messages.append(db_message_data)
            
            return messages
            
        except Exception as e:
            Logger.error(f"Error getting recent messages: {e}")
            return []
    
    async def save_streaming_response(
        self,
        account_db_key: int,
        room_id: str,
        ai_response: str,
        metadata: dict
    ):
        """ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ AI ì‘ë‹µ ì €ì¥"""
        
        # 1. Redisì— ì„ì‹œ ì €ì¥
        cache_key = f"chat:user:{account_db_key}:room:{room_id}:messages"
        ai_message_data = {
            "message_id": f"msg_{uuid.uuid4().hex[:16]}",
            "room_id": room_id,
            "sender_type": "AI",
            "content": ai_response,
            "timestamp": datetime.now().isoformat(),
            "metadata": metadata
        }
        
        async with CacheService.get_client() as client:
            await client.lpush(cache_key, json.dumps(ai_message_data))
        
        # 2. QueueServiceë¥¼ í†µí•œ MySQL ì˜êµ¬ ì €ì¥
        queue_service = QueueService.get_instance()
        await queue_service.send_message(
            queue_name="chat_persistence",
            payload={
                "type": "save_ai_response",
                "account_db_key": account_db_key,
                "shard_id": await self._get_user_shard(account_db_key),
                "message_data": ai_message_data
            },
            message_type="chat_save",
            priority=1  # ë†’ì€ ìš°ì„ ìˆœìœ„
        )
    
    async def _get_user_shard(self, account_db_key: int) -> int:
        """ì‚¬ìš©ì ìƒ¤ë“œ ID ì¡°íšŒ"""
        try:
            db_service = ServiceContainer.get_database_service()
            result = await db_service.execute_global_query(
                "SELECT shard_id FROM table_user_shard_mapping WHERE account_db_key = %s",
                (account_db_key,)
            )
            return result[0]['shard_id'] if result else 1
        except Exception as e:
            Logger.error(f"Error getting user shard: {e}")
            return 1
```

#### 2. SSE ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
```python
# base_server/application/base_web_server/routers/chat.py

from fastapi import APIRouter, Request, HTTPException
from fastapi.responses import StreamingResponse
from sse_starlette.sse import EventSourceResponse
from template.base.template_context import TemplateContext, TemplateType
from template.base.template_service import TemplateService
from template.chat.common.chat_serialize import *
from service.cache.cache_service import CacheService
from service.core.logger import Logger
import json
import asyncio
from datetime import datetime

router = APIRouter()

# ê¸°ì¡´ chat_protocol ì„¤ì •ì€ ìœ ì§€
chat_protocol = ChatProtocol()

def setup_chat_protocol_callbacks():
    """Chat protocol ì½œë°± ì„¤ì •"""
    chat_template = TemplateContext.get_template(TemplateType.CHAT)
    chat_protocol.on_chat_message_send_req_callback = getattr(chat_template, "on_chat_message_send_req", None)
    # ... ê¸°ì¡´ ì½œë°±ë“¤

@router.post("/stream")
async def stream_chat_response(request: ChatMessageSendRequest, req: Request):
    """LLM ì‘ë‹µì„ SSEë¡œ ìŠ¤íŠ¸ë¦¬ë°"""
    
    # 1. ì„¸ì…˜ ê²€ì¦ (TemplateService íŒ¨í„´ ë”°ë¼)
    ip = req.headers.get("X-Forwarded-For", req.client.host).split(", ")[0]
    
    async def generate_stream():
        try:
            # 2. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ (TemplateService.run_user íŒ¨í„´)
            save_result = await TemplateService.run_user(
                req.method,
                "/api/chat/message/send",  # ë‚´ë¶€ì ìœ¼ë¡œ ê¸°ì¡´ ë©”ì‹œì§€ ì €ì¥ ë¡œì§ ì‚¬ìš©
                ip,
                request.model_dump_json(),
                chat_protocol.chat_message_send_req_controller
            )
            
            result_data = json.loads(save_result)
            if result_data.get('errorCode', 1000) != 0:
                yield {
                    "event": "error",
                    "data": json.dumps({"error": "Failed to save message"})
                }
                return
            
            # 3. ìŠ¤íŠ¸ë¦¼ ìƒíƒœ ê´€ë¦¬
            stream_key = result_data.get('stream_key')
            message_id = result_data.get('message_id')
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì•Œë¦¼
            yield {
                "event": "start",
                "data": json.dumps({
                    "message_id": message_id,
                    "timestamp": datetime.now().isoformat()
                })
            }
            
            # 4. LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ì™¸ë¶€ LLM API í˜¸ì¶œ)
            full_response = ""
            sample_response = "ì•ˆë…•í•˜ì„¸ìš”! íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ì¢…ëª©ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”?"
            
            # ì²­í¬ ë‹¨ìœ„ë¡œ ì „ì†¡
            for i, char in enumerate(sample_response):
                # ì¤‘ë‹¨ ìš”ì²­ í™•ì¸
                async with CacheService.get_client() as client:
                    stop_check = await client.get_string(f"{stream_key}:stop")
                    if stop_check:
                        yield {
                            "event": "stopped",
                            "data": json.dumps({"reason": "User requested stop"})
                        }
                        return
                
                full_response += char
                
                # 3-5ìì”© ë¬¶ì–´ì„œ ì „ì†¡
                if (i + 1) % 3 == 0 or i == len(sample_response) - 1:
                    yield {
                        "event": "message",
                        "data": json.dumps({
                            "type": "content",
                            "content": char,
                            "delta": char
                        })
                    }
                    await asyncio.sleep(0.05)  # ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ íš¨ê³¼
            
            # 5. ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
            if request.analysis_symbols:
                analysis_results = {
                    "symbols": request.analysis_symbols,
                    "sentiment": "POSITIVE",
                    "recommendations": [
                        {
                            "symbol": symbol,
                            "action": "BUY",
                            "confidence": 0.75
                        } for symbol in request.analysis_symbols
                    ]
                }
                
                yield {
                    "event": "analysis",
                    "data": json.dumps(analysis_results)
                }
            
            # 6. AI ì‘ë‹µ ì €ì¥
            chat_template = TemplateContext.get_template(TemplateType.CHAT)
            await chat_template.save_streaming_response(
                account_db_key=1,  # ì‹¤ì œë¡œëŠ” ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜´
                room_id=request.room_id,
                ai_response=full_response,
                metadata={"analysis_symbols": request.analysis_symbols}
            )
            
            # ì™„ë£Œ ì‹œê·¸ë„
            yield {
                "event": "done",
                "data": json.dumps({
                    "message_length": len(full_response),
                    "timestamp": datetime.now().isoformat()
                })
            }
            
        except Exception as e:
            Logger.error(f"Stream error: {e}")
            yield {
                "event": "error",
                "data": json.dumps({"error": str(e)})
            }
        finally:
            # ìŠ¤íŠ¸ë¦¼ ìƒíƒœ ì •ë¦¬
            if 'stream_key' in locals():
                async with CacheService.get_client() as client:
                    await client.delete(stream_key)
                    await client.delete(f"{stream_key}:stop")
    
    # SSE ì‘ë‹µ ë°˜í™˜
    return EventSourceResponse(
        generate_stream(),
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",  # Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
        }
    )

@router.post("/stream/{room_id}/stop")
async def stop_stream(room_id: str, req: Request):
    """ì§„í–‰ ì¤‘ì¸ ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨"""
    ip = req.headers.get("X-Forwarded-For", req.client.host).split(", ")[0]
    
    # ì„ì‹œë¡œ account_db_key=1 ì‚¬ìš© (ì‹¤ì œë¡œëŠ” ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜´)
    stream_key = f"stream:1:{room_id}"
    
    async with CacheService.get_client() as client:
        await client.set_string(f"{stream_key}:stop", "true", expire=10)
    
    return {"status": "stop_requested"}

# ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
@router.post("/rooms")
async def chat_room_list(request: ChatRoomListRequest, req: Request):
    """ì±„íŒ…ë°© ëª©ë¡ ì¡°íšŒ"""
    ip = req.headers.get("X-Forwarded-For", req.client.host).split(", ")[0]
    return await TemplateService.run_user(
        req.method, req.url.path, ip,
        request.model_dump_json(),
        chat_protocol.chat_room_list_req_controller
    )

# ... ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ë“¤ ê³„ì†
```

#### 3. ë°±ê·¸ë¼ìš´ë“œ í ì²˜ë¦¬ê¸° (QueueService í™œìš©)
```python
# base_server/service/queue/chat_persistence_worker.py

from service.queue.queue_service import QueueService
from service.queue.message_queue import QueueMessage
from service.service_container import ServiceContainer
from service.core.logger import Logger
import json
import asyncio

class ChatPersistenceWorker:
    """ì±„íŒ… ë©”ì‹œì§€ë¥¼ MySQLì— ì˜êµ¬ ì €ì¥í•˜ëŠ” ì›Œì»¤"""
    
    def __init__(self):
        self.queue_service = QueueService.get_instance()
        self.db_service = ServiceContainer.get_database_service()
        self.running = False
        
    async def start(self):
        """í ì›Œì»¤ ì‹œì‘"""
        self.running = True
        
        # QueueServiceì˜ ë©”ì‹œì§€ ì†Œë¹„ìë¡œ ë“±ë¡
        await self.queue_service.register_message_consumer(
            queue_name="chat_persistence",
            consumer_id="chat_persistence_worker",
            callback=self._process_message
        )
        
        Logger.info("ChatPersistenceWorker started")
    
    async def stop(self):
        """í ì›Œì»¤ ì¤‘ì§€"""
        self.running = False
        Logger.info("ChatPersistenceWorker stopped")
    
    async def _process_message(self, message: QueueMessage) -> bool:
        """ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            msg_type = message.payload.get("type")
            
            if msg_type == "save_user_message":
                return await self._save_user_message(message.payload)
            elif msg_type == "save_ai_response":
                return await self._save_ai_response(message.payload)
            else:
                Logger.warn(f"Unknown message type: {msg_type}")
                return False
                
        except Exception as e:
            Logger.error(f"Message processing error: {e}")
            return False
    
    async def _save_user_message(self, payload: dict) -> bool:
        """ì‚¬ìš©ì ë©”ì‹œì§€ MySQL ì €ì¥"""
        try:
            data = payload["message_data"]
            shard_id = payload["shard_id"]
            
            # ê¸°ì¡´ í”„ë¡œì‹œì € ì‚¬ìš©
            result = await self.db_service.call_shard_procedure(
                shard_id,
                "fp_save_chat_message_direct",
                (
                    data["message_id"],
                    data["room_id"],
                    data["sender_type"],
                    data["content"],
                    json.dumps(data.get("metadata", {}))
                )
            )
            
            Logger.info(f"User message saved to MySQL: {data['message_id']}")
            return True
            
        except Exception as e:
            Logger.error(f"Failed to save user message: {e}")
            return False
    
    async def _save_ai_response(self, payload: dict) -> bool:
        """AI ì‘ë‹µ MySQL ì €ì¥"""
        try:
            data = payload["message_data"]
            shard_id = payload["shard_id"]
            
            result = await self.db_service.call_shard_procedure(
                shard_id,
                "fp_save_chat_message_direct",
                (
                    data["message_id"],
                    data["room_id"],
                    data["sender_type"],
                    data["content"],
                    json.dumps(data.get("metadata", {}))
                )
            )
            
            Logger.info(f"AI response saved to MySQL: {data['message_id']}")
            return True
            
        except Exception as e:
            Logger.error(f"Failed to save AI response: {e}")
            return False

# main.pyì—ì„œ ì›Œì»¤ ì‹œì‘
async def start_chat_persistence_worker():
    """ì±„íŒ… ì˜ì†ì„± ì›Œì»¤ ì‹œì‘"""
    if QueueService._initialized:
        worker = ChatPersistenceWorker()
        await worker.start()
        return worker
    return None
```

---

## 2. LLM ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„ ë°©ì‹ ê²°ì •

### ğŸ¤” ì˜ì‚¬ê²°ì • ê³¼ì •

#### ê³ ë¯¼í–ˆë˜ ì„ íƒì§€ë“¤

| ì„ íƒì§€ | ì¥ì  | ë‹¨ì  | íŒë‹¨ |
|--------|------|------|------|
| **SSE** | â€¢ HTTP ê¸°ë°˜ (ì¸í”„ë¼ í˜¸í™˜)<br>â€¢ ìë™ ì¬ì—°ê²°<br>â€¢ êµ¬í˜„ ë‹¨ìˆœ | â€¢ ë‹¨ë°©í–¥ í†µì‹ ë§Œ ê°€ëŠ¥<br>â€¢ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡ | âœ… LLM ìŠ¤íŠ¸ë¦¬ë°ì— ìµœì  |
| **WebSocket** | â€¢ ì–‘ë°©í–¥ ì‹¤ì‹œê°„ í†µì‹ <br>â€¢ ë°”ì´ë„ˆë¦¬ ì§€ì› | â€¢ í”„ë¡ì‹œ ì„¤ì • ë³µì¡<br>â€¢ Sticky session í•„ìš” | âŒ í˜„ì¬ ìš”êµ¬ì‚¬í•­ì— ê³¼ë„í•¨ |

#### ğŸ¯ ìµœì¢… ì„ íƒ: SSE (Server-Sent Events)

**ì„ íƒ ì´ìœ :**
1. LLM ìŠ¤íŠ¸ë¦¬ë°ì€ ë³¸ì§ˆì ìœ¼ë¡œ ë‹¨ë°©í–¥ í†µì‹ 
2. ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ ì¬ì—°ê²° ì²˜ë¦¬
3. ëª¨ë“  HTTP ì¸í”„ë¼ì™€ ì™„ë²½ í˜¸í™˜
4. FastAPIì—ì„œ EventSourceResponse ë„¤ì´í‹°ë¸Œ ì§€ì›

### ğŸ’» í”„ë¡ íŠ¸ì—”ë“œ í†µí•© ì½”ë“œ

#### React Hook êµ¬í˜„ (base_server í”„ë¡ íŠ¸ì—”ë“œì™€ í†µí•©)
```typescript
// base_server/frontend/ai-trading-platform/hooks/use-chat-stream.ts

import { useCallback, useRef, useState } from 'react';
import { useAppDispatch, useAppSelector } from '@/lib/store/hooks';
import { addMessage, updateStreamingMessage } from '@/lib/store/slices/chat-slice';

interface StreamOptions {
  roomId: string;
  content: string;
  includePortfolio?: boolean;
  analysisSymbols?: string[];
}

export function useChatStream() {
  const dispatch = useAppDispatch();
  const { user } = useAppSelector((state) => state.auth);
  const [isStreaming, setIsStreaming] = useState(false);
  const eventSourceRef = useRef<EventSource | null>(null);
  const currentMessageRef = useRef<string>('');

  const startStream = useCallback(async (options: StreamOptions) => {
    if (isStreaming) return;
    
    setIsStreaming(true);
    currentMessageRef.current = '';

    try {
      // 1. SSE ì—°ê²° ì‹œì‘ (base_server API ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
      const params = new URLSearchParams({
        room_id: options.roomId,
        content: options.content,
        include_portfolio: String(options.includePortfolio || false),
        analysis_symbols: JSON.stringify(options.analysisSymbols || [])
      });

      const eventSource = new EventSource(
        `/api/chat/stream?${params}`,
        { withCredentials: true }
      );

      // 2. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
      eventSource.addEventListener('start', (event) => {
        const data = JSON.parse(event.data);
        dispatch(addMessage({
          id: data.message_id,
          roomId: options.roomId,
          type: 'ai',
          content: '',
          timestamp: data.timestamp,
          isStreaming: true
        }));
      });

      eventSource.addEventListener('message', (event) => {
        const data = JSON.parse(event.data);
        if (data.type === 'content') {
          currentMessageRef.current += data.content;
          dispatch(updateStreamingMessage({
            roomId: options.roomId,
            content: currentMessageRef.current
          }));
        }
      });

      eventSource.addEventListener('analysis', (event) => {
        const analysisData = JSON.parse(event.data);
        // ë¶„ì„ ê²°ê³¼ë¥¼ í¬íŠ¸í´ë¦¬ì˜¤ ìŠ¬ë¼ì´ìŠ¤ì— ì—…ë°ì´íŠ¸
        console.log('Analysis results:', analysisData);
      });

      eventSource.addEventListener('done', (event) => {
        dispatch(updateStreamingMessage({
          roomId: options.roomId,
          content: currentMessageRef.current,
          isStreaming: false
        }));
        eventSource.close();
        setIsStreaming(false);
      });

      eventSource.addEventListener('error', (event) => {
        console.error('SSE Error:', event);
        eventSource.close();
        setIsStreaming(false);
      });

      eventSourceRef.current = eventSource;

    } catch (error) {
      console.error('Stream error:', error);
      setIsStreaming(false);
    }
  }, [dispatch, isStreaming]);

  const stopStream = useCallback(async (roomId: string) => {
    if (eventSourceRef.current) {
      eventSourceRef.current.close();
      eventSourceRef.current = null;
    }

    // ì„œë²„ì— ì¤‘ë‹¨ ìš”ì²­
    await fetch(`/api/chat/stream/${roomId}/stop`, {
      method: 'POST',
      credentials: 'include'
    });

    setIsStreaming(false);
  }, []);

  return { startStream, stopStream, isStreaming };
}
```

### ğŸš€ ìš´ì˜ í™˜ê²½ ì„¤ì •

#### Nginx ì„¤ì • (base_server ë°°í¬ìš©)
```nginx
# /etc/nginx/sites-available/base_server

upstream base_server_backend {
    server 127.0.0.1:8000;
    server 127.0.0.1:8001;
    server 127.0.0.1:8002;
}

server {
    listen 443 ssl http2;
    server_name api.base-server.com;

    # SSE ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
    location /api/chat/stream {
        proxy_pass http://base_server_backend;
        
        # SSE í•„ìˆ˜ ì„¤ì •
        proxy_set_header Connection '';
        proxy_http_version 1.1;
        chunked_transfer_encoding off;
        proxy_buffering off;
        proxy_cache off;
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì • (LLM ì‘ë‹µ ì‹œê°„ ê³ ë ¤)
        proxy_read_timeout 300s;
        keepalive_timeout 300s;
        
        # í—¤ë” ì„¤ì •
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # ì¼ë°˜ API ì—”ë“œí¬ì¸íŠ¸
    location /api {
        proxy_pass http://base_server_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

---

## 3. base_server ì•„í‚¤í…ì²˜ í†µí•© ì¸ì‚¬ì´íŠ¸

### ğŸ“Š ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤

| ê¸°ì¤€ | ê°€ì¤‘ì¹˜ | Redis+MySQL | Redis+ES | SSE | WebSocket |
|------|--------|-------------|----------|-----|-----------|
| ê¸°ì¡´ ì¸í”„ë¼ í™œìš© | 30% | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| êµ¬í˜„ ë³µì¡ë„ | 25% | â­â­â­â­ | â­â­ | â­â­â­â­â­ | â­â­ |
| ìš´ì˜ ì•ˆì •ì„± | 25% | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| ë¹„ìš© íš¨ìœ¨ì„± | 20% | â­â­â­â­â­ | â­â­ | â­â­â­â­â­ | â­â­â­â­ |

### ğŸ¯ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

```
"ìµœê³ ì˜ ê¸°ìˆ " â‰  "ìµœì ì˜ ê¸°ìˆ "
```

#### base_serverì˜ ê°•ì  í™œìš©
1. **ServiceContainer íŒ¨í„´**: ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì¤‘ì•™ ì§‘ì¤‘ì‹ìœ¼ë¡œ ê´€ë¦¬
2. **TemplateService íŒ¨í„´**: ì¸ì¦/ì„¸ì…˜ ê´€ë¦¬ê°€ ì´ë¯¸ êµ¬í˜„ë¨
3. **QueueService**: ë©”ì‹œì§€í/ì´ë²¤íŠ¸í ì¸í”„ë¼ ì¤€ë¹„ë¨
4. **Protocol ê¸°ë°˜ í†µì‹ **: íƒ€ì… ì•ˆì „í•œ API í†µì‹  êµ¬ì¡°

#### ì ì§„ì  í™•ì¥ ì „ëµ
```
Phase 1: SSE + Redis/MySQL (âœ… í˜„ì¬)
         â†“
Phase 2: + OpenSearch (í–¥í›„ ê²€ìƒ‰ ê°•í™”)
         â†“  
Phase 3: + WebSocket (ì‹¤ì‹œê°„ í˜‘ì—… ì‹œ)
```

### ğŸ’¡ ë°°ìš´ ì 

1. **ê¸°ì¡´ ì•„í‚¤í…ì²˜ ì¡´ì¤‘**
   - base_serverì˜ Template-Service-Protocol íŒ¨í„´ í™œìš©
   - ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ë³´ë‹¤ ê¸°ì¡´ êµ¬ì¡°ì— ë§ëŠ” í™•ì¥

2. **ì‹¤ìš©ì£¼ì˜ì  ì ‘ê·¼**
   - ì§€ê¸ˆ ë‹¹ì¥ í•„ìš”í•œ ê²ƒì— ì§‘ì¤‘
   - ê³¼ë„í•œ ë¯¸ë˜ ì¤€ë¹„ë³´ë‹¤ ì ì§„ì  ê°œì„ 

3. **íŒ€ ì—­ëŸ‰ ê³ ë ¤**
   - ì´ë¯¸ ìˆ™ë ¨ëœ íŒ¨í„´ê³¼ ë„êµ¬ í™œìš©
   - ìƒˆë¡œìš´ ê¸°ìˆ  í•™ìŠµë³´ë‹¤ ê¸°ì¡´ ì—­ëŸ‰ ê·¹ëŒ€í™”

---

## 4. êµ¬í˜„ ê³„íš

### Phase 1: ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„
- [ ] ChatTemplateImplì— ìŠ¤íŠ¸ë¦¬ë° ë©”ì„œë“œ ì¶”ê°€
- [ ] chat ë¼ìš°í„°ì— SSE ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- [ ] ChatPersistenceWorker êµ¬í˜„ ë° ë“±ë¡

### Phase 2: í”„ë¡ íŠ¸ì—”ë“œ í†µí•©  
- [ ] useChatStream í›… êµ¬í˜„
- [ ] chat-sliceì— ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì¶”ê°€
- [ ] ì±„íŒ… UI ì»´í¬ë„ŒíŠ¸ ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‘

### Phase 3: ìš´ì˜ í™˜ê²½ ì¤€ë¹„
- [ ] Nginx ì„¤ì • ì—…ë°ì´íŠ¸  
- [ ] ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì„¤ì •
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ìµœì í™”

---

ì´ë²ˆ ì£¼ì°¨ë¥¼ í†µí•´ **"ì™œ ì´ ê¸°ìˆ ì„ ì„ íƒí–ˆëŠ”ê°€?"**ë¼ëŠ” ì§ˆë¬¸ì— ëª…í™•íˆ ë‹µí•  ìˆ˜ ìˆëŠ” ì˜ì‚¬ê²°ì • ì—­ëŸ‰ê³¼ í•¨ê»˜, **ê¸°ì¡´ ì•„í‚¤í…ì²˜ë¥¼ ì¡´ì¤‘í•˜ë©´ì„œë„ í˜„ëŒ€ì  ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²•**ì„ í•™ìŠµí•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì‹¤ë¬´ì—ì„œëŠ” ìµœì‹  ê¸°ìˆ ë³´ë‹¤ **íŒ€ê³¼ í”„ë¡œì íŠ¸ì— ì í•©í•œ ê¸°ìˆ  ì„ íƒ**ì´ ì„±ê³µì˜ í•µì‹¬ì„ì„ ë‹¤ì‹œ í•œë²ˆ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤.