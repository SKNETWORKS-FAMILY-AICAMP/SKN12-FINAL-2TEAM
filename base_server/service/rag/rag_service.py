import asyncio
import hashlib
import time
from typing import Optional, Dict, Any, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from service.rag.rag_config import RagConfig
from service.rag.rag_vectordb_client import RagVectorDbClient, RagVectorDbConfig
from service.core.logger import Logger

class RagService:
    """
    RAG (Retrieval-Augmented Generation) ì„œë¹„ìŠ¤
    
    SearchService(í‚¤ì›Œë“œ ê²€ìƒ‰)ì™€ VectorDbService(ë²¡í„° ê²€ìƒ‰)ë¥¼ ì¡°í•©í•œ 
    í•˜ì´ë¸Œë¦¬ë“œ ë¬¸ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì •ì  í´ë˜ìŠ¤ (111 íŒ¨í„´)
    """
    
    # 111 íŒ¨í„´ ìƒíƒœ ê´€ë¦¬
    _initialized: bool = False
    _config: Optional[RagConfig] = None
    _search_available: bool = False
    _vector_available: bool = False
    
    # RAG ì „ìš© ë²¡í„° í´ë¼ì´ì–¸íŠ¸ (coroutine ì¬ì‚¬ìš© ë¬¸ì œ í•´ê²°)
    _rag_vector_client: Optional[RagVectorDbClient] = None
    
    # ì„±ëŠ¥ í†µê³„
    _stats = {
        "documents_indexed": 0,
        "search_requests": 0,
        "hybrid_searches": 0,
        "avg_search_time": 0.0
    }

    @classmethod
    def init(cls, rag_config: RagConfig) -> bool:
        """
        RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (111 íŒ¨í„´)
        
        Args:
            rag_config: RAG ì„œë¹„ìŠ¤ ì„¤ì •
            
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            Logger.info("ğŸš€ RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
            
            if cls._initialized:
                Logger.warn("âš ï¸ RAG ì„œë¹„ìŠ¤ê°€ ì´ë¯¸ ì´ˆê¸°í™”ë¨")
                return True
            
            # ì„¤ì • ê²€ì¦
            if not cls._validate_config(rag_config):
                Logger.error("âŒ RAG ì„¤ì • ê²€ì¦ ì‹¤íŒ¨")
                return False
            
            cls._config = rag_config
            
            # ì˜ì¡´ ì„œë¹„ìŠ¤ ìƒíƒœ ê²€ì¦
            if not cls._validate_dependencies():
                Logger.error("âŒ ì˜ì¡´ ì„œë¹„ìŠ¤ ê²€ì¦ ì‹¤íŒ¨")
                return False
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ê²€ì¦
            if not cls._validate_hybrid_setup():
                Logger.error("âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨")
                return False
            
            # í†µê³„ ì´ˆê¸°í™”
            cls._reset_stats()
            
            cls._initialized = True
            Logger.info(f"âœ… RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            Logger.info(f"   - ë²¡í„° ê²€ìƒ‰: {'í™œì„±í™”' if cls._vector_available else 'ë¹„í™œì„±í™”'}")
            Logger.info(f"   - í‚¤ì›Œë“œ ê²€ìƒ‰: {'í™œì„±í™”' if cls._search_available else 'ë¹„í™œì„±í™”'}")
            Logger.info(f"   - í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ: {'í™œì„±í™”' if (cls._vector_available and cls._search_available) else 'ë¹„í™œì„±í™”'}")
            
            return True
            
        except Exception as e:
            Logger.error(f"âŒ RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            cls._initialized = False
            cls._config = None
            return False

    @classmethod
    def _validate_config(cls, config: RagConfig) -> bool:
        """RAG ì„¤ì • ê²€ì¦"""
        try:
            if not config.collection_name:
                Logger.error("collection_nameì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return False
            
            if not config.embedding_model:
                Logger.error("embedding_modelì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return False
            
            if config.default_k <= 0:
                Logger.error(f"default_këŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•¨: {config.default_k}")
                return False
            
            if not (0.0 <= config.default_threshold <= 1.0):
                Logger.error(f"default_thresholdëŠ” 0.0~1.0 ì‚¬ì´ì—¬ì•¼ í•¨: {config.default_threshold}")
                return False
            
            Logger.debug("RAG ì„¤ì • ê²€ì¦ í†µê³¼")
            return True
            
        except Exception as e:
            Logger.error(f"RAG ì„¤ì • ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    @classmethod
    def _validate_dependencies(cls) -> bool:
        """ì˜ì¡´ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ìƒíƒœ ê²€ì¦"""
        try:
            from service.search.search_service import SearchService
            from service.vectordb.vectordb_service import VectorDbService
            
            # SearchService ìƒíƒœ í™•ì¸
            cls._search_available = SearchService.is_initialized()
            Logger.info(f"SearchService ìƒíƒœ: {'ì‚¬ìš© ê°€ëŠ¥' if cls._search_available else 'ì‚¬ìš© ë¶ˆê°€'}")
            
            # VectorDbService ìƒíƒœ í™•ì¸
            cls._vector_available = VectorDbService.is_initialized()
            Logger.info(f"VectorDbService ìƒíƒœ: {'ì‚¬ìš© ê°€ëŠ¥' if cls._vector_available else 'ì‚¬ìš© ë¶ˆê°€'}")
            
            # RAG ì „ìš© ë²¡í„° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (coroutine ì¬ì‚¬ìš© ë¬¸ì œ í•´ê²°)
            if cls._vector_available and cls._config.enable_vector_db:
                try:
                    # RAG ì„¤ì •ì—ì„œ ë²¡í„° DB ì„¤ì • ì¶”ì¶œ
                    vector_config = RagVectorDbConfig(
                        aws_access_key_id=cls._config.aws_access_key_id,
                        aws_secret_access_key=cls._config.aws_secret_access_key,
                        region_name=cls._config.region_name,
                        knowledge_base_id=cls._config.knowledge_base_id,
                        aws_session_token=getattr(cls._config, 'aws_session_token', None),
                        max_retries=3,
                        retry_delay_base=1.0,
                        timeout=30.0
                    )
                    
                    cls._rag_vector_client = RagVectorDbClient(vector_config)
                    Logger.info("âœ… RAG ì „ìš© ë²¡í„° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                    
                except Exception as e:
                    Logger.error(f"âŒ RAG ì „ìš© ë²¡í„° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    cls._vector_available = False
            
            # ìµœì†Œ í•˜ë‚˜ì˜ ì„œë¹„ìŠ¤ëŠ” ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•¨
            if not (cls._search_available or cls._vector_available):
                Logger.error("Searchì™€ Vector ì„œë¹„ìŠ¤ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
                return False
            
            return True
            
        except Exception as e:
            Logger.error(f"ì˜ì¡´ ì„œë¹„ìŠ¤ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    @classmethod
    def _validate_hybrid_setup(cls) -> bool:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ê²€ì¦"""
        try:
            # ë²¡í„° DB ì„¤ì • í™•ì¸
            if cls._config.enable_vector_db and not cls._vector_available:
                Logger.warn("ë²¡í„° DB í™œì„±í™” ì„¤ì •ì´ì§€ë§Œ VectorDbServiceê°€ ì‚¬ìš© ë¶ˆê°€")
                
            # Fallback ê²€ìƒ‰ ì„¤ì • í™•ì¸
            if cls._config.enable_fallback_search and not cls._search_available:
                Logger.warn("Fallback ê²€ìƒ‰ í™œì„±í™” ì„¤ì •ì´ì§€ë§Œ SearchServiceê°€ ì‚¬ìš© ë¶ˆê°€")
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ëŠ¥ì„± í™•ì¸
            hybrid_possible = cls._search_available and cls._vector_available
            if hybrid_possible:
                Logger.info("ğŸ” ì™„ì „í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ëŠ¥")
            else:
                Logger.warn("âš ï¸ ì œí•œëœ ê²€ìƒ‰ ëª¨ë“œë¡œ ë™ì‘")
            
            return True
            
        except Exception as e:
            Logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    @classmethod
    def _reset_stats(cls):
        """í†µê³„ ì´ˆê¸°í™”"""
        cls._stats = {
            "documents_indexed": 0,
            "search_requests": 0,
            "hybrid_searches": 0,
            "avg_search_time": 0.0
        }

    @classmethod
    async def add_documents(cls, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ì¸ì§€ì…˜ íŒŒì´í”„ë¼ì¸ - ë‘ ì„œë¹„ìŠ¤ì— ë³‘ë ¬ ì €ì¥
        
        Args:
            documents: ì €ì¥í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
                [{"id": str, "content": str, "metadata": dict}, ...]
                
        Returns:
            Dict: ì €ì¥ ê²°ê³¼ í†µê³„
        """
        if not cls._initialized:
            raise RuntimeError("RAG ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        start_time = time.time()
        Logger.info(f"ğŸ“„ ë¬¸ì„œ ì¸ì§€ì…˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {len(documents)}ê°œ ë¬¸ì„œ")
        
        try:
            # ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ê²€ì¦
            processed_docs = cls._preprocess_documents(documents)
            if not processed_docs:
                Logger.warn("ì²˜ë¦¬í•  ìœ íš¨í•œ ë¬¸ì„œê°€ ì—†ìŒ")
                return {"success": False, "message": "ìœ íš¨í•œ ë¬¸ì„œê°€ ì—†ìŒ"}
            
            # ë¬¸ì„œ ì²­í‚¹ (ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• )
            chunked_docs = cls._chunk_documents(processed_docs)
            Logger.info(f"ğŸ“ ë¬¸ì„œ ì²­í‚¹ ì™„ë£Œ: {len(chunked_docs)}ê°œ ì²­í¬")
            
            # ë³‘ë ¬ ì €ì¥ ì‹¤í–‰
            storage_results = await cls._parallel_storage(chunked_docs)
            
            # ê²°ê³¼ ì§‘ê³„
            total_time = time.time() - start_time
            success_count = storage_results.get("success_count", 0)
            error_count = storage_results.get("error_count", 0)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            cls._stats["documents_indexed"] += success_count
            
            Logger.info(f"âœ… ë¬¸ì„œ ì¸ì§€ì…˜ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨ ({total_time:.2f}ì´ˆ)")
            
            return {
                "success": error_count == 0,
                "total_documents": len(documents),
                "total_chunks": len(chunked_docs),
                "success_count": success_count,
                "error_count": error_count,
                "processing_time": total_time,
                "storage_details": storage_results
            }
            
        except Exception as e:
            Logger.error(f"âŒ ë¬¸ì„œ ì¸ì§€ì…˜ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time
            }

    @classmethod
    def _preprocess_documents(cls, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ê²€ì¦"""
        processed = []
        
        for i, doc in enumerate(documents):
            try:
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if not isinstance(doc, dict):
                    Logger.warn(f"ë¬¸ì„œ {i}: dict íƒ€ì…ì´ ì•„ë‹˜")
                    continue
                    
                if "content" not in doc or not doc["content"]:
                    Logger.warn(f"ë¬¸ì„œ {i}: content í•„ë“œ ì—†ìŒ")
                    continue
                
                # ID ìƒì„± (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
                if "id" not in doc or not doc["id"]:
                    doc["id"] = cls._generate_document_id(doc["content"])
                
                # ë©”íƒ€ë°ì´í„° ê¸°ë³¸ê°’ ì„¤ì •
                if "metadata" not in doc:
                    doc["metadata"] = {}
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                doc["metadata"]["indexed_at"] = time.time()
                
                processed.append(doc)
                
            except Exception as e:
                Logger.warn(f"ë¬¸ì„œ {i} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        return processed

    @classmethod
    def _generate_document_id(cls, content: str) -> str:
        """ë¬¸ì„œ ë‚´ìš© ê¸°ë°˜ ID ìƒì„±"""
        return f"doc_{hashlib.md5(content.encode('utf-8')).hexdigest()[:16]}"

    @classmethod
    def _chunk_documents(cls, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ì²­í‚¹ - ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• """
        chunks = []
        max_chunk_size = cls._config.max_content_length
        
        for doc in documents:
            content = doc["content"]
            
            # ë¬¸ì„œê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
            if len(content) <= max_chunk_size:
                chunks.append(doc)
                continue
            
            # ê¸´ ë¬¸ì„œëŠ” ì²­í‚¹
            chunk_texts = cls._split_text(content, max_chunk_size)
            
            for i, chunk_text in enumerate(chunk_texts):
                chunk_doc = {
                    "id": f"{doc['id']}_chunk_{i}",
                    "content": chunk_text,
                    "metadata": {
                        **doc["metadata"],
                        "parent_id": doc["id"],
                        "chunk_index": i,
                        "total_chunks": len(chunk_texts)
                    }
                }
                chunks.append(chunk_doc)
        
        return chunks

    @classmethod
    def _split_text(cls, text: str, max_size: int) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ë¶„í• """
        if len(text) <= max_size:
            return [text]
        
        chunks = []
        sentences = text.split('. ')
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk + sentence) <= max_size:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks

    @classmethod
    async def _parallel_storage(cls, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë‘ ì„œë¹„ìŠ¤ì— ë³‘ë ¬ë¡œ ë¬¸ì„œ ì €ì¥"""
        search_results = []
        vector_results = []
        
        # ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ íƒœìŠ¤í¬ ìƒì„±
        tasks = []
        
        if cls._search_available:
            tasks.append(cls._store_to_search_service(documents))
        
        if cls._vector_available:
            tasks.append(cls._store_to_vector_service(documents))
        
        # ë³‘ë ¬ ì‹¤í–‰
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ë¶„ì„
            success_count = 0
            error_count = 0
            
            for result in results:
                if isinstance(result, Exception):
                    Logger.error(f"ì €ì¥ íƒœìŠ¤í¬ ì‹¤íŒ¨: {result}")
                    error_count += len(documents)
                else:
                    success_count += result.get("success_count", 0)
                    error_count += result.get("error_count", 0)
        
        return {
            "success_count": success_count,
            "error_count": error_count,
            "search_results": search_results,
            "vector_results": vector_results
        }

    @classmethod
    async def _store_to_search_service(cls, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """OpenSearchì— ë¬¸ì„œ ì €ì¥"""
        try:
            from service.search.search_service import SearchService
            
            Logger.debug(f"OpenSearchì— {len(documents)}ê°œ ë¬¸ì„œ ì €ì¥ ì‹œì‘")
            
            success_count = 0
            error_count = 0
            
            # OpenSearch í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì‚¬ìš©
            client = SearchService.get_client()
            if not client:
                raise Exception("OpenSearch í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ")
            
            index_name = cls._config.collection_name
            
            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
            for doc in documents:
                try:
                    # ë¬¸ì„œ ì¸ë±ì‹±
                    response = await SearchService.index_document(
                        index_name, 
                        {
                            "content": doc["content"],
                            "metadata": doc["metadata"]
                        },
                        doc["id"]
                    )
                    
                    if response:
                        success_count += 1
                    else:
                        error_count += 1
                        
                except Exception as e:
                    Logger.warn(f"ë¬¸ì„œ {doc['id']} OpenSearch ì €ì¥ ì‹¤íŒ¨: {e}")
                    error_count += 1
            
            Logger.info(f"OpenSearch ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
            
            return {
                "service": "search",
                "success_count": success_count,
                "error_count": error_count
            }
            
        except Exception as e:
            Logger.error(f"OpenSearch ì €ì¥ ì‹¤íŒ¨: {e}")
            return {
                "service": "search",
                "success_count": 0,
                "error_count": len(documents),
                "error": str(e)
            }

    @classmethod
    async def _store_to_vector_service(cls, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """VectorDBì— ë¬¸ì„œ ì €ì¥"""
        try:
            from service.vectordb.vectordb_service import VectorDbService
            
            Logger.debug(f"VectorDBì— {len(documents)}ê°œ ë¬¸ì„œ ì €ì¥ ì‹œì‘")
            
            success_count = 0
            error_count = 0
            
            for doc in documents:
                try:
                    # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
                    embed_result = await VectorDbService.embed_text(doc["content"])
                    
                    if not embed_result.get("success"):
                        Logger.warn(f"ë¬¸ì„œ {doc['id']} ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                        error_count += 1
                        continue
                    
                    # ë²¡í„° ì €ì¥ (ì‹¤ì œ êµ¬í˜„ì€ VectorDbServiceì˜ ë©”ì„œë“œ í™•ì¸ í•„ìš”)
                    # ì—¬ê¸°ì„œëŠ” ì„ë² ë”©ì´ ì„±ê³µí–ˆë‹¤ê³  ê°€ì •
                    success_count += 1
                    
                except Exception as e:
                    Logger.warn(f"ë¬¸ì„œ {doc['id']} VectorDB ì €ì¥ ì‹¤íŒ¨: {e}")
                    error_count += 1
            
            Logger.info(f"VectorDB ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
            
            return {
                "service": "vector",
                "success_count": success_count,
                "error_count": error_count
            }
            
        except Exception as e:
            Logger.error(f"VectorDB ì €ì¥ ì‹¤íŒ¨: {e}")
            return {
                "service": "vector",
                "success_count": 0,
                "error_count": len(documents),
                "error": str(e)
            }

    @classmethod
    async def retrieve(cls, 
                      query: str, 
                      top_k: Optional[int] = None, 
                      hybrid: bool = True,
                      bm25_weight: float = 0.5,
                      vector_weight: float = 0.5) -> List[Dict[str, Any]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ - BM25ì™€ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì¡°í•©
        
        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’: config.default_k)
            hybrid: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš© ì—¬ë¶€
            bm25_weight: BM25 ì ìˆ˜ ê°€ì¤‘ì¹˜
            vector_weight: ë²¡í„° ì ìˆ˜ ê°€ì¤‘ì¹˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not cls._initialized:
            raise RuntimeError("RAG ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        start_time = time.time()
        k = top_k or cls._config.default_k
        
        Logger.info(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘: '{query}' (k={k}, hybrid={hybrid})")
        
        try:
            cls._stats["search_requests"] += 1
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
            if hybrid and cls._search_available and cls._vector_available:
                cls._stats["hybrid_searches"] += 1
                results = await cls._hybrid_search(query, k, bm25_weight, vector_weight)
            elif cls._vector_available:
                Logger.info("ë²¡í„° ê²€ìƒ‰ ëª¨ë“œ")
                results = await cls._vector_search_only(query, k)
            elif cls._search_available:
                Logger.info("í‚¤ì›Œë“œ ê²€ìƒ‰ ëª¨ë“œ")
                results = await cls._bm25_search_only(query, k)
            else:
                Logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ìƒ‰ ì„œë¹„ìŠ¤ê°€ ì—†ìŒ")
                return []
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            search_time = time.time() - start_time
            cls._update_search_stats(search_time)
            
            Logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ ({search_time:.3f}ì´ˆ)")
            
            return results
            
        except Exception as e:
            Logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    @classmethod
    async def _hybrid_search(cls, 
                           query: str, 
                           k: int, 
                           bm25_weight: float, 
                           vector_weight: float) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        Logger.debug("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë“œ ì‹œì‘")
        
        # ë³‘ë ¬ë¡œ ë‘ ê°€ì§€ ê²€ìƒ‰ ì‹¤í–‰
        bm25_task = cls._bm25_search_only(query, k * 2)  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ë‹¤ì–‘ì„± í™•ë³´
        vector_task = cls._vector_search_only(query, k * 2)
        
        bm25_results, vector_results = await asyncio.gather(bm25_task, vector_task)
        
        # ì ìˆ˜ í•©ì„± ë° ìˆœìœ„ ê²°ì •
        combined_results = cls._fuse_search_results(
            bm25_results, vector_results, 
            bm25_weight, vector_weight
        )
        
        # ìƒìœ„ Kê°œ ë°˜í™˜
        return combined_results[:k]

    @classmethod
    async def _bm25_search_only(cls, query: str, k: int) -> List[Dict[str, Any]]:
        """BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ ì‹¤í–‰ - í¬ë¡¤ëŸ¬ êµ¬ì¡°ì— ë§ì¶¤"""
        try:
            from service.search.search_service import SearchService
            
            # í¬ë¡¤ëŸ¬ì—ì„œ ì €ì¥í•œ OpenSearch êµ¬ì¡°ì— ë§ì¶¤
            search_query = {
                "query": {
                    "multi_match": {
                        "query": query,
                        "fields": ["title", "ticker", "source"],  # í¬ë¡¤ëŸ¬ êµ¬ì¡°
                        "type": "best_fields"
                    }
                },
                "size": k
            }
            
            # í¬ë¡¤ëŸ¬ê°€ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ì¸ë±ìŠ¤ ì´ë¦„ìœ¼ë¡œ ìˆ˜ì •
            response = await SearchService.search("yahoo_finance_news", search_query)
            
            if not response:
                return []
            
            results = []
            for hit in response.get("hits", {}).get("hits", []):
                source_data = hit["_source"]
                
                # í¬ë¡¤ëŸ¬ êµ¬ì¡°ì—ì„œ titleê³¼ source ì¶”ì¶œ
                title = source_data.get("title", "No title")
                source = source_data.get("source", "unknown")
                
                # í¬ë¡¤ëŸ¬ êµ¬ì¡°ì— ë§ì¶° ë©”íƒ€ë°ì´í„° êµ¬ì„±
                metadata = {
                    "title": title,
                    "source": source,
                    "ticker": source_data.get("ticker", ""),
                    "date": source_data.get("date", ""),
                    "link": source_data.get("link", ""),
                    "content_type": source_data.get("content_type", ""),
                    "task_id": source_data.get("task_id", ""),
                    "collected_at": source_data.get("collected_at", ""),
                    "created_at": source_data.get("created_at", "")
                }
                
                # í¬ë¡¤ëŸ¬ì—ì„œëŠ” titleì´ ì‹¤ì œ ë‰´ìŠ¤ ì œëª©ì´ë¯€ë¡œ contentë¡œ ì‚¬ìš©
                content = title
                
                result = {
                    "id": hit["_id"],
                    "content": content,
                    "metadata": metadata,
                    "score": hit["_score"],
                    "search_type": "bm25"
                }
                results.append(result)
            
            return results
            
        except Exception as e:
            Logger.error(f"BM25 ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    @classmethod
    async def _vector_search_only(cls, query: str, k: int) -> List[Dict[str, Any]]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ë§Œ ì‹¤í–‰ - RAG ì „ìš© í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©"""
        try:
            # RAG ì „ìš© ë²¡í„° í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (coroutine ì¬ì‚¬ìš© ë¬¸ì œ í•´ê²°)
            if cls._rag_vector_client:
                vector_results = await cls._rag_vector_client.similarity_search(
                    query=query,
                    top_k=k
                )
                
                if not vector_results.get("success"):
                    Logger.warn(f"RAG ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {vector_results.get('error', 'Unknown error')}")
                    return []
                
                results = []
                for result in vector_results.get("results", []):
                    doc_result = {
                        "id": result.get("id", ""),
                        "content": result.get("content", ""),
                        "metadata": result.get("metadata", {}),
                        "score": result.get("score", 0.0),
                        "search_type": "vector"
                    }
                    results.append(doc_result)
                
                return results
            
            else:
                # Fallback: ê¸°ì¡´ VectorDbService ì‚¬ìš©
                from service.vectordb.vectordb_service import VectorDbService
                
                # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
                embed_result = await VectorDbService.embed_text(query)
                
                if not embed_result.get("success"):
                    Logger.warn("ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                    return []
                
                # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
                vector_results = await VectorDbService.similarity_search(
                    query=query,
                    top_k=k
                )
                
                if not vector_results:
                    return []
                
                results = []
                for result in vector_results.get("results", []):
                    doc_result = {
                        "id": result.get("id", ""),
                        "content": result.get("content", ""),
                        "metadata": result.get("metadata", {}),
                        "score": result.get("score", 0.0),
                        "search_type": "vector"
                    }
                    results.append(doc_result)
                
                return results
            
        except Exception as e:
            Logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    @classmethod
    def _fuse_search_results(cls,
                           bm25_results: List[Dict[str, Any]],
                           vector_results: List[Dict[str, Any]],
                           bm25_weight: float,
                           vector_weight: float) -> List[Dict[str, Any]]:
        """BM25ì™€ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ í•©ì„±"""
        
        # ê²°ê³¼ë¥¼ IDë¡œ ë§¤í•‘
        bm25_map = {r["id"]: r for r in bm25_results}
        vector_map = {r["id"]: r for r in vector_results}
        
        # ëª¨ë“  ê³ ìœ í•œ ë¬¸ì„œ ID ìˆ˜ì§‘
        all_ids = set(bm25_map.keys()) | set(vector_map.keys())
        
        combined = []
        
        for doc_id in all_ids:
            bm25_result = bm25_map.get(doc_id)
            vector_result = vector_map.get(doc_id)
            
            # ì ìˆ˜ ì •ê·œí™” ë° í•©ì„±
            bm25_score = cls._normalize_bm25_score(bm25_result["score"]) if bm25_result else 0.0
            vector_score = vector_result["score"] if vector_result else 0.0
            
            # ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚°
            combined_score = (bm25_score * bm25_weight) + (vector_score * vector_weight)
            
            # ìš°ì„ ìˆœìœ„: BM25 > Vector (ë©”íƒ€ë°ì´í„° í’ë¶€ë„ ê¸°ì¤€)
            primary_result = bm25_result or vector_result
            
            combined_result = {
                **primary_result,
                "score": combined_score,
                "search_type": "hybrid",
                "score_details": {
                    "bm25_score": bm25_score,
                    "vector_score": vector_score,
                    "bm25_weight": bm25_weight,
                    "vector_weight": vector_weight
                }
            }
            
            combined.append(combined_result)
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        combined.sort(key=lambda x: x["score"], reverse=True)
        
        return combined

    @classmethod
    def _normalize_bm25_score(cls, score: float) -> float:
        """BM25 ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”"""
        # ê°„ë‹¨í•œ sigmoid ì •ê·œí™” (ì‹¤ì œë¡œëŠ” ë°ì´í„°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
        import math
        return 1 / (1 + math.exp(-score / 10))

    @classmethod
    def _update_search_stats(cls, search_time: float):
        """ê²€ìƒ‰ ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        current_avg = cls._stats["avg_search_time"]
        search_count = cls._stats["search_requests"]
        
        # ì´ë™ í‰ê·  ê³„ì‚°
        cls._stats["avg_search_time"] = (
            (current_avg * (search_count - 1)) + search_time
        ) / search_count

    @classmethod
    def is_initialized(cls) -> bool:
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸ (111 íŒ¨í„´)"""
        return cls._initialized

    @classmethod
    def get_stats(cls) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return {
            **cls._stats,
            "initialized": cls._initialized,
            "search_available": cls._search_available,
            "vector_available": cls._vector_available,
            "hybrid_capable": cls._search_available and cls._vector_available
        }

    @classmethod
    async def health_check(cls) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        if not cls._initialized:
            return {
                "status": "not_initialized",
                "message": "RAG ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"
            }
        
        # ì˜ì¡´ ì„œë¹„ìŠ¤ ìƒíƒœ ì¬í™•ì¸
        try:
            from service.search.search_service import SearchService
            from service.vectordb.vectordb_service import VectorDbService
            
            search_status = SearchService.is_initialized()
            vector_status = VectorDbService.is_initialized()
            
            if search_status and vector_status:
                status = "healthy"
            elif search_status or vector_status:
                status = "degraded"
            else:
                status = "critical"
            
            return {
                "status": status,
                "initialized": cls._initialized,
                "dependencies": {
                    "search_service": search_status,
                    "vector_service": vector_status
                },
                "capabilities": {
                    "hybrid_search": search_status and vector_status,
                    "keyword_search": search_status,
                    "vector_search": vector_status
                },
                "stats": cls.get_stats()
            }
            
        except Exception as e:
            Logger.error(f"RAG ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "message": f"ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}"
            }

    @classmethod
    async def shutdown(cls) -> bool:
        """ì„œë¹„ìŠ¤ ì¢…ë£Œ (111 íŒ¨í„´)"""
        try:
            if not cls._initialized:
                Logger.info("RAG ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì¢…ë£Œ ìŠ¤í‚µ")
                return True
            
            Logger.info("ğŸ”„ RAG ì„œë¹„ìŠ¤ ì¢…ë£Œ ì‹œì‘...")
            
            # í†µê³„ ë¡œê·¸ ì¶œë ¥
            stats = cls.get_stats()
            Logger.info(f"RAG ì„œë¹„ìŠ¤ í†µê³„:")
            Logger.info(f"  - ì¸ë±ì‹±ëœ ë¬¸ì„œ: {stats['documents_indexed']}ê°œ")
            Logger.info(f"  - ê²€ìƒ‰ ìš”ì²­: {stats['search_requests']}ê°œ")
            Logger.info(f"  - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: {stats['hybrid_searches']}ê°œ")
            Logger.info(f"  - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {stats['avg_search_time']:.3f}ì´ˆ")
            
            # RAG ì „ìš© ë²¡í„° í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ
            if cls._rag_vector_client:
                try:
                    await cls._rag_vector_client.close()
                    Logger.info("âœ… RAG ì „ìš© ë²¡í„° í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì™„ë£Œ")
                except Exception as e:
                    Logger.error(f"âŒ RAG ì „ìš© ë²¡í„° í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì‹¤íŒ¨: {e}")
            
            # ìƒíƒœ ì´ˆê¸°í™”
            cls._initialized = False
            cls._config = None
            cls._search_available = False
            cls._vector_available = False
            cls._rag_vector_client = None
            cls._reset_stats()
            
            Logger.info("âœ… RAG ì„œë¹„ìŠ¤ ì¢…ë£Œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            Logger.error(f"âŒ RAG ì„œë¹„ìŠ¤ ì¢…ë£Œ ì‹¤íŒ¨: {e}")
            return False