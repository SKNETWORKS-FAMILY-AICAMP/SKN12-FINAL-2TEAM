from typing import List, Dict, Optional, Any, Callable
from datetime import datetime
try:
    from pydantic import BaseModel
except ImportError:
    # pydanticì´ ì—†ì„ ê²½ìš° ê°„ë‹¨í•œ í´ë˜ìŠ¤ë¡œ ëŒ€ì²´
    class BaseModel:
        def __init__(self, **kwargs):
            for key, value in kwargs.items():
                setattr(self, key, value)

from service.llm.AIChat.BasicTools.FinancialStatementTool import FinancialStatementTool
from service.llm.AIChat.BasicTools.NewsTool import NewsTool
from service.llm.AIChat.BasicTools.MacroEconomicTool import MacroEconomicTool
from service.llm.AIChat.BasicTools.TechnicalAnalysisTool import TechnicalAnalysisTool
from service.llm.AIChat.BasicTools.MarketDataTool import MarketDataTool, MarketDataInput
import pandas as pd
import numpy as np

class CompositeFormula(BaseModel):
    """
    Composite ê³µì‹ ì •ì˜ ë° ë¬¸ì„œí™”ë¥¼ ìœ„í•œ í´ë˜ìŠ¤
    
    Attributes:
        name: ê³µì‹ ì´ë¦„
        func: ê³µì‹ í•¨ìˆ˜ (Dict[str, float] -> float)
        description: ê³µì‹ ì„¤ëª…
        category: ê³µì‹ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "macro", "technical", "sentiment")
        version: ê³µì‹ ë²„ì „
    """
    def __init__(self, name: str, func: Callable[[Dict[str, float]], float], 
                 description: Optional[str] = None, category: Optional[str] = None, 
                 version: Optional[str] = "1.0"):
        self.name = name
        self.func = func
        self.description = description
        self.category = category
        self.version = version
    
    def __call__(self, features: Dict[str, float]) -> float:
        """ê³µì‹ í•¨ìˆ˜ ì‹¤í–‰"""
        return self.func(features)
    
    def get_formula_map(self) -> Dict[str, Callable[[Dict[str, float]], float]]:
        """FeaturePipelineToolì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜"""
        return {self.name: self.func}

class FeaturePipelineTool:
    def __init__(self, ai_chat_service) -> None:
        self.ai_chat_service = ai_chat_service

    # ì •ê·œí™” ëŒ€ìƒ í”¼ì²˜ ìƒìˆ˜ ì •ì˜
    LOG_SCALE_FEATURES = {
        "GDP", "CPIAUCSL", "marketCap", "news_count", 
        "PRICE", "DEXKOUS", "composite_1", "composite_3"
    }
    
    Z_SCORE_FEATURES = {
        "RSI", "MACD", "EMA", "VIX", "priceEarningsRatio", 
        "returnOnEquity", "positive_news_ratio", "composite_2"
    }

    # ğŸ†• ê¸°ë³¸ Composite ê³µì‹ë“¤ (ì°¸ê³ ìš©)
    @staticmethod
    def get_default_composite_formulas() -> Dict[str, CompositeFormula]:
        """ê¸°ë³¸ composite ê³µì‹ë“¤ì„ ë°˜í™˜"""
        return {
            "macro_economic_index": CompositeFormula(
                name="composite_1",
                func=lambda feats: 0.5 * (feats.get("GDP", 0.0) + feats.get("CPIAUCSL", 0.0)),
                description="ê±°ì‹œê²½ì œ ë³µí•© ì§€í‘œ (GDP + CPI)",
                category="macro"
            ),
            "inflation_volatility_index": CompositeFormula(
                name="composite_2", 
                func=lambda feats: 0.7 * feats.get("CPIAUCSL", 0.0) + 0.3 * feats.get("VIX", 0.0),
                description="ì¸í”Œë ˆì´ì…˜ + ë³€ë™ì„± ì§€í‘œ (CPI + VIX)",
                category="macro"
            ),
            "technical_volatility_index": CompositeFormula(
                name="composite_3",
                func=lambda feats: 0.6 * feats.get("RSI", 0.0) + 0.4 * feats.get("VIX", 0.0),
                description="ê¸°ìˆ ì  + ë³€ë™ì„± ì§€í‘œ (RSI + VIX)",
                category="technical"
            )
        }

    def _extract_macro(self, macro_data: List[Dict[str, Any]], feature_name: str) -> float:
        """Extracts the latest value for a given feature from macro data."""
        latest_value = 0.0
        latest_date = ""
        for item in macro_data:
            if item.get("series_id") == feature_name:
                current_date = item.get("date", "")
                if current_date > latest_date:
                    latest_date = current_date
                    try:
                        value_str = item.get("value", "0.0")
                        if isinstance(value_str, str) and value_str != '.':
                            latest_value = float(value_str)
                        elif isinstance(value_str, (int, float)):
                            latest_value = value_str
                        else:
                            latest_value = 0.0
                    except (ValueError, TypeError):
                        latest_value = 0.0
        return latest_value

    def _log1p_normalize(self, value: float) -> float:
        """ë¡œê·¸ ì •ê·œí™” (í° ê°’ì— ì ìš©)"""
        if value > 0:
            return np.log1p(value)
        return 0.0
    
    def _zscore_normalize(self, value: float, feature_name: str) -> float:
        """Z-score ì •ê·œí™” (ì¼ë°˜ì ì¸ ë²”ìœ„ì˜ ê°’ì— ì ìš©)"""
        # í”¼ì²˜ë³„ ê³ ì •ëœ ê¸°ì¤€ê°’ ì‚¬ìš©
        feature_means = {
            "RSI": 50.0,              # RSI í‰ê· 
            "MACD": 0.0,              # MACD í‰ê· 
            "EMA": 100.0,             # EMA í‰ê· 
            "VIX": 20.0,              # VIX í‰ê· 
            "priceEarningsRatio": 15.0,  # PER í‰ê· 
            "returnOnEquity": 10.0,   # ROE í‰ê· 
            "positive_news_ratio": 0.5,  # ê¸ì • ë‰´ìŠ¤ ë¹„ìœ¨ í‰ê· 
            "CPIAUCSL": 300.0,        # CPI í‰ê· 
        }
        
        feature_stds = {
            "RSI": 15.0,              # RSI í‘œì¤€í¸ì°¨
            "MACD": 0.02,             # MACD í‘œì¤€í¸ì°¨
            "EMA": 20.0,              # EMA í‘œì¤€í¸ì°¨
            "VIX": 8.0,               # VIX í‘œì¤€í¸ì°¨
            "priceEarningsRatio": 10.0,  # PER í‘œì¤€í¸ì°¨
            "returnOnEquity": 5.0,    # ROE í‘œì¤€í¸ì°¨
            "positive_news_ratio": 0.2,  # ê¸ì • ë‰´ìŠ¤ ë¹„ìœ¨ í‘œì¤€í¸ì°¨
            "CPIAUCSL": 20.0,         # CPI í‘œì¤€í¸ì°¨
        }
        
        mean_val = feature_means.get(feature_name, 0.0)
        std_val = feature_stds.get(feature_name, 1.0)
        
        if std_val > 1e-8:
            return (value - mean_val) / std_val
        return 0.0

    def _generate_composite_features(
        self, 
        features: Dict[str, Any], 
        composite_formula_map: Optional[Dict[str, Callable[[Dict[str, float]], float]]] = None,
        debug: bool = False
    ) -> Dict[str, Any]:
        """
        ë³µí•© í”¼ì²˜ ìƒì„± - ì™¸ë¶€ì—ì„œ ì •ì˜ëœ ê³µì‹ ë˜ëŠ” ê¸°ë³¸ ê³µì‹ ì‚¬ìš©
        
        Args:
            features: ê¸°ë³¸ í”¼ì²˜ ë”•ì…”ë„ˆë¦¬
            composite_formula_map: ì™¸ë¶€ì—ì„œ ì •ì˜ëœ composite ê³µì‹ ë§µ
            debug: ë””ë²„ê¹… ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            ë³µí•© í”¼ì²˜ ë”•ì…”ë„ˆë¦¬
        """
        composites = {}
        
        # ğŸ†• ì™¸ë¶€ì—ì„œ ì •ì˜ëœ ê³µì‹ ì‚¬ìš©
        if composite_formula_map:
            for comp_name, func in composite_formula_map.items():
                try:
                    composites[comp_name] = func(features)
                    if debug:
                        print(f"[Composite] {comp_name}: {composites[comp_name]:.4f}")
                except Exception as e:
                    if debug:
                        print(f"[Composite Error] {comp_name}: {e}")
                    composites[comp_name] = 0.0
        
        return composites

    def _selective_normalize(self, features: Dict[str, Any], targets: List[str], debug: bool = False) -> Dict[str, Any]:
        """
        ì„ íƒì  ì •ê·œí™” - ì§€ì •ëœ í”¼ì²˜ë§Œ ì •ê·œí™”
        
        Args:
            features: ì •ê·œí™”í•  í”¼ì²˜ ë”•ì…”ë„ˆë¦¬
            targets: ì •ê·œí™”í•  í”¼ì²˜ ë¦¬ìŠ¤íŠ¸
            debug: ë””ë²„ê¹… ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            ì •ê·œí™”ëœ í”¼ì²˜ ë”•ì…”ë„ˆë¦¬
        """
        normalized = features.copy()
        
        for target in targets:
            if target in features:
                raw_value = features[target]
                
                if not isinstance(raw_value, (int, float)) or pd.isna(raw_value):
                    normalized[target] = 0.0
                    if debug:
                        print(f"[Selective Normalize] Invalid value for {target}, setting to 0.0")
                    continue
                
                # í”¼ì²˜ë³„ ì •ê·œí™” ë°©ì‹ ì„ íƒ
                if target in self.LOG_SCALE_FEATURES:
                    normalized[target] = self._log1p_normalize(raw_value)
                    if debug:
                        print(f"[Selective Normalize] Applied log1p for {target}, value={raw_value:.4f} -> {normalized[target]:.4f}")
                elif target in self.Z_SCORE_FEATURES:
                    normalized[target] = self._zscore_normalize(raw_value, target)
                    if debug:
                        print(f"[Selective Normalize] Applied z-score for {target}, value={raw_value:.4f} -> {normalized[target]:.4f}")
                else:
                    # ê¸°ë³¸ì ìœ¼ë¡œ Z-score ì ìš©
                    normalized[target] = self._zscore_normalize(raw_value, target)
                    if debug:
                        print(f"[Selective Normalize] Applied default z-score for {target}, value={raw_value:.4f} -> {normalized[target]:.4f}")
        
        return normalized

    def transform(
        self,
        tickers: List[str],
        start_date: str,
        end_date: Optional[str] = None,
        feature_set: Optional[List[str]] = None,
        normalize: bool = True,
        normalize_targets: Optional[List[str]] = None,
        generate_composites: bool = False,
        composite_formula_map: Optional[Dict[str, Callable[[Dict[str, float]], float]]] = None,
        return_raw: bool = False,
        debug: bool = False
    ) -> Dict[str, Any]:
        if debug:
            print(f"[FeaturePipelineTool] transform called with:")
            print(f"  - tickers: {tickers}")
            print(f"  - feature_set: {feature_set}")
            print(f"  - debug: {debug}")
        """
        ì™„ì „í•œ í”¼ì²˜ íŒŒì´í”„ë¼ì¸ - ë³µí•© í”¼ì²˜ ìƒì„± + ì„ íƒì  ì •ê·œí™” + Raw/Normalized ë™ì‹œ ë°˜í™˜ ì§€ì›
        
        Parameters
        ----------
        tickers : List[str]
            ë¶„ì„í•  ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        start_date : str
            ë°ì´í„° ì‹œì‘ì¼
        end_date : Optional[str]
            ë°ì´í„° ì¢…ë£Œì¼
        feature_set : Optional[List[str]]
            ì¶”ì¶œí•  í”¼ì²˜ ë¦¬ìŠ¤íŠ¸
        normalize : bool, default True
            ì •ê·œí™” ì ìš© ì—¬ë¶€
        normalize_targets : Optional[List[str]]
            ì •ê·œí™”í•  í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  í”¼ì²˜ ì •ê·œí™”)
        generate_composites : bool, default False
            ë³µí•© í”¼ì²˜ ìƒì„± ì—¬ë¶€
        composite_formula_map : Optional[Dict[str, Callable]]
            ì™¸ë¶€ì—ì„œ ì •ì˜ëœ composite ê³µì‹ ë§µ
            ì˜ˆ: {"composite_1": lambda feats: 0.5 * (feats.get("GDP", 0.0) + feats.get("CPIAUCSL", 0.0))}
        return_raw : bool, default False
            Raw ê°’ê³¼ Normalized ê°’ì„ ë™ì‹œì— ë°˜í™˜í• ì§€ ì—¬ë¶€
        debug : bool, default False
            ë””ë²„ê¹…ìš© ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
        """
        end_date = end_date or datetime.today().strftime("%Y-%m-%d")
        feature_set = feature_set or [
            "GDP", "CPIAUCSL", "DEXKOUS", "RSI", "MACD", "EMA", "VIX", "PRICE",
            "PRICE_HISTORY", "priceEarningsRatio", "returnOnEquity", "marketCap",
            "news_count", "positive_news_ratio"
        ]
        features: Dict[str, Any] = {}

        # Macro
        macro_series_ids = [f for f in ["GDP", "CPIAUCSL", "DEXKOUS"] if f in feature_set]
        if macro_series_ids:
            macro = MacroEconomicTool(self.ai_chat_service).get_data(series_ids=macro_series_ids)
            if macro.data:
                for feat in macro_series_ids:
                    features[feat] = self._extract_macro(macro.data, feat)

        # Technical
        tech_features = [f for f in ["RSI", "MACD", "EMA"] if f in feature_set]
        if debug:
            print(f"[FeaturePipelineTool] Technical features requested: {tech_features}")
            print(f"[FeaturePipelineTool] Tickers: {tickers}")
        if tech_features and tickers:
            if debug:
                print(f"[FeaturePipelineTool] Calling TechnicalAnalysisTool...")
            ta = TechnicalAnalysisTool(self.ai_chat_service).get_data(tickers=tickers)
            ta_data = None
            if isinstance(ta.results, dict):
                ta_data = ta.results.get(tickers[0]) or (next(iter(ta.results.values())) if ta.results else None)
            elif isinstance(ta.results, list) and ta.results:
                ta_data = ta.results[0]
            
            if ta_data:
                if "RSI" in feature_set: features["RSI"] = getattr(ta_data, "rsi", 0.0)
                if "MACD" in feature_set: features["MACD"] = getattr(ta_data, "macd", 0.0)
                if "EMA" in feature_set: features["EMA"] = getattr(ta_data, "ema", 0.0)

        # Financial Statements
        fs_features = [f for f in ["priceEarningsRatio", "returnOnEquity", "marketCap"] if f in feature_set]
        if fs_features and tickers:
            ticker = tickers[0]
            if "priceEarningsRatio" in fs_features or "returnOnEquity" in fs_features:
                ratios_tool = FinancialStatementTool(self.ai_chat_service, "ratios")
                ratios_result = ratios_tool.get_data(ticker=ticker, period="annual", limit=1)
                if ratios_result.data:
                    ratios_data = ratios_result.data[0]
                    if "priceEarningsRatio" in fs_features: features["priceEarningsRatio"] = ratios_data.get("priceEarningsRatio")
                    if "returnOnEquity" in fs_features: features["returnOnEquity"] = ratios_data.get("returnOnEquity")
            
            if "marketCap" in fs_features:
                key_metrics_data = FinancialStatementTool(self.ai_chat_service, "key-metrics").get_data(ticker=ticker, limit=1)
                if key_metrics_data.data:
                    features["marketCap"] = key_metrics_data.data[0].get("marketCap", 0.0)

        # News Features
        news_features = [f for f in ["news_count", "positive_news_ratio"] if f in feature_set]
        if news_features:
            query = tickers[0] if tickers else "stock market"
            news_result = NewsTool(self.ai_chat_service).get_data(query=query, k=10)
            if news_result and news_result.data:
                total = len(news_result.data)
                positive = sum(1 for item in news_result.data if item.get("sentiment") == "positive")
                features["news_count"] = total
                features["positive_news_ratio"] = round(positive / total, 3) if total > 0 else 0.0

        # Market
        market_features = [f for f in ["VIX", "PRICE", "PRICE_HISTORY"] if f in feature_set]
        if market_features and tickers:
            market_inp = MarketDataInput(tickers=tickers, start_date=start_date, end_date=end_date)
            market = MarketDataTool(self.ai_chat_service).get_data(**market_inp.dict())
            if "VIX" in feature_set: features["VIX"] = market.vix or 0.0
            
            price_data = market.price_data.get(tickers[0], [])
            if "PRICE" in feature_set:
                features["PRICE"] = float(price_data[-1].get("Adj Close", 0)) if price_data else 0.0
            if "PRICE_HISTORY" in feature_set:
                features["PRICE_HISTORY"] = pd.DataFrame(price_data) if price_data else pd.DataFrame()

        # ğŸ†• ë³µí•© í”¼ì²˜ ìƒì„± (ì™¸ë¶€ ê³µì‹ ë˜ëŠ” ê¸°ë³¸ ê³µì‹)
        if generate_composites:
            composite_features = self._generate_composite_features(features, composite_formula_map, debug)
            features.update(composite_features)
            if debug:
                print(f"[FeaturePipelineTool] Generated {len(composite_features)} composite features: {list(composite_features.keys())}")
            
            # ğŸ†• Composite í”¼ì²˜ ìë™ ì •ê·œí™” ëŒ€ìƒ ì¶”ê°€
            if normalize and normalize_targets is not None:
                composite_keys = list(composite_features.keys())
                for key in composite_keys:
                    if key not in normalize_targets:
                        normalize_targets.append(key)
                if debug:
                    print(f"[FeaturePipelineTool] Auto-added composite features to normalize_targets: {composite_keys}")

        # ğŸ†• Raw ê°’ ì €ì¥ (return_raw=Trueì¸ ê²½ìš°)
        raw_features = features.copy() if return_raw else None

        # ğŸ†• ì™„ì „í•œ ì •ê·œí™” íŒŒì´í”„ë¼ì¸
        if normalize:
            if normalize_targets:
                # ì„ íƒì  ì •ê·œí™”
                result = self._selective_normalize(features, normalize_targets, debug)
                if debug:
                    print(f"[FeaturePipelineTool] Selective normalization completed: {len(result)} features")
            else:
                # ì „ì²´ ì •ê·œí™” (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                result = {}
                for feat_name, raw_value in features.items():
                    if not isinstance(raw_value, (int, float)) or pd.isna(raw_value):
                        result[feat_name] = 0.0
                        if debug:
                            print(f"[FeaturePipelineTool] Invalid value for {feat_name}, setting to 0.0")
                        continue
                        
                    # í”¼ì²˜ë³„ ì •ê·œí™” ë°©ì‹ ì„ íƒ
                    if feat_name in self.LOG_SCALE_FEATURES:
                        result[feat_name] = self._log1p_normalize(raw_value)
                        if debug:
                            print(f"[FeaturePipelineTool] Applied log1p for {feat_name}, value={raw_value:.4f} -> {result[feat_name]:.4f}")
                    elif feat_name in self.Z_SCORE_FEATURES:
                        result[feat_name] = self._zscore_normalize(raw_value, feat_name)
                        if debug:
                            print(f"[FeaturePipelineTool] Applied z-score for {feat_name}, value={raw_value:.4f} -> {result[feat_name]:.4f}")
                    else:
                        # ê¸°ë³¸ì ìœ¼ë¡œ Z-score ì ìš©
                        result[feat_name] = self._zscore_normalize(raw_value, feat_name)
                        if debug:
                            print(f"[FeaturePipelineTool] Applied default z-score for {feat_name}, value={raw_value:.4f} -> {result[feat_name]:.4f}")
                
                if debug:
                    print(f"[FeaturePipelineTool] Full normalization completed: {len(result)} features")
        else:
            # ì •ê·œí™”í•˜ì§€ ì•Šê³  raw ê°’ ê·¸ëŒ€ë¡œ ë°˜í™˜
            result = features
            if debug:
                print(f"[FeaturePipelineTool] Raw values returned: {len(result)} features")
        
        # ğŸ†• Raw + Normalized ë™ì‹œ ë°˜í™˜
        if return_raw:
            return {
                "raw": raw_features,
                "normalized": result
            }
        else:
            return result
