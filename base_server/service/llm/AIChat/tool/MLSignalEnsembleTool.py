"""
ml_signal_ensemble.py
=====================
MLSignalEnsemble  â¡  BaseFinanceTool ìƒì† + `get_data()` í‘œì¤€ ì¸í„°í˜ì´ìŠ¤

â— êµ¬ì„±
    â–¸ XGBoost íšŒê·€ ì‹ í˜¸
    â–¸ LSTM ì‹œê³„ì—´ ì‹ í˜¸
    â–¸ ì „í†µ(ìˆ˜ì‹Â·ë£°) ì‹ í˜¸
    â–¸ Î±, Î², Î³ ê°€ì¤‘ì¹˜ë¡œ ìµœì¢… ì•™ìƒë¸”

â— ì‚¬ì „ í•™ìŠµ
    - `fit()` : (X, y) ì…ë ¥ìœ¼ë¡œ ë‘ ëª¨ë¸ì„ ëª¨ë‘ í•™ìŠµ
    - í•™ìŠµì´ ëë‚˜ë©´ `is_trained` í”Œë˜ê·¸ê°€ ì¼œì§

â— ì…ë ¥ (get_data)
    current_data       : dict â†’ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì— í•„ìš”í•œ ëª¨ë“  ì›ì‹œ ë°ì´í„°
    traditional_signal : float (ê¸°ë³¸ 0.0)

â— ì¶œë ¥ (dict)
    {
        'xgb_signal'        : float,
        'lstm_signal'       : float,
        'traditional_signal': float,
        'final_signal'      : float,
        'elapsed'           : float   # ì˜ˆì¸¡ ì†Œìš” ì‹œê°„
    }
"""

from __future__ import annotations

import time
from typing import Dict, Tuple

import numpy as np
from numpy.typing import NDArray

try:
    import xgboost as xgb
except ImportError:  # ëŸ°íƒ€ì„ì— ì—†ë‹¤ë©´ ë”ë¯¸
    xgb = None

try:
    from tensorflow import keras
    from keras import layers
except ImportError:
    keras = None

from BaseFinanceTool import BaseFinanceTool

__all__ = ["MLSignalEnsemble"]


# --------------------------------------------------------------------- #
#                         í—¬í¼: íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§                           #
# --------------------------------------------------------------------- #
def feature_engineering(data: Dict) -> Tuple[NDArray, NDArray]:
    """
    ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” specialist_agents ë°ì´í„°ë¥¼ ë°›ì•„
    â–¸ ê¸°ìˆ Â·ê±°ì‹œÂ·í€ë”ë©˜í„¸Â·ê°ì • ì§€í‘œ ë“±ì„ ë²¡í„°í™”
    ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë”ë¯¸ ë°°ì—´ì„ ë°˜í™˜
    """
    X = np.random.randn(120, 8)  # 120 ìƒ˜í”Œ, 8 íŠ¹ì„±
    y = np.random.randn(120)
    return X, y


# --------------------------------------------------------------------- #
#                             ì•™ìƒë¸” í´ë˜ìŠ¤                              #
# --------------------------------------------------------------------- #
class MLSignalEnsemble(BaseFinanceTool):
    """XGBoost + LSTM + ì „í†µì‹ í˜¸ í†µí•© ì•™ìƒë¸”"""

    def __init__(self) -> None:
        super().__init__()  # API-Key ë¶ˆí•„ìš”

        # 1) XGBoost
        self.xgb_model = (
            xgb.XGBRegressor(
                n_estimators=150,
                max_depth=4,
                learning_rate=0.05,
                subsample=0.8,
                colsample_bytree=0.8,
                objective="reg:squarederror",
                verbosity=0,
            )
            if xgb
            else None
        )

        # 2) LSTM
        self.lstm_model = self._build_lstm() if keras else None

        # 3) ê°€ì¤‘ì¹˜
        self.weights = np.array([0.4, 0.4, 0.2])  # [XGB, LSTM, Traditional]

        self.is_trained = False

    # ----------------------------- ëª¨ë¸ -------------------------------- #
    @staticmethod
    def _build_lstm():
        model = keras.Sequential(
            [
                layers.LSTM(64, return_sequences=True, input_shape=(60, 8)),
                layers.Dropout(0.3),
                layers.LSTM(32),
                layers.Dense(16, activation="relu"),
                layers.Dense(1),
            ]
        )
        model.compile(optimizer="adam", loss="mse", verbose=0)
        return model

    # ----------------------------- í•™ìŠµ -------------------------------- #
    def fit(self, training_raw: Dict) -> None:
        """ì „ì²˜ë¦¬ â†’ X, y â†’ ë‘ ëª¨ë¸ ëª¨ë‘ í•™ìŠµ"""
        X, y = feature_engineering(training_raw)

        if self.xgb_model:
            self.xgb_model.fit(X, y)

        if self.lstm_model:
            # ìµœê·¼ 60ê°œ ìƒ˜í”Œë¡œ LSTM í•™ìŠµ (ë°ëª¨ ê°„ì†Œí™”)
            X_lstm = X[-60:].reshape(1, 60, 8)
            y_lstm = y[-60:]
            self.lstm_model.fit(X_lstm, y_lstm, epochs=2, verbose=0)

        self.is_trained = True

    # ----------------------------- ì˜ˆì¸¡(get_data) ---------------------- #
    def get_data(
        self,
        tickers: List[str],
        start_date: str,
        end_date: str,
        traditional_signal: float = 0.0,
        *,
        max_latency: float = 1.0,
    ) -> Dict:
        """
        Parameters
        ----------
        tickers : List[str]
            ë¶„ì„í•  ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        start_date : str
            ë°ì´í„° ì‹œì‘ì¼(YYYY-MM-DD)
        end_date : str
            ë°ì´í„° ì¢…ë£Œì¼(YYYY-MM-DD)
        traditional_signal : float
            ìˆ˜ì‹ ê¸°ë°˜(ëª¨ë©˜í…€, ë°¸ë¥˜ ë“±) ì „í†µ ì‹ í˜¸

        Returns
        -------
        dict : xgb_signal, lstm_signal, traditional_signal, final_signal, elapsed
        """
        if not self.is_trained:
            raise RuntimeError("MLSignalEnsemble must be trained with `.fit()` first.")

        t0 = time.time()

        # FeaturePipelineToolì„ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ í”¼ì²˜ ì¶”ì¶œ (Raw + Normalized ë™ì‹œ ë°˜í™˜)
        from service.llm.AIChat.tool.FeaturePipelineTool import FeaturePipelineTool
        
        # ğŸ†• ML ì•™ìƒë¸” ì „ìš© Composite ê³µì‹ ì •ì˜
        ml_ensemble_composite_formulas = {
            # ê¸°ìˆ ì  + ê±°ì‹œê²½ì œ ë³µí•© ì§€í‘œ (XGBoostìš©)
            "ml_tech_macro": lambda feats: (
                0.4 * feats.get("RSI", 0.0) + 
                0.3 * feats.get("MACD", 0.0) + 
                0.3 * feats.get("GDP", 0.0)
            ),
            # ë³€ë™ì„± + í€ë”ë©˜í„¸ ë³µí•© ì§€í‘œ (LSTMìš©)
            "ml_vol_fundamental": lambda feats: (
                0.5 * feats.get("VIX", 0.0) + 
                0.3 * feats.get("CPIAUCSL", 0.0) + 
                0.2 * feats.get("DEXKOUS", 0.0)
            ),
            # ëª¨ë©˜í…€ + ë°¸ë¥˜ ë³µí•© ì§€í‘œ (ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì¡°ì •ìš©)
            "ml_momentum_value": lambda feats: (
                0.6 * feats.get("RSI", 0.0) + 
                0.4 * feats.get("MACD", 0.0)
            )
        }
        
        pipeline_result = FeaturePipelineTool(self.ai_chat_service).transform(
            tickers=tickers,
            start_date=start_date,
            end_date=end_date,
            feature_set=["RSI", "MACD", "PRICE_HISTORY", "GDP", "CPIAUCSL", "DEXKOUS", "VIX"],
            normalize=True,  # âœ… ì •ê·œí™” í™œì„±í™”
            normalize_targets=["GDP", "CPIAUCSL", "RSI", "MACD", "VIX"],  # âœ… ML ëª¨ë¸ìš© ì„ íƒì  ì •ê·œí™”
            generate_composites=True,  # âœ… ë³µí•© í”¼ì²˜ ìƒì„±
            composite_formula_map=ml_ensemble_composite_formulas,  # ğŸ†• ML ì•™ìƒë¸” ì „ìš© ê³µì‹ ì‚¬ìš©
            return_raw=True,  # ğŸ†• Raw + Normalized ë™ì‹œ ë°˜í™˜
            debug=False
        )

        # ì •ê·œí™”ëœ í”¼ì²˜ë¡œ ML ëª¨ë¸ ì…ë ¥ ìƒì„±
        norm_features = pipeline_result["normalized"]
        X, _ = self._feature_engineering_from_features(norm_features)

        xgb_sig = (
            float(self.xgb_model.predict(X[:1])[0]) if self.xgb_model else 0.0
        )
        lstm_sig = (
            float(self.lstm_model.predict(X[:1].reshape(1, 1, 8))[0, 0])
            if self.lstm_model
            else 0.0
        )

        final = (
            self.weights[0] * xgb_sig
            + self.weights[1] * lstm_sig
            + self.weights[2] * traditional_signal
        )

        elapsed = time.time() - t0
        if elapsed > max_latency:
            raise RuntimeError(f"Latency {elapsed:.3f}s > {max_latency}s")

        return {
            "xgb_signal": xgb_sig,
            "lstm_signal": lstm_sig,
            "traditional_signal": traditional_signal,
            "final_signal": final,
            "elapsed": elapsed,
        }

    def _feature_engineering_from_features(self, features: Dict) -> Tuple[NDArray, NDArray]:
        """
        FeaturePipelineToolì—ì„œ ì–»ì€ features ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬
        ML ëª¨ë¸ì˜ ì…ë ¥ X, yë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        ìƒˆë¡œìš´ composite í”¼ì²˜ë“¤ì„ í¬í•¨í•˜ì—¬ ë” í’ë¶€í•œ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        # ê¸°ë³¸ í”¼ì²˜ë“¤
        gdp = features.get("GDP", 0.0)
        cpi = features.get("CPIAUCSL", 0.0)
        rsi = features.get("RSI", 0.0)
        macd = features.get("MACD", 0.0)
        vix = features.get("VIX", 0.0)
        price_history = features.get("PRICE_HISTORY", pd.DataFrame())
        
        # ğŸ†• ML ì•™ìƒë¸” ì „ìš© composite í”¼ì²˜ë“¤
        ml_tech_macro = features.get("ml_tech_macro", 0.0)
        ml_vol_fundamental = features.get("ml_vol_fundamental", 0.0)
        ml_momentum_value = features.get("ml_momentum_value", 0.0)
        
        # ê°€ê²© ë°ì´í„°ì—ì„œ ì¶”ê°€ íŠ¹ì„± ì¶”ì¶œ
        price_feature = 0.0
        if not price_history.empty and len(price_history) > 0:
            latest_price = price_history.iloc[-1].get("Adj Close", 0.0)
            if len(price_history) > 1:
                prev_price = price_history.iloc[-2].get("Adj Close", latest_price)
                price_feature = (latest_price - prev_price) / prev_price if prev_price > 0 else 0.0
            else:
                price_feature = latest_price

        # ğŸ†• 8ì°¨ì› íŠ¹ì„± ë²¡í„° êµ¬ì„± (ê¸°ì¡´ 5ì°¨ì›ì—ì„œ í™•ì¥)
        X = np.array([[
            gdp,                    # 1. GDP
            cpi,                    # 2. CPI
            rsi,                    # 3. RSI
            macd,                   # 4. MACD
            vix,                    # 5. VIX
            ml_tech_macro,          # 6. ğŸ†• ê¸°ìˆ ì +ê±°ì‹œê²½ì œ ë³µí•©ì§€í‘œ
            ml_vol_fundamental,     # 7. ğŸ†• ë³€ë™ì„±+í€ë”ë©˜í„¸ ë³µí•©ì§€í‘œ
            price_feature           # 8. ğŸ†• ê°€ê²© ë³€í™”ìœ¨
        ]])
        
        y = np.array([0.0])  # ì˜ˆì¸¡ ëŒ€ìƒ yëŠ” ì—¬ê¸°ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë”ë¯¸ ê°’
        return X, y


# --------------------------------------------------------------------- #
# ë°ëª¨ ì‹¤í–‰
# --------------------------------------------------------------------- #
if __name__ == "__main__":
    ens = MLSignalEnsemble()
    # 1) í•™ìŠµ
    ens.fit(training_raw={})
    # 2) ì˜ˆì¸¡
    out = ens.get_data(current_raw={}, traditional_signal=0.1)
    print(out)
