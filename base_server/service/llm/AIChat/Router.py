from __future__ import annotations

"""AIChatRouter â€“ Financeâ€‘focused LangGraph pipeline
====================================================

ğŸ”‘ **í•µì‹¬**
    â€¢ LLM(system prompt) â†” **êµ¬ì²´ì ì¸ description ì´ í¬í•¨ëœ Tool** â†” ì‚¬ìš©ì ì§ˆë¬¸.
    â€¢ should_continue ë¡œì§ì—ì„œ *dict* í˜•íƒœì™€ *pydantic ê°ì²´* í˜•íƒœì˜ `tool_calls`ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•˜ë„ë¡ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

ë³€ê²½ ë‚´ì—­
---------
1. **_extract_tool_name(â€¦)**Â í—¬í¼ í•¨ìˆ˜ ì¶”ê°€  
   â€“ dict(`{"name": â€¦}`)ì´ë“  ê°ì²´ë“  ì•ˆì „í•˜ê²Œ ì´ë¦„ ì¶”ì¶œ.
2. **should_continue()**ì™€ **print_clean_messages()** ë¡œì§ì„ ì´ í—¬í¼ë¡œ êµì²´.

"""

import json
from datetime import datetime
from zoneinfo import ZoneInfo
from typing import Any, Dict, List

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from langgraph.graph import StateGraph, MessagesState, END, START
from langgraph.prebuilt import ToolNode
from langchain_core.prompts import ChatPromptTemplate

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íˆ´ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from service.llm.AIChat.BasicTools.FinancialStatementTool import (
    FinancialStatementTool,
    FinancialStatementParams,
)
from service.llm.AIChat.BasicTools.MacroEconomicTool import (
    MacroEconomicTool,
    MacroEconomicInput,
)
from service.llm.AIChat.BasicTools.SectorAnalysisTool import (
    SectorAnalysisTool,
    SectorAnalysisInput,
)
from service.llm.AIChat.BasicTools.TechnicalAnalysisTool import (
    TechnicalAnalysisTool,
    TechnicalAnalysisInput,
)
from service.llm.AIChat.BasicTools.MarketDataTool import (
    MarketDataTool,
    MarketDataInput,
)
from service.llm.AIChat.BasicTools.NewsTool import NewsTool, NewsInput
from service.llm.AIChat.BasicTools.IndustryAnalysisTool import (
    IndustryAnalysisTool,
    IndustryAnalysisInput,
)

from service.llm.AIChat.tool.MarketRegimeDetectorTool import (
    MarketRegimeDetector,
    MarketRegimeDetectorInput,
)
from service.llm.AIChat.tool.KalmanRegimeFilterTool import (
    KalmanRegimeFilterTool,
    KalmanRegimeFilterInput,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_tool_name(tc: Any) -> str | None:
    """`tool_calls` ìš”ì†Œì—ì„œ ì•ˆì „í•˜ê²Œ nameì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    OpenAI(ChatOpenAI) ì‘ë‹µì€ list[dict] íƒ€ì…ì´ê³ ,
    ì¼ë¶€ LangChain ë‚´ë¶€ ê°ì²´ëŠ” `.name` attributeë¥¼ ê°–ìŠµë‹ˆë‹¤.
    """
    if isinstance(tc, dict):
        return tc.get("name")
    return getattr(tc, "name", None)


class AIChatRouter:
    """LLMÂ +Â LangGraph ê¸°ë°˜ ê¸ˆìœµ ë¶„ì„ ë¼ìš°í„°"""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def __init__(self):
        # ì„œë¹„ìŠ¤ ì»¨í…Œì´ë„ˆì—ì„œ AI ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì£¼ì…
        from service.service_container import ServiceContainer

        self.ai_chat_service = ServiceContainer.get_ai_chat_service()
        self.OPENAI_API_KEY = (
            self.ai_chat_service.llm_config
            .providers[self.ai_chat_service.llm_config.default_provider]
            .api_key
        )

        self.today = datetime.now(ZoneInfo("Asia/Seoul")).date()
        self.SYSTEM_PROMPT = {
            "role": "system",
            "content": (
                "ë„ˆëŠ” ê¸ˆìœµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” AI ì „ë¬¸ê°€ì•¼. "
                "ì¤‘ìš”: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•´. "
                "ì ˆëŒ€ë¡œ ë„êµ¬ ì—†ì´ ë‹µë³€í•˜ì§€ ë§ˆ. "
                "ì¬ë¬´ ì‹¤ì , ì£¼ê°€, ì‹œì„¸, ë‰´ìŠ¤ ë“± ëª¨ë“  ê¸ˆìœµ ì •ë³´ëŠ” ë„êµ¬ë¥¼ í†µí•´ ìˆ˜ì§‘í•´ì•¼ í•´. "
                "ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´. "
                "ë„êµ¬ ì‚¬ìš©ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ì—ë„ ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ ì°¾ì•„ì„œ ì‚¬ìš©í•´. "
                f"ì˜¤ëŠ˜ ë‚ ì§œëŠ” {self.today}ì•¼."
            ),
        }

        # íˆ´ ì •ì˜ + LLM ì¤€ë¹„
        self.TOOLS = self._define_tools()
        self.llm = ChatOpenAI(
            model=self.ai_chat_service.llm_config.providers[
        self.ai_chat_service.llm_config.default_provider
    ].model, api_key=self.OPENAI_API_KEY, temperature=0
        )
        self.llm_with_tools = self.llm.bind_tools(self.TOOLS)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íˆ´ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _define_tools(self):
        """self.ai_chat_serviceë¥¼ ì¬ì‚¬ìš©í•˜ë©° descriptionì„ ëª…í™•íˆ ê¸°ì¬"""

        @tool(args_schema=FinancialStatementParams)
        def income_statement_tool(**params):
            """ê¸°ì—…ì˜ ì†ìµê³„ì‚°ì„œ(Income Statement)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ë§¤ì¶œ, ë¹„ìš©, ìˆœì´ìµ ë“± ìˆ˜ìµì„± ì§€í‘œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì¬ë¬´ ì‹¤ì  ë¶„ì„ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤."""
            agent = FinancialStatementTool(self.ai_chat_service, "income-statement")
            return agent.get_data(**params)

        @tool(args_schema=FinancialStatementParams)
        def balance_sheet_tool(**params):
            """ê¸°ì—…ì˜ ì¬ë¬´ìƒíƒœí‘œ(Balance Sheet)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ìì‚°, ë¶€ì±„, ìë³¸ ë“± ì¬ë¬´ ê±´ì „ì„± ì§€í‘œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì¬ë¬´ ì‹¤ì  ë¶„ì„ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤."""
            agent = FinancialStatementTool(self.ai_chat_service, "balance-sheet-statement")
            return agent.get_data(**params)

        @tool(args_schema=FinancialStatementParams)
        def cashflow_statement_tool(**params):
            """ê¸°ì—…ì˜ í˜„ê¸ˆíë¦„í‘œ(Cash Flow Statement)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ì˜ì—…, íˆ¬ì, ì¬ë¬´ í™œë™ì˜ í˜„ê¸ˆ íë¦„ì„ ì œê³µí•©ë‹ˆë‹¤. ì¬ë¬´ ì‹¤ì  ë¶„ì„ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤."""
            agent = FinancialStatementTool(self.ai_chat_service, "cash-flow-statement")
            return agent.get_data(**params)

        @tool(args_schema=FinancialStatementParams)
        def ratios_tool(**params):
            """ìˆ˜ìµì„±Â·íš¨ìœ¨ì„± ë“± ì¬ë¬´ë¹„ìœ¨(Ratios)ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
            agent = FinancialStatementTool(self.ai_chat_service, "ratios")
            return agent.get_data(**params)

        @tool(args_schema=FinancialStatementParams)
        def key_metrics_tool(**params):
            """ì£¼ë‹¹ì§€í‘œÂ·ë°°ë‹¹Â·PSR ë“± í•µì‹¬ì§€í‘œ(Key Metrics)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
            agent = FinancialStatementTool(self.ai_chat_service, "key-metrics")
            return agent.get_data(**params)

        @tool(args_schema=FinancialStatementParams)
        def financial_growth_tool(**params):
            """ë§¤ì¶œÂ·ì´ìµ ì„±ì¥ë¥  ë“± Financial Growth ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
            agent = FinancialStatementTool(self.ai_chat_service, "financial-growth")
            return agent.get_data(**params)

        @tool(args_schema=FinancialStatementParams)
        def enterprise_value_tool(**params):
            """ì‹œê°€ì´ì•¡Â·EV/EBITDA ë“± Enterprise Value ê´€ë ¨ ì§€í‘œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
            agent = FinancialStatementTool(self.ai_chat_service, "enterprise-values")
            return agent.get_data(**params)

        @tool(args_schema=NewsInput)
        def news(**params):
            """ì‹¤ì‹œê°„Â·ê³¼ê±° ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ìš”ì•½í•´ ì œê³µí•©ë‹ˆë‹¤."""
            agent = NewsTool(self.ai_chat_service)
            return agent.get_data(**params).summary

        @tool(args_schema=TechnicalAnalysisInput)
        def technical_analysis(**params):
            """RSIÂ·MACD ë“± ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•´ ì œê³µí•©ë‹ˆë‹¤."""
            agent = TechnicalAnalysisTool(self.ai_chat_service)
            results = agent.get_data(**params).results
            return "\n".join(r if isinstance(r, str) else r.summary for r in results)

        @tool(args_schema=MarketDataInput)
        def market_data(**params):
            """ì£¼ê°€Â·ê±°ë˜ëŸ‰ ë“± ì¼/ë¶„/í‹± Market Dataë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
            agent = MarketDataTool(self.ai_chat_service)
            return agent.get_data(**params).summary

        @tool(args_schema=MacroEconomicInput)
        def macro_economic(**params):
            """GDPÂ·CPIÂ·ì‹¤ì—…ë¥  ë“± ê±°ì‹œê²½ì œ ì§€í‘œë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
            agent = MacroEconomicTool(self.ai_chat_service)
            return agent.get_data(**params).summary

        @tool(args_schema=SectorAnalysisInput)
        def sector_analysis(**params):
            """11ê°œ GICS ì„¹í„°ì˜ í¼í¬ë¨¼ìŠ¤Â·ë°¸ë¥˜ì—ì´ì…˜ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
            agent = SectorAnalysisTool(self.ai_chat_service)
            return agent.get_data(**params).summary

        @tool(args_schema=IndustryAnalysisInput)
        def industry_analysis(**params):
            """ì„¸ë¶€ ì‚°ì—…(Industry) ë ˆë²¨ì—ì„œ ì£¼ìš” ì§€í‘œë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
            agent = IndustryAnalysisTool(self.ai_chat_service)
            return agent.get_data(**params).summary

        @tool(args_schema=MarketRegimeDetectorInput)
        def market_regime_detector_tool(**params):
            """ì‹œì¥ ë ˆì§(ê°•ì„¸/ì•½ì„¸/íš¡ë³´) íŒë‹¨ì„ ìœ„í•œ í†µê³„ ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
            agent = MarketRegimeDetector()
            return agent.get_data(**params).summary

        @tool(args_schema=KalmanRegimeFilterInput)
        def kalman_regime_filter_tool(**params):
            """ì¹¼ë§Œ í•„í„° ê¸°ë°˜ ë ˆì§ ì „í™˜ ê°ì§€ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""
            agent = KalmanRegimeFilterTool(self.ai_chat_service)
            return agent.get_data(**params).summary

        return [
            income_statement_tool,
            balance_sheet_tool,
            cashflow_statement_tool,
            ratios_tool,
            key_metrics_tool,
            financial_growth_tool,
            enterprise_value_tool,
            news,
            technical_analysis,
            market_data,
            macro_economic,
            sector_analysis,
            industry_analysis,
            market_regime_detector_tool,
            kalman_regime_filter_tool,
        ]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LangGraph ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def should_continue(self, state: MessagesState):
        """ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— íˆ´ í˜¸ì¶œì´ ìˆìœ¼ë©´ â†’íˆ´ ë…¸ë“œ, ì—†ìœ¼ë©´ END"""
        from service.core.logger import Logger

        last = state["messages"][-1]
        tool_calls = getattr(last, "tool_calls", None)
        
        Logger.debug(f"should_continue: ë§ˆì§€ë§‰ ë©”ì‹œì§€ íƒ€ì…={type(last).__name__}")
        Logger.debug(f"should_continue: tool_calls={tool_calls}")
        
        if not tool_calls:
            Logger.debug("should_continue: ë„êµ¬ í˜¸ì¶œ ì—†ìŒ â†’ END")
            return END

        # í˜„ì¬ ë©”ì‹œì§€ì˜ ë„êµ¬ í˜¸ì¶œë§Œ í™•ì¸ (ì¤‘ë³µ ì²´í¬ ì œê±°)
        current_tool_calls = []
        for tc in tool_calls:
            name = _extract_tool_name(tc)
            if name:
                current_tool_calls.append(name)
        
        Logger.debug(f"should_continue: í˜„ì¬ ë„êµ¬ í˜¸ì¶œë“¤={current_tool_calls}")
        
        if current_tool_calls:
            Logger.debug("should_continue: ë„êµ¬ í˜¸ì¶œ ìˆìŒ â†’ tools")
            return "tools"
        else:
            Logger.debug("should_continue: ìœ íš¨í•œ ë„êµ¬ í˜¸ì¶œ ì—†ìŒ â†’ END")
            return END

    def call_model(self, state: MessagesState):
        print("ğŸ”„ call_model: ", state["messages"])

        has_system = any(getattr(m, "role", None) == "system" for m in state["messages"])
        messages = ([self.SYSTEM_PROMPT] if not has_system else []) + state["messages"]

        resp = self.llm_with_tools.invoke(messages)
        return {"messages": state["messages"] + [resp]}

    def build_workflow(self):
        g = StateGraph(MessagesState)
        g.add_node("call_model", self.call_model)
        g.add_node("tools", ToolNode(self.TOOLS))
        g.add_edge(START, "call_model")
        g.add_conditional_edges("call_model", self.should_continue, {"tools", END})
        g.add_edge("tools", "call_model")
        return g.compile()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def run_question(self, question: str) -> str:
        from service.core.logger import Logger
        
        Logger.debug(f"Router.run_question ì‹œì‘: {question}")
        graph = self.build_workflow()
        init = [self.SYSTEM_PROMPT, {"role": "user", "content": question}]
        result = graph.invoke({"messages": init})
        
        Logger.debug(f"Router ì‹¤í–‰ ì™„ë£Œ, ë©”ì‹œì§€ ìˆ˜: {len(result['messages'])}")
        
        # ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
        tool_results = []
        for i, m in enumerate(result["messages"]):
            Logger.debug(f"ë©”ì‹œì§€ {i}: {type(m).__name__}, content={getattr(m, 'content', 'N/A')[:100]}...")
            if hasattr(m, 'name') and m.name:  # ToolMessageì¸ ê²½ìš°
                tool_results.append(f"ğŸ›  {m.name}: {m.content}")
                Logger.debug(f"ë„êµ¬ ê²°ê³¼ ë°œê²¬: {m.name}")
        
        if tool_results:
            Logger.debug(f"ë„êµ¬ ê²°ê³¼ ë°˜í™˜: {len(tool_results)}ê°œ")
            return "\n".join(tool_results)
        else:
            # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ AI ì‘ë‹µ ë°˜í™˜
            for m in reversed(result["messages"]):
                if hasattr(m, 'content') and m.content and not hasattr(m, 'name'):
                    Logger.debug(f"AI ì‘ë‹µ ë°˜í™˜: {m.content[:100]}...")
                    return m.content
            Logger.warn("ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return "ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def print_clean_messages(self, messages):
        """í„°ë¯¸ë„ìš© ê°„ëµ ë¡œê·¸ ì¶œë ¥"""
        print("ğŸ”„ í˜¸ì¶œ ë¡œê·¸ ì •ë¦¬")
        for m in messages:
            cls = getattr(m, "__class__", type("x", (), {})).__name__
            content = getattr(m, "content", "")
            if cls == "HumanMessage":
                print(f"ğŸ‘¤ Human: {content}")
            elif cls == "AIMessage":
                tool_calls = m.additional_kwargs.get("tool_calls", [])
                for tc in tool_calls:
                    print(f"ğŸ¤– AI â†’ Tool: {tc.get('name', '')} {tc.get('arguments', '')}")
                if content.strip():
                    print(f"ğŸ¤– AI ì‘ë‹µ: {content.strip()}")
            elif cls == "ToolMessage":
                print(f"ğŸ›  Tool({getattr(m, 'name', '')}): {content}")
            else:
                print(f"â“ {cls}: {content}")
