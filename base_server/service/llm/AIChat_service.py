# base_server/service/llm/AIChat_service.py

from service.core.logger import Logger
import os, uuid, asyncio, json
from fastapi import WebSocket, WebSocketDisconnect, HTTPException
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import RedisChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate

from service.service_container import ServiceContainer
from service.cache.cache_service import CacheService
from service.llm.AIChat.Router import AIChatRouter
from service.llm.llm_config import LlmConfig
from markdown import markdown
class AIChatService:
    """AI ì±„íŒ… ì„œë¹„ìŠ¤ - LLM ì‘ë‹µ ìƒì„±ì—ë§Œ ì§‘ì¤‘"""
    def __init__(self, llm_config: LlmConfig):
        self.llm_config = llm_config
        # llm ì¸ìŠ¤í„´ìŠ¤ëŠ” llm_configì—ì„œ ì§ì ‘ ìƒì„±
        from langchain_openai import ChatOpenAI
        api_key = os.getenv("OPENAI_API_KEY") or llm_config.providers[llm_config.default_provider].api_key
        self.llm = ChatOpenAI(model=llm_config.providers[llm_config.default_provider].model,
                              temperature=llm_config.providers[llm_config.default_provider].temperature,
                              openai_api_key=api_key)
        # ìŠ¤íŠ¸ë¦¬ë°ìš© LLM
        self.llm_stream = ChatOpenAI(model=llm_config.providers[llm_config.default_provider].model,
                                     temperature=llm_config.providers[llm_config.default_provider].temperature,
                                     streaming=True,
                                     openai_api_key=api_key)
        self._session_mem: dict[str, ConversationBufferMemory] = {}

        if not CacheService.is_initialized():
            raise RuntimeError("CacheService is not initialized. Please initialize CacheService first.")

        self.cache_service = CacheService.get_instance()
        # CacheServiceì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ê°€ì ¸ì™€ì„œ ì‚¬ìš©
        cache_client = self.cache_service.get_client()
        # RedisChatMessageHistoryì˜ key_prefixì— ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í¬í•¨
        # ì£¼ì˜: RedisChatMessageHistoryëŠ” key_prefixì™€ session_idë¥¼ ì¡°í•©í•˜ì—¬ í‚¤ë¥¼ ìƒì„±
        # ì‹¤ì œ í‚¤: {key_prefix}{session_id}
        self.KEY_PREFIX = f"{cache_client.cache_key}:chat:"
        Logger.info(f"AIChatService initialized with key prefix: {self.KEY_PREFIX}")

    def mem(self, session_id: str) -> ConversationBufferMemory:
        """ì„¸ì…˜ë³„ ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬ (Redis ê¸°ë°˜)"""
        if session_id not in self._session_mem:
            cache_client = self.cache_service.get_client()
            redis_url = f"redis://{cache_client._host}:{cache_client._port}/{cache_client._db}"
            if cache_client._password:
                redis_url = f"redis://:{cache_client._password}@{cache_client._host}:{cache_client._port}/{cache_client._db}"
            
            # RedisChatMessageHistoryëŠ” key_prefix + session_idë¡œ í‚¤ë¥¼ ìƒì„±
            # ì˜ˆ: finance_app:LOCAL:chat:room_123 í˜•íƒœë¡œ ì €ì¥ë¨
            history = RedisChatMessageHistory(
                session_id=session_id,
                url=redis_url,
                key_prefix=self.KEY_PREFIX,  # finance_app:LOCAL:chat:
            )
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
            Logger.debug(f"Creating RedisChatMessageHistory with key_prefix={self.KEY_PREFIX}, session_id={session_id}")
            Logger.debug(f"Expected Redis key pattern: {self.KEY_PREFIX}{session_id}")
            
            self._session_mem[session_id] = ConversationBufferMemory(
                chat_memory=history,
                return_messages=True
            )
        return self._session_mem[session_id]

    async def chat(self, message: str, session_id: str = "", client_session=None):
        """REST APIìš© ì±„íŒ… ì‘ë‹µ ìƒì„±"""
        if not message.strip():
            raise HTTPException(400, "message empty")
        sid = session_id or str(uuid.uuid4())
        Logger.debug(f"AIChatService.chat called with session_id={sid}, message={message}")
        
        # ğŸ†• ì„¸ì…˜ ì •ë³´ë¥¼ í¬í•¨í•œ ë¼ìš°í„° ìƒì„±
        Logger.debug(f"AIChatService.chat client_session: {client_session}")
        router = AIChatRouter(client_session)
        
        # ğŸ†• í´ë¡œì €ë¡œ ì•ˆì „í•˜ê²Œ ê°ì‹¸ê¸° (ë¹„ë™ê¸° ì²˜ë¦¬ ì•ˆì „ì„±)
        def run_question_with_session():
            return router.run_question(message)
        
        # ë¹„ë™ê¸° ì‹¤í–‰ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ë„êµ¬ í˜¸ì¶œì´ ì œëŒ€ë¡œ ì‘ë™í•˜ë„ë¡ í•¨
        loop = asyncio.get_event_loop()
        tool_out = await loop.run_in_executor(None, run_question_with_session)
        answer = await self._full_answer(sid, message, tool_out)
        Logger.debug(f"AIChatService.chat response for session_id={sid}: {answer}")
        return {"session_id": sid, "reply": answer}

    async def stream(self, ws: WebSocket):
        """WebSocketìš© ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì‘ë‹µ ìƒì„±"""
        await ws.accept()
        try:
            while True:
                data = await ws.receive_text()
                try:
                    req = json.loads(data)
                    q = req["message"].strip()
                    sid = req.get("session_id") or str(uuid.uuid4())
                except (KeyError, json.JSONDecodeError):
                    await ws.send_text(json.dumps({"error": "bad payload"}))
                    continue
                if not q:
                    await ws.send_text(json.dumps({"error": "empty message"}))
                    continue

                router = AIChatRouter()
                tool_out = await asyncio.get_running_loop().run_in_executor(
                    None, router.run_question, q
                )
                joined = "\n".join(tool_out) if isinstance(tool_out, list) else str(tool_out)

                memory = self.mem(sid)
                prompt = ChatPromptTemplate.from_messages(
                    [("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì •í™•í•œ AI ë¹„ì„œì…ë‹ˆë‹¤.")] +
                    memory.buffer +
                    [("user", f'{q}\n\nğŸ›  ë„êµ¬ ê²°ê³¼:\n{joined}')]
                )

                stream = (prompt | self.llm_stream).astream({})
                full_resp = ""
                async for chunk in stream:
                    token = getattr(chunk, "content", "")
                    if token:
                        full_resp += token
                        await ws.send_text(token)
                await ws.send_text("[DONE]")
                memory.chat_memory.add_user_message(q)
                memory.chat_memory.add_ai_message(full_resp)
        except WebSocketDisconnect:
            return

    async def _full_answer(self, sid: str, question: str, tool_out):
        """ì „ì²´ ì‘ë‹µ ìƒì„± (REST APIìš©)"""
        joined = "\n".join(tool_out) if isinstance(tool_out, list) else str(tool_out)
        memory = self.mem(sid)
        prompt = ChatPromptTemplate.from_messages(
            [("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì •í™•í•œ AI ë¹„ì„œì…ë‹ˆë‹¤.")] +
            memory.buffer +
            [("user", f'{question}\n\nğŸ›  ë„êµ¬ ê²°ê³¼:\n{joined}')]
        )
        answer = markdown((prompt | self.llm).invoke({}).content)
        memory.chat_memory.add_user_message(question)
        if isinstance(answer, list):
            answer = "\n".join(str(x) for x in answer)
        memory.chat_memory.add_ai_message(answer)
        return answer

    async def load_chat_history(self, session_id: str, messages: list):
        """DB/Redisì—ì„œ ë¡œë“œí•œ ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ë©”ëª¨ë¦¬ì— ë³µì›
        
        Args:
            session_id: ì±„íŒ… ì„¸ì…˜ ID (room_id)
            messages: ChatMessage ê°ì²´ ë¦¬ìŠ¤íŠ¸ (ì‹œê°„ìˆœ ì •ë ¬ë¨)
        """
        try:
            memory = self.mem(session_id)
            
            # ë©”ëª¨ë¦¬ê°€ ì´ë¯¸ ìˆëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸ (ì•ˆì „ì¥ì¹˜)
            if len(memory.buffer) > 0:
                Logger.debug(f"Memory already exists for session {session_id}, skipping history load")
                return
            
            # ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ë¡œë“œí•  í•„ìš” ì—†ìŒ
            if not messages:
                Logger.debug(f"No messages to load for session {session_id}")
                return
            
            # ë©”ì‹œì§€ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ì¶”ê°€ (clear í•˜ì§€ ì•Šê³  ì¶”ê°€ë§Œ)
            loaded_count = 0
            for msg in messages:
                try:
                    if msg.sender_type == "USER":
                        memory.chat_memory.add_user_message(msg.content)
                        loaded_count += 1
                    elif msg.sender_type == "AI":
                        memory.chat_memory.add_ai_message(msg.content)
                        loaded_count += 1
                    else:
                        Logger.debug(f"Skipping message with unknown sender_type: {msg.sender_type}")
                except Exception as msg_error:
                    Logger.warn(f"Failed to load message {msg.message_id}: {msg_error}")
                    continue
            
            Logger.info(f"Loaded {loaded_count}/{len(messages)} messages into AI memory for session {session_id}")
            
        except Exception as e:
            Logger.error(f"Failed to load chat history for session {session_id}: {e}")
            # íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ìƒˆ ëŒ€í™”ë¡œ ì‹œì‘)
    
    async def get_session_memory_keys(self, session_id: str) -> list:
        """íŠ¹ì • ì„¸ì…˜ì˜ Redis í‚¤ íŒ¨í„´ ë°˜í™˜ (ë””ë²„ê¹…ìš©)
        
        Returns:
            ì‹¤ì œ Redisì— ì €ì¥ë˜ëŠ” í‚¤ ë¦¬ìŠ¤íŠ¸
        """
        # RedisChatMessageHistoryì˜ ê¸°ë³¸ í‚¤ íŒ¨í„´
        # LangChainì€ ë³´í†µ {key_prefix}{session_id} í˜•íƒœë¡œ í‚¤ë¥¼ ìƒì„±
        base_key = f"{self.KEY_PREFIX}{session_id}"
        
        # LangChainì˜ ì¼ë°˜ì ì¸ íŒ¨í„´
        return [
            base_key,  # ë©”ì¸ í‚¤
            f"{base_key}:messages",  # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (ê°€ëŠ¥í•œ íŒ¨í„´)
        ]

    async def do_with_lock(self, key: str, ttl: int = 10):
        """ë¶„ì‚° ë½ì„ ì‚¬ìš©í•œ ì‘ì—… ì‹¤í–‰"""
        lock_service = ServiceContainer.get_lock_service()
        token = await lock_service.acquire(key, ttl=ttl)
        if not token:
            raise Exception("ë½ íšë“ ì‹¤íŒ¨")
        try:
            # ë½ì´ ë³´ì¥ëœ ì‘ì—…
            pass
        finally:
            await lock_service.release(key, token)
