# AI Trading Platform â€” Queue Service

> **ê°œìš”**: SKN12-FINAL-2TEAMì˜ AI íŠ¸ë ˆì´ë”© í”Œë«í¼ ë°±ì—”ë“œ Queue ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ë©”ì‹œì§€íì™€ ì´ë²¤íŠ¸íë¥¼ í†µí•© ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œìœ¼ë¡œ, ì•„ì›ƒë°•ìŠ¤ íŒ¨í„´ê³¼ ì—°ê³„í•˜ì—¬ íŠ¸ëœì­ì…˜ ì¼ê´€ì„±ì„ ë³´ì¥í•˜ëŠ” ë¹„ë™ê¸° ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

---

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

### ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
queue/
â”œâ”€â”€ __init__.py                    # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ queue_service.py               # í†µí•© í ì„œë¹„ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
â”œâ”€â”€ message_queue.py               # ë©”ì‹œì§€í ì‹œìŠ¤í…œ (Redis ê¸°ë°˜)
â”œâ”€â”€ event_queue.py                 # ì´ë²¤íŠ¸í ì‹œìŠ¤í…œ (Pub/Sub íŒ¨í„´)
â””â”€â”€ queue_examples.py              # ì‚¬ìš© ì˜ˆì œ ë° í…ŒìŠ¤íŠ¸ ì½”ë“œ
```

---

## ğŸ”§ í•µì‹¬ ê¸°ëŠ¥

### 1. **í†µí•© í ì„œë¹„ìŠ¤ (QueueService)**
- **ì‹±ê¸€í†¤ íŒ¨í„´**: `get_instance()` ë©”ì„œë“œë¡œ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
- **í†µí•© ê´€ë¦¬**: ë©”ì‹œì§€í, ì´ë²¤íŠ¸í, ì•„ì›ƒë°•ìŠ¤ íŒ¨í„´ì„ í•˜ë‚˜ì˜ ì„œë¹„ìŠ¤ë¡œ í†µí•©
- **ì´ˆê¸°í™” ê´€ë¦¬**: `initialize()`, `graceful_shutdown()` ë©”ì„œë“œë¡œ ì„œë¹„ìŠ¤ ìƒëª…ì£¼ê¸° ê´€ë¦¬
- **í†µê³„ ì¶”ì **: ë©”ì‹œì§€ ì²˜ë¦¬, ì´ë²¤íŠ¸ ë°œí–‰, ì˜¤ë¥˜ ë“±ì˜ í†µê³„ ìˆ˜ì§‘

### 2. **ë©”ì‹œì§€í ì‹œìŠ¤í…œ (MessageQueue)**
- **ìš°ì„ ìˆœìœ„ ê¸°ë°˜**: LOW(1), NORMAL(2), HIGH(3), CRITICAL(4) ìš°ì„ ìˆœìœ„ ì§€ì›
- **ì§€ì—° ì‹¤í–‰**: `scheduled_at` í•„ë“œë¡œ ë¯¸ë˜ ì‹œì  ë©”ì‹œì§€ ì˜ˆì•½
- **ì¬ì‹œë„ ë¡œì§**: ì‹¤íŒ¨í•œ ë©”ì‹œì§€ì˜ ìë™ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
- **Dead Letter Queue**: ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ ì‹œ DLQë¡œ ì´ë™
- **ìˆœì„œ ë³´ì¥**: `partition_key`ë¥¼ í†µí•œ ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥

### 3. **ì´ë²¤íŠ¸í ì‹œìŠ¤í…œ (EventQueue)**
- **Pub/Sub íŒ¨í„´**: ì´ë²¤íŠ¸ ë°œí–‰ìì™€ êµ¬ë…ì ê°„ì˜ ëŠìŠ¨í•œ ê²°í•©
- **ì´ë²¤íŠ¸ íƒ€ì…**: ê³„ì •, í¬íŠ¸í´ë¦¬ì˜¤, ì‹œì¥ ë°ì´í„°, ì•Œë¦¼, ì˜ˆì¸¡ ë“± ë‹¤ì–‘í•œ ë„ë©”ì¸
- **í•„í„°ë§**: êµ¬ë… ì‹œ ì´ë²¤íŠ¸ íƒ€ì…ê³¼ ì¡°ê±´ ê¸°ë°˜ í•„í„°ë§
- **êµ¬ë… ê´€ë¦¬**: ë™ì  êµ¬ë…/í•´ì œ ë° í™œì„± ìƒíƒœ ê´€ë¦¬

### 4. **ì•„ì›ƒë°•ìŠ¤ íŒ¨í„´ ì—°ë™**
- **íŠ¸ëœì­ì…˜ ì¼ê´€ì„±**: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ì´ë²¤íŠ¸ ë°œí–‰ì˜ ì›ìì„± ë³´ì¥
- **ì´ë²¤íŠ¸ ì˜ì†ì„±**: MySQLì„ í†µí•œ ì´ë²¤íŠ¸ ì €ì¥ ë° ë³µêµ¬
- **ìë™ ì²˜ë¦¬**: ë°±ê·¸ë¼ìš´ë“œì—ì„œ pending ì´ë²¤íŠ¸ ìë™ ì²˜ë¦¬

---

## ğŸ“š ì‚¬ìš©ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬

### **ë°±ì—”ë“œ & ì¸í”„ë¼**
- **asyncio**: ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° ë° íƒœìŠ¤í¬ ê´€ë¦¬
- **uuid**: ê³ ìœ  ì‹ë³„ì ìƒì„±
- **json**: ë©”ì‹œì§€/ì´ë²¤íŠ¸ ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™”
- **dataclasses**: ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜
- **datetime**: ì‹œê°„ ê¸°ë°˜ ë©”ì‹œì§€ ìŠ¤ì¼€ì¤„ë§

### **ê°œë°œ ë„êµ¬**
- **typing**: íƒ€ì… íŒíŠ¸ ë° íƒ€ì… ì•ˆì „ì„±
- **enum**: ë©”ì‹œì§€ ìƒíƒœ, ìš°ì„ ìˆœìœ„, ì´ë²¤íŠ¸ íƒ€ì… ì—´ê±°í˜•
- **abc**: ì¶”ìƒ í´ë˜ìŠ¤ ë° ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- **service.core.logger.Logger**: êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ

### **ì™¸ë¶€ ì˜ì¡´ì„±**
- **service.cache.CacheService**: Redis ìºì‹œ ì„œë¹„ìŠ¤
- **service.outbox.OutboxService**: ì•„ì›ƒë°•ìŠ¤ íŒ¨í„´ ì„œë¹„ìŠ¤
- **service.scheduler.SchedulerService**: ìŠ¤ì¼€ì¤„ëŸ¬ ì„œë¹„ìŠ¤

---

## ğŸª í•µì‹¬ í´ë˜ìŠ¤ ë° ë©”ì„œë“œ

### **QueueService - í†µí•© í ì„œë¹„ìŠ¤**

```python
class QueueService:
    """í†µí•© í ì„œë¹„ìŠ¤ - ë©”ì‹œì§€í/ì´ë²¤íŠ¸í/ì•„ì›ƒë°•ìŠ¤ íŒ¨í„´ í†µí•© ê´€ë¦¬"""
    
    _instance: Optional['QueueService'] = None
    _initialized: bool = False
    
    @classmethod
    def get_instance(cls) -> 'QueueService':
        """ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    
    @classmethod
    async def initialize(cls, db_service) -> bool:
        """í ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
    
    async def send_message(self, queue_name: str, payload: Dict[str, Any], 
                          message_type: str, priority: MessagePriority = MessagePriority.NORMAL,
                          scheduled_at: Optional[datetime] = None, 
                          partition_key: Optional[str] = None) -> bool:
        """ë©”ì‹œì§€ ì „ì†¡"""
    
    async def register_message_consumer(self, queue_name: str, consumer_id: str, 
                                      handler: Callable[[QueueMessage], bool]) -> bool:
        """ë©”ì‹œì§€ ì†Œë¹„ì ë“±ë¡"""
    
    async def publish_event(self, event_type: EventType, source: str, 
                           data: Dict[str, Any], correlation_id: Optional[str] = None) -> bool:
        """ì´ë²¤íŠ¸ ë°œí–‰"""
    
    async def subscribe_events(self, subscriber_id: str, event_types: List[EventType],
                              callback: Callable[[Event], bool]) -> Optional[str]:
        """ì´ë²¤íŠ¸ êµ¬ë…"""
```

### **MessageQueueManager - ë©”ì‹œì§€í ê´€ë¦¬ì**

```python
class MessageQueueManager:
    """ë©”ì‹œì§€í ë§¤ë‹ˆì € - Redis ê¸°ë°˜ ë©”ì‹œì§€í ê´€ë¦¬"""
    
    def __init__(self, cache_service):
        self.cache_service = cache_service
    
    async def enqueue_message(self, message: QueueMessage) -> bool:
        """ë©”ì‹œì§€ íì— ì¶”ê°€"""
    
    async def dequeue_message(self, queue_name: str, consumer_id: str) -> Optional[QueueMessage]:
        """ë©”ì‹œì§€ íì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
    
    async def ack_message(self, message_id: str, consumer_id: str) -> bool:
        """ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ í™•ì¸"""
    
    async def nack_message(self, message_id: str, consumer_id: str, retry: bool = True) -> bool:
        """ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ì²˜ë¦¬"""
    
    async def process_delayed_messages(self):
        """ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬"""
```

### **EventQueueManager - ì´ë²¤íŠ¸í ê´€ë¦¬ì**

```python
class EventQueueManager:
    """ì´ë²¤íŠ¸í ë§¤ë‹ˆì € - Redis ê¸°ë°˜ ì´ë²¤íŠ¸í ê´€ë¦¬"""
    
    def __init__(self, cache_service):
        self.cache_service = cache_service
    
    async def initialize(self):
        """ì´ë²¤íŠ¸í ì´ˆê¸°í™”"""
    
    async def publish_event(self, event: Event) -> bool:
        """ì´ë²¤íŠ¸ ë°œí–‰"""
    
    async def subscribe_events(self, subscriber_id: str, event_types: List[EventType],
                              callback: Callable[[Event], bool]) -> Optional[str]:
        """ì´ë²¤íŠ¸ êµ¬ë…"""
    
    async def unsubscribe_from_events(self, subscription_id: str) -> bool:
        """êµ¬ë… í•´ì œ"""
    
    async def process_published_events(self):
        """ë°œí–‰ëœ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
```

---

## ğŸŒ API ì—°ë™ ë°©ì‹

### **í ì„œë¹„ìŠ¤ ì´ˆê¸°í™”**

```python
# main.pyì—ì„œ DatabaseService ì´í›„ ì´ˆê¸°í™”
from service.queue.queue_service import initialize_queue_service

# DatabaseService ì´ˆê¸°í™” í›„
success = await initialize_queue_service(db_service)
if success:
    Logger.info("QueueService ì´ˆê¸°í™” ì™„ë£Œ")
else:
    Logger.error("QueueService ì´ˆê¸°í™” ì‹¤íŒ¨")
```

### **ë©”ì‹œì§€ ì „ì†¡ ë° ì†Œë¹„**

```python
from service.queue.queue_service import get_queue_service
from service.queue.message_queue import MessagePriority

queue_service = get_queue_service()

# ë©”ì‹œì§€ ì „ì†¡
await queue_service.send_message(
    queue_name="user_notifications",
    payload={"user_id": "user123", "message": "í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸"},
    message_type="notification",
    priority=MessagePriority.HIGH
)

# ë©”ì‹œì§€ ì†Œë¹„ì ë“±ë¡
async def notification_handler(message: QueueMessage) -> bool:
    try:
        # ë©”ì‹œì§€ ì²˜ë¦¬ ë¡œì§
        Logger.info(f"ì•Œë¦¼ ì²˜ë¦¬: {message.payload}")
        return True
    except Exception as e:
        Logger.error(f"ì•Œë¦¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

await queue_service.register_message_consumer(
    "user_notifications",
    "notification_worker_1",
    notification_handler
)
```

### **ì´ë²¤íŠ¸ ë°œí–‰ ë° êµ¬ë…**

```python
from service.queue.event_queue import EventType

# ì´ë²¤íŠ¸ ë°œí–‰
await queue_service.publish_event(
    event_type=EventType.PORTFOLIO_UPDATED,
    source="portfolio_service",
    data={"portfolio_id": "portfolio123", "changes": ["AAPL", "GOOGL"]}
)

# ì´ë²¤íŠ¸ êµ¬ë…
async def portfolio_event_handler(event: Event) -> bool:
    try:
        Logger.info(f"í¬íŠ¸í´ë¦¬ì˜¤ ì´ë²¤íŠ¸ ì²˜ë¦¬: {event.data}")
        return True
    except Exception as e:
        Logger.error(f"ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

await queue_service.subscribe_events(
    "portfolio_monitor",
    [EventType.PORTFOLIO_UPDATED, EventType.TRADE_EXECUTED],
    portfolio_event_handler
)
```

---

## ğŸ”„ í ì„œë¹„ìŠ¤ ì „ì²´ íë¦„

### **1. ë©”ì‹œì§€í ì²˜ë¦¬ í”Œë¡œìš°**
```
1. ë©”ì‹œì§€ ì „ì†¡ (send_message)
2. Redis ìš°ì„ ìˆœìœ„ íì— ì €ì¥
3. ì†Œë¹„ìê°€ ì§ì ‘ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (dequeue)
4. ë©”ì‹œì§€ ì²˜ë¦¬ ë° ACK/NACK
5. ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë˜ëŠ” DLQ ì´ë™
```

### **2. ì´ë²¤íŠ¸í ì²˜ë¦¬ í”Œë¡œìš°**
```
1. ì´ë²¤íŠ¸ ë°œí–‰ (publish_event)
2. êµ¬ë…ì íì— ì´ë²¤íŠ¸ ì§ì ‘ ì¶”ê°€
3. êµ¬ë…ìê°€ ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
4. ì½œë°± í•¨ìˆ˜ ì‹¤í–‰
5. ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹…
```

### **3. ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ í”Œë¡œìš°**
```
1. ì§€ì—° ë©”ì‹œì§€ ì˜ˆì•½ (scheduled_at)
2. Redis Sorted Setì— ì €ì¥
3. ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ì„œê°€ 10ì´ˆë§ˆë‹¤ í™•ì¸
4. ì‹¤í–‰ ì‹œê°„ ë„ë‹¬ ì‹œ ì¼ë°˜ íë¡œ ì´ë™
5. ì •ìƒì ì¸ ë©”ì‹œì§€ ì²˜ë¦¬ íë¦„
```

---

## ğŸ”Œ í ì‹œìŠ¤í…œ êµ¬í˜„ ìƒì„¸

### **Redis ê¸°ë°˜ ë©”ì‹œì§€í**

```python
class RedisCacheMessageQueue(IMessageQueue):
    """CacheServiceë¥¼ ì‚¬ìš©í•˜ëŠ” Redis ë©”ì‹œì§€í"""
    
    def __init__(self, cache_service):
        self.cache_service = cache_service
        
        # Redis í‚¤ íŒ¨í„´ë“¤
        self.message_key_pattern = "mq:message:{message_id}"
        self.priority_queue_pattern = "mq:priority:{queue_name}:{priority}"
        self.delayed_key_pattern = "mq:delayed:messages"
        self.processing_key_pattern = "mq:processing:{queue_name}"
        self.dlq_key_pattern = "mq:dlq:{queue_name}"
    
    async def enqueue(self, message: QueueMessage) -> bool:
        """ë©”ì‹œì§€ íì— ì¶”ê°€"""
        try:
            # ë©”ì‹œì§€ ë°ì´í„° ì €ì¥
            message_key = self.message_key_pattern.format(message_id=message.id)
            message_data = {
                "id": message.id,
                "queue_name": message.queue_name,
                "payload": json.dumps(message.payload),
                "message_type": message.message_type,
                "priority": message.priority.value,
                "status": message.status.value,
                "retry_count": message.retry_count,
                "max_retries": message.max_retries,
                "created_at": message.created_at.isoformat() if message.created_at else None,
                "scheduled_at": message.scheduled_at.isoformat() if message.scheduled_at else None,
                "partition_key": message.partition_key
            }
            
            # ìš°ì„ ìˆœìœ„ íì— ì¶”ê°€
            priority_queue_key = self.priority_queue_pattern.format(
                queue_name=message.queue_name, 
                priority=message.priority.value
            )
            
            await self.cache_service.set_hash(message_key, message_data)
            await self.cache_service.lpush(priority_queue_key, message.id)
            
            # ì§€ì—° ë©”ì‹œì§€ì¸ ê²½ìš° Sorted Setì— ì¶”ê°€
            if message.scheduled_at:
                score = message.scheduled_at.timestamp()
                await self.cache_service.zadd(self.delayed_key_pattern, {message.id: score})
            
            Logger.info(f"ë©”ì‹œì§€ íì— ì¶”ê°€: {message.id} (ìš°ì„ ìˆœìœ„: {message.priority.value})")
            return True
            
        except Exception as e:
            Logger.error(f"ë©”ì‹œì§€ í ì¶”ê°€ ì‹¤íŒ¨: {message.id} - {e}")
            return False
```

### **ì´ë²¤íŠ¸í Pub/Sub êµ¬í˜„**

```python
class RedisCacheEventQueue(IEventQueue):
    """CacheServiceë¥¼ ì‚¬ìš©í•˜ëŠ” Redis ì´ë²¤íŠ¸í"""
    
    def __init__(self, cache_service):
        self.cache_service = cache_service
        
        # Redis í‚¤ íŒ¨í„´
        self.event_stream_pattern = "eq:stream:{event_type}"
        self.subscription_key = "eq:subscriptions"
        self.subscriber_key_pattern = "eq:subscriber:{subscriber_id}"
        self.event_history_pattern = "eq:history:{event_type}"
        
        # êµ¬ë…ì ì •ë³´
        self.subscriptions: Dict[str, Subscription] = {}
        self.active_subscribers: Set[str] = set()
    
    async def publish(self, event: Event) -> bool:
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        try:
            # ì´ë²¤íŠ¸ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”
            event_payload = {
                "event": {
                    "id": event.id,
                    "event_type": event.event_type.value,
                    "source": event.source,
                    "data": event.data,
                    "timestamp": event.timestamp.isoformat(),
                    "correlation_id": event.correlation_id,
                    "version": event.version,
                    "metadata": event.metadata
                }
            }
            
            event_json = json.dumps(event_payload)
            
            # ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬ì— ì €ì¥
            history_key = self.event_history_pattern.format(event_type=event.event_type.value)
            await self.cache_service.list_push_right(history_key, event_json)
            await self.cache_service.expire(history_key, 86400)  # 24ì‹œê°„ í›„ ë§Œë£Œ
            
            # ê´€ë ¨ êµ¬ë…ìë“¤ì—ê²Œ ì´ë²¤íŠ¸ ì „ë‹¬
            for subscription in self.subscriptions.values():
                if event.event_type in subscription.event_types and subscription.active:
                    subscriber_queue_key = self.subscriber_key_pattern.format(
                        subscriber_id=subscription.subscriber_id
                    )
                    await self.cache_service.list_push_right(subscriber_queue_key, event_json)
            
            Logger.info(f"ì´ë²¤íŠ¸ ë°œí–‰ ì™„ë£Œ: {event.id} ({event.event_type.value})")
            return True
            
        except Exception as e:
            Logger.error(f"ì´ë²¤íŠ¸ ë°œí–‰ ì‹¤íŒ¨: {event.id} - {e}")
            return False
```

---

## ğŸ”¬ ê³ ê¸‰ ê¸°ëŠ¥ ì‹¬ì¸µ ë¶„ì„: í ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

í ì„œë¹„ìŠ¤ì˜ í•µì‹¬ì€ **ë©”ì‹œì§€íì™€ ì´ë²¤íŠ¸íì˜ í†µí•© ê´€ë¦¬**ì™€ **ì•„ì›ƒë°•ìŠ¤ íŒ¨í„´ê³¼ì˜ ì—°ë™**ì…ë‹ˆë‹¤.

### **1. ê°œìš”**
ì´ ì‹œìŠ¤í…œì€ **Redisë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³ ì„±ëŠ¥ ë©”ì‹œì§€ ì²˜ë¦¬**ì™€ **ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜**ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì „í†µì ì¸ ë™ê¸°ì‹ ì²˜ë¦¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , **ë¹„ë™ê¸° ë©”ì‹œì§€ ì²˜ë¦¬**ì™€ **ì´ë²¤íŠ¸ ì£¼ë„ ì„¤ê³„**ë¥¼ í†µí•´ ì‹œìŠ¤í…œì˜ í™•ì¥ì„±ê³¼ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

### **2. í•µì‹¬ ì•„í‚¤í…ì²˜ ë° ë°ì´í„° í”Œë¡œìš°**

#### **2.1 ë©”ì‹œì§€í ìš°ì„ ìˆœìœ„ ì²˜ë¦¬**
```python
async def dequeue_message(self, queue_name: str, consumer_id: str) -> Optional[QueueMessage]:
    """ë©”ì‹œì§€ íì—ì„œ ê°€ì ¸ì˜¤ê¸° (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)"""
    try:
        # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ í í™•ì¸ (CRITICAL â†’ HIGH â†’ NORMAL â†’ LOW)
        for priority in [MessagePriority.CRITICAL, MessagePriority.HIGH, 
                        MessagePriority.NORMAL, MessagePriority.LOW]:
            
            priority_queue_key = self.priority_queue_pattern.format(
                queue_name=queue_name, 
                priority=priority.value
            )
            
            # ì›ìì  ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
            message_id = await self.cache_service.rpop(priority_queue_key)
            if message_id:
                # ë©”ì‹œì§€ ë°ì´í„° ì¡°íšŒ
                message_key = self.message_key_pattern.format(message_id=message_id)
                message_data = await self.cache_service.get_hash(message_key)
                
                if message_data:
                    # ì²˜ë¦¬ ì¤‘ ìƒíƒœë¡œ ë³€ê²½
                    processing_key = self.processing_key_pattern.format(queue_name=queue_name)
                    await self.cache_service.hset(processing_key, message_id, consumer_id)
                    
                    # QueueMessage ê°ì²´ ìƒì„±
                    message = QueueMessage(
                        id=message_id,
                        queue_name=queue_name,
                        payload=json.loads(message_data["payload"]),
                        message_type=message_data["message_type"],
                        priority=MessagePriority(int(message_data["priority"])),
                        status=MessageStatus(message_data["status"]),
                        retry_count=int(message_data["retry_count"]),
                        max_retries=int(message_data["max_retries"]),
                        created_at=datetime.fromisoformat(message_data["created_at"]) if message_data["created_at"] else None,
                        scheduled_at=datetime.fromisoformat(message_data["scheduled_at"]) if message_data["scheduled_at"] else None,
                        partition_key=message_data.get("partition_key")
                    )
                    
                    Logger.info(f"ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°: {message_id} (ìš°ì„ ìˆœìœ„: {priority.value})")
                    return message
        
        return None
        
    except Exception as e:
        Logger.error(f"ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None
```

#### **2.2 ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ**
```python
async def process_delayed_messages(self):
    """ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        current_time = datetime.now().timestamp()
        
        # ì‹¤í–‰ ì‹œê°„ì´ ë„ë‹¬í•œ ì§€ì—° ë©”ì‹œì§€ ì¡°íšŒ
        ready_messages = await self.cache_service.zrangebyscore(
            self.delayed_key_pattern,
            min_score=0,
            max_score=current_time
        )
        
        for message_id in ready_messages:
            try:
                # ë©”ì‹œì§€ ë°ì´í„° ì¡°íšŒ
                message_key = self.message_key_pattern.format(message_id=message_id)
                message_data = await self.cache_service.get_hash(message_key)
                
                if message_data:
                    # ì§€ì—° ë©”ì‹œì§€ì—ì„œ ì œê±°
                    await self.cache_service.zrem(self.delayed_key_pattern, message_id)
                    
                    # ì¼ë°˜ ìš°ì„ ìˆœìœ„ íë¡œ ì´ë™
                    priority = int(message_data["priority"])
                    priority_queue_key = self.priority_queue_pattern.format(
                        queue_name=message_data["queue_name"], 
                        priority=priority
                    )
                    
                    await self.cache_service.lpush(priority_queue_key, message_id)
                    
                    Logger.info(f"ì§€ì—° ë©”ì‹œì§€ í™œì„±í™”: {message_id}")
                
            except Exception as e:
                Logger.error(f"ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {message_id} - {e}")
        
    except Exception as e:
        Logger.error(f"ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
```

### **3. ì‹¤ì œ êµ¬í˜„ëœ ë™ì‘ ê³¼ì •**

#### **3.1 ë©”ì‹œì§€ ì²˜ë¦¬ ê³¼ì •**
```
1. ë©”ì‹œì§€ ì „ì†¡ (ìš°ì„ ìˆœìœ„, ì§€ì—°ì‹œê°„ ì„¤ì • ê°€ëŠ¥)
2. Redis ìš°ì„ ìˆœìœ„ íì— ì €ì¥
3. ì†Œë¹„ìê°€ ì§ì ‘ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (dequeue)
4. ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
5. ë©”ì‹œì§€ ì²˜ë¦¬ ë° ACK/NACK
6. ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë˜ëŠ” DLQ ì´ë™
```

#### **3.2 ì´ë²¤íŠ¸ ì²˜ë¦¬ ê³¼ì •**
```
1. ì´ë²¤íŠ¸ ë°œí–‰ (ë„ë©”ì¸ë³„ ì´ë²¤íŠ¸ íƒ€ì…)
2. êµ¬ë…ì íì— ì´ë²¤íŠ¸ ì§ì ‘ ì¶”ê°€
3. êµ¬ë…ìê°€ ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
4. ì´ë²¤íŠ¸ ì²˜ë¦¬ ë° ì½œë°± í•¨ìˆ˜ ì‹¤í–‰
5. ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹…
```

### **4. ì„±ëŠ¥ ìµœì í™” íš¨ê³¼**

#### **4.1 ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì²˜ë¦¬**
```
ìš°ì„ ìˆœìœ„ë³„ ë…ë¦½ í:
- CRITICAL: ì¦‰ì‹œ ì²˜ë¦¬ (ì‹œìŠ¤í…œ ì•Œë¦¼, ì˜¤ë¥˜ ë“±)
- HIGH: ë†’ì€ ìš°ì„ ìˆœìœ„ (ì‚¬ìš©ì ì•Œë¦¼, ê±°ë˜ ì‹¤í–‰ ë“±)
- NORMAL: ì¼ë°˜ ìš°ì„ ìˆœìœ„ (ì¼ë°˜ ì‘ì—…)
- LOW: ë‚®ì€ ìš°ì„ ìˆœìœ„ (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)
```

#### **4.2 ì§€ì—° ë©”ì‹œì§€ ìµœì í™”**
```
Redis Sorted Set í™œìš©:
- ì‹¤í–‰ ì‹œê°„ì„ scoreë¡œ ì‚¬ìš©
- O(log N) ì‹œê°„ ë³µì¡ë„ë¡œ íš¨ìœ¨ì  ì¡°íšŒ
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
```

### **5. ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬**

#### **5.1 ì¬ì‹œë„ ë¡œì§**
```python
async def nack_message(self, message_id: str, consumer_id: str, retry: bool = True) -> bool:
    """ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ì²˜ë¦¬"""
    try:
        # ë©”ì‹œì§€ ë°ì´í„° ì¡°íšŒ
        message_key = self.message_key_pattern.format(message_id=message_id)
        message_data = await self.cache_service.get_hash(message_key)
        
        if message_data:
            retry_count = int(message_data["retry_count"])
            max_retries = int(message_data["max_retries"])
            
            if retry and retry_count < max_retries:
                # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
                new_retry_count = retry_count + 1
                await self.cache_service.hset(message_key, "retry_count", new_retry_count)
                
                # ì¬ì‹œë„ ëŒ€ê¸° ìƒíƒœë¡œ ë³€ê²½
                await self.cache_service.hset(message_key, "status", MessageStatus.RETRY.value)
                
                # ì›ë˜ ìš°ì„ ìˆœìœ„ íì— ë‹¤ì‹œ ì¶”ê°€
                priority = int(message_data["priority"])
                priority_queue_key = self.priority_queue_pattern.format(
                    queue_name=message_data["queue_name"], 
                    priority=priority
                )
                
                await self.cache_service.lpush(priority_queue_key, message_id)
                
                Logger.warning(f"ë©”ì‹œì§€ ì¬ì‹œë„ ì˜ˆì•½: {message_id} ({new_retry_count}/{max_retries})")
                
            else:
                # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ì‹œ DLQë¡œ ì´ë™
                await self.cache_service.hset(message_key, "status", MessageStatus.FAILED.value)
                
                dlq_key = self.dlq_key_pattern.format(queue_name=message_data["queue_name"])
                await self.cache_service.lpush(dlq_key, message_id)
                
                Logger.error(f"ë©”ì‹œì§€ ìµœì¢… ì‹¤íŒ¨ - DLQ ì´ë™: {message_id}")
            
            # ì²˜ë¦¬ ì¤‘ ìƒíƒœì—ì„œ ì œê±°
            processing_key = self.processing_key_pattern.format(queue_name=message_data["queue_name"])
            await self.cache_service.hdel(processing_key, message_id)
            
            return True
            
    except Exception as e:
        Logger.error(f"ë©”ì‹œì§€ NACK ì²˜ë¦¬ ì‹¤íŒ¨: {message_id} - {e}")
        return False
```

#### **5.2 ìë™ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜**
```python
async def _start_delayed_message_processor_with_check(self):
    """CacheService ì—°ê²° ì²´í¬ë¥¼ í¬í•¨í•œ ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ê¸° ì‹œì‘"""
    async def process_delayed_with_cache_check():
        while self.__class__._initialized:  # ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
            try:
                # CacheService ì—°ê²° ìƒíƒœ í™•ì¸
                cache_service = CacheService.get_instance()
                if not cache_service.is_initialized():
                    Logger.debug("CacheServiceê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ. ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ ê±´ë„ˆëœ€")
                    await asyncio.sleep(30)
                    continue
                
                # ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸
                health_check = await cache_service.health_check()
                if not health_check.get("healthy", False):
                    Logger.debug(f"Redis ì—°ê²° ë¶ˆì•ˆì •: {health_check.get('error', 'Unknown')}. ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ ê±´ë„ˆëœ€")
                    await asyncio.sleep(30)
                    continue
                
                # ì •ìƒ ì²˜ë¦¬
                await self.message_queue_manager.message_queue.process_delayed_messages()
                await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ í™•ì¸
                
            except Exception as e:
                Logger.error(f"ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ê¸° ì˜¤ë¥˜: {e}")
                await asyncio.sleep(30)
        
        Logger.debug("ì§€ì—° ë©”ì‹œì§€ ì²˜ë¦¬ê¸° ì¢…ë£Œ")
    
    asyncio.create_task(process_delayed_with_cache_check())
```

### **6. ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€**

#### **6.1 ì‚¬ìš©ì ì•Œë¦¼ ì‹œìŠ¤í…œ**
```python
# ê³ ìš°ì„ ìˆœìœ„ ì•Œë¦¼ ë©”ì‹œì§€
await queue_service.send_message(
    queue_name="user_notifications",
    payload={
        "user_id": "user123",
        "message": "ì£¼ê°€ ì•Œë¦¼: AAPLì´ $150.00ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤",
        "notification_type": "price_alert",
        "stock_symbol": "AAPL",
        "target_price": 150.00
    },
    message_type="price_alert",
    priority=MessagePriority.HIGH
)

# ì•Œë¦¼ ì†Œë¹„ì ë“±ë¡
async def price_alert_handler(message: QueueMessage) -> bool:
    try:
        payload = message.payload
        user_id = payload["user_id"]
        message_text = payload["message"]
        
        # í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ 
        await send_push_notification(user_id, message_text)
        
        # ì•Œë¦¼ ë¡œê·¸ ì €ì¥ 
        await save_notification_log(user_id, "price_alert", message_text)
        
        Logger.info(f"ê°€ê²© ì•Œë¦¼ ì²˜ë¦¬ ì™„ë£Œ: {user_id}")
        return True
        
    except Exception as e:
        Logger.error(f"ê°€ê²© ì•Œë¦¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

await queue_service.register_message_consumer(
    "user_notifications",
    "price_alert_worker",
    price_alert_handler
)
```

#### **6.2 í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹± ìŠ¤ì¼€ì¤„ë§**
```python
# 10ë¶„ í›„ ì‹¤í–‰ë  ë¦¬ë°¸ëŸ°ì‹± ì‘ì—…
delayed_time = datetime.now() + timedelta(minutes=10)

await queue_service.send_message(
    queue_name="portfolio_tasks",
    payload={
        "task_type": "portfolio_rebalancing",
        "portfolio_id": "portfolio123",
        "target_allocation": {
            "stocks": 0.6,
            "bonds": 0.3,
            "cash": 0.1
        },
        "rebalance_threshold": 0.05
    },
    message_type="scheduled_task",
    priority=MessagePriority.NORMAL,
    scheduled_at=delayed_time
)

# ë¦¬ë°¸ëŸ°ì‹± ì‘ì—… ì²˜ë¦¬ì
async def rebalancing_handler(message: QueueMessage) -> bool:
    try:
        payload = message.payload
        portfolio_id = payload["portfolio_id"]
        target_allocation = payload["target_allocation"]
        
        # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ
        current_portfolio = await get_portfolio(portfolio_id)
        
        # ë¦¬ë°¸ëŸ°ì‹± ê³„ì‚°
        rebalancing_orders = calculate_rebalancing_orders(
            current_portfolio, target_allocation
        )
        
        # ì£¼ë¬¸ ì‹¤í–‰
        for order in rebalancing_orders:
            await execute_trade_order(order)
        
        Logger.info(f"í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹± ì™„ë£Œ: {portfolio_id}")
        return True
        
    except Exception as e:
        Logger.error(f"í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹± ì‹¤íŒ¨: {e}")
        return False

await queue_service.register_message_consumer(
    "portfolio_tasks",
    "rebalancing_worker",
    rebalancing_handler
)
```

### **7. í•µì‹¬ íŠ¹ì§• ë° ì¥ì **

#### **7.1 ì„±ëŠ¥ ë° í™•ì¥ì„±**
- **Redis ê¸°ë°˜**: ê³ ì„±ëŠ¥ ì¸ë©”ëª¨ë¦¬ ë°ì´í„° êµ¬ì¡°
- **ìš°ì„ ìˆœìœ„ ì²˜ë¦¬**: ì¤‘ìš”ë„ì— ë”°ë¥¸ ë©”ì‹œì§€ ì²˜ë¦¬ ìˆœì„œ
- **ì§€ì—° ì‹¤í–‰**: ë¯¸ë˜ ì‹œì  ì‘ì—… ìŠ¤ì¼€ì¤„ë§
- **ë°°ì¹˜ ì²˜ë¦¬**: íš¨ìœ¨ì ì¸ ë©”ì‹œì§€ ì²˜ë¦¬

#### **7.2 ì•ˆì •ì„± ë° ì‹ ë¢°ì„±**
- **ì¬ì‹œë„ ë¡œì§**: ì‹¤íŒ¨í•œ ë©”ì‹œì§€ì˜ ìë™ ì¬ì‹œë„
- **Dead Letter Queue**: ì²˜ë¦¬ ë¶ˆê°€ëŠ¥í•œ ë©”ì‹œì§€ ê²©ë¦¬
- **ë¶„ì‚°ë½**: ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
- **ìƒíƒœ ì¶”ì **: ë©”ì‹œì§€ì˜ ì „ì²´ ìƒëª…ì£¼ê¸° ì¶”ì 

#### **7.3 ìœ ì—°ì„± ë° í™•ì¥ì„±**
- **ì´ë²¤íŠ¸ ê¸°ë°˜**: ëŠìŠ¨í•œ ê²°í•©ì˜ ì‹œìŠ¤í…œ ì„¤ê³„
- **ë™ì  êµ¬ë…**: ëŸ°íƒ€ì„ì— ì´ë²¤íŠ¸ êµ¬ë…/í•´ì œ
- **í•„í„°ë§**: ì´ë²¤íŠ¸ íƒ€ì…ê³¼ ì¡°ê±´ ê¸°ë°˜ êµ¬ë…
- **ì•„ì›ƒë°•ìŠ¤ ì—°ë™**: íŠ¸ëœì­ì…˜ ì¼ê´€ì„± ë³´ì¥

ì´ ì‹œìŠ¤í…œì€ ë‹¨ìˆœí•œ ë©”ì‹œì§€ ì „ë‹¬ì„ ë„˜ì–´ì„œ **ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì²˜ë¦¬**, **ì§€ì—° ì‹¤í–‰**, **ì´ë²¤íŠ¸ ì£¼ë„ ì„¤ê³„**, **íŠ¸ëœì­ì…˜ ì¼ê´€ì„±**ì„ ì œê³µí•˜ëŠ” ê³ ë„í™”ëœ í ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

---

## ğŸ“Š ì‚¬ìš© ì˜ˆì œ

### **ê¸°ë³¸ ë©”ì‹œì§€í ì‚¬ìš©**

```python
from service.queue.queue_service import get_queue_service
from service.queue.message_queue import MessagePriority

queue_service = get_queue_service()

# ë©”ì‹œì§€ ì „ì†¡
await queue_service.send_message(
    queue_name="email_notifications",
    payload={
        "to": "user@example.com",
        "subject": "í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸",
        "body": "í¬íŠ¸í´ë¦¬ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
    },
    message_type="email",
    priority=MessagePriority.NORMAL
)

# ë©”ì‹œì§€ ì†Œë¹„ì ë“±ë¡
async def email_handler(message: QueueMessage) -> bool:
    try:
        payload = message.payload
        # ì´ë©”ì¼ ë°œì†¡ ë¡œì§
        from service.email.email_service import EmailService
        await EmailService.send_email(
            to_emails=[payload["to"]],
            subject=payload["subject"],
            body=payload["body"]
        )
        return True
    except Exception as e:
        Logger.error(f"ì´ë©”ì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

await queue_service.register_message_consumer(
    "email_notifications",
    "email_worker",
    email_handler
)
```

### **ì§€ì—° ë©”ì‹œì§€ ìŠ¤ì¼€ì¤„ë§**

```python
from datetime import datetime, timedelta

# 1ì‹œê°„ í›„ ì‹¤í–‰ë  ì‘ì—…
delayed_time = datetime.now() + timedelta(hours=1)

await queue_service.send_message(
    queue_name="maintenance_tasks",
    payload={
        "task": "database_cleanup",
        "tables": ["user_sessions", "temp_data"],
        "retention_days": 30
    },
    message_type="maintenance",
    priority=MessagePriority.LOW,
    scheduled_at=delayed_time
)
```

### **ì´ë²¤íŠ¸ ê¸°ë°˜ ì‹œìŠ¤í…œ**

```python
from service.queue.event_queue import EventType

# í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸ ì´ë²¤íŠ¸ ë°œí–‰
await queue_service.publish_event(
    event_type=EventType.PORTFOLIO_UPDATED,
    source="portfolio_service",
    data={
        "portfolio_id": "portfolio123",
        "user_id": "user456",
        "changes": ["AAPL", "GOOGL"],
        "timestamp": datetime.now().isoformat()
    }
)

# ì´ë²¤íŠ¸ êµ¬ë…
async def portfolio_update_handler(event: Event) -> bool:
    try:
        # í¬íŠ¸í´ë¦¬ì˜¤ ë³€ê²½ ì•Œë¦¼
        Logger.info(f"í¬íŠ¸í´ë¦¬ì˜¤ ë³€ê²½ ì´ë²¤íŠ¸ ì²˜ë¦¬: {event.data}")
        # ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸ ë¡œì§ êµ¬í˜„ í•„ìš”
        # await update_portfolio(event.data)
        return True
    except Exception as e:
        Logger.error(f"í¬íŠ¸í´ë¦¬ì˜¤ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

await queue_service.subscribe_events(
    "portfolio_monitor",
    [EventType.PORTFOLIO_UPDATED, EventType.TRADE_EXECUTED],
    portfolio_update_handler
)
```

---

## âš™ï¸ ì„¤ì •

### **QueueService ì„¤ì •**

```python
# main.pyì—ì„œ ì´ˆê¸°í™”
from service.queue.queue_service import initialize_queue_service

# DatabaseService ì´ˆê¸°í™” í›„
success = await initialize_queue_service(db_service)
if not success:
    Logger.error("QueueService ì´ˆê¸°í™” ì‹¤íŒ¨")
    exit(1)
```

### **Redis ì„¤ì • (CacheServiceë¥¼ í†µí•´)**

```json
{
  "cache": {
    "redis": {
      "host": "your_redis_host",
      "port": 6379,
      "db": 0,
      "password": "your_redis_password",
      "max_connections": 10
    }
  }
}
```

### **ë©”ì‹œì§€í ì„¤ì •**

```python
# ë©”ì‹œì§€ ìš°ì„ ìˆœìœ„
MessagePriority.LOW = 1      # ë‚®ì€ ìš°ì„ ìˆœìœ„
MessagePriority.NORMAL = 2   # ì¼ë°˜ ìš°ì„ ìˆœìœ„
MessagePriority.HIGH = 3     # ë†’ì€ ìš°ì„ ìˆœìœ„
MessagePriority.CRITICAL = 4 # ìµœê³  ìš°ì„ ìˆœìœ„

# ì¬ì‹œë„ ì„¤ì •
max_retries = 3              # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (QueueMessage ê¸°ë³¸ê°’)
```

---

## ğŸ”— ì—°ê´€ í´ë”

### **ì‚¬ìš©í•˜ëŠ” Service**
- **service.cache.CacheService**: Redis ìºì‹œ ì„œë¹„ìŠ¤ë¥¼ í†µí•œ ë©”ì‹œì§€/ì´ë²¤íŠ¸ ì €ì¥
- **service.outbox.OutboxService**: íŠ¸ëœì­ì…˜ ì¼ê´€ì„±ì„ ìœ„í•œ ì•„ì›ƒë°•ìŠ¤ íŒ¨í„´ ì—°ë™
- **service.scheduler.SchedulerService**: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìŠ¤ì¼€ì¤„ë§

### **ì‚¬ìš©í•˜ëŠ” Template**
- **template.chat**: ì±„íŒ… ì˜ì†ì„± ì»¨ìŠˆë¨¸ë¥¼ QueueServiceì— ë“±ë¡í•˜ì—¬ ë©”ì‹œì§€ ì²˜ë¦¬
- **template.notification**: ì•Œë¦¼ ì˜ì†ì„± ì»¨ìŠˆë¨¸ë¥¼ QueueServiceì— ë“±ë¡í•˜ì—¬ ì•Œë¦¼ ì²˜ë¦¬
- **template.admin**: QueueService ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° í í†µê³„ ì¡°íšŒ

### **ì˜ì¡´ì„± ê´€ê³„**
- **service.core.logger.Logger**: êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ
- **service.db.DatabaseService**: ì•„ì›ƒë°•ìŠ¤ ì´ë²¤íŠ¸ ì˜ì†ì„± ì €ì¥
- **application.base_web_server.main**: ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° í†µí•©

---

## ğŸ“š ì™¸ë¶€ ì‹œìŠ¤í…œ

### **Redis**
- **ë©”ì‹œì§€í**: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë©”ì‹œì§€ ì €ì¥ ë° ì²˜ë¦¬
- **ì´ë²¤íŠ¸í**: Pub/Sub íŒ¨í„´ì˜ ì´ë²¤íŠ¸ ì „íŒŒ
- **ì§€ì—° ë©”ì‹œì§€**: Sorted Setì„ í™œìš©í•œ ìŠ¤ì¼€ì¤„ë§
- **ë¶„ì‚°ë½**: ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€

### **MySQL**
- **ì•„ì›ƒë°•ìŠ¤ ì´ë²¤íŠ¸**: OutboxServiceë¥¼ í†µí•œ íŠ¸ëœì­ì…˜ ì¼ê´€ì„± ë³´ì¥ (QueueServiceì™€ ì—°ë™)

---