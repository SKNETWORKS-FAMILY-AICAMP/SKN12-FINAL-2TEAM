from __future__ import annotations

import json, os
from typing import List, Dict, Any
from dotenv import load_dotenv
from pydantic import BaseModel

from langchain_openai import ChatOpenAI
from langchain.tools import tool
from langgraph.graph import StateGraph, MessagesState, END
from langgraph.prebuilt import ToolNode

from .tool.specialist_agents import (
    FinancialStatementAgent, FinancialStatementInput,
    NewsAgent, NewsInput,
    TechnicalAnalysisAgent, TechnicalAnalysisInput,
    MacroEconomicAgent, MacroEconomicInput,
    SectorAnalysisAgent, SectorAnalysisInput
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. í™˜ê²½ ë³€ìˆ˜
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not (OPENAI_API_KEY and OPENAI_API_KEY.startswith("sk-")):
    raise ValueError("âŒ ìœ íš¨í•œ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Tool ì •ì˜
@tool
def financial_statement(ticker: str) -> str:
    """ì¢…ëª©ì˜ ìž¬ë¬´ì œí‘œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ë§¤ì¶œ, ìˆœì´ìµ, EPS)."""
    agent = FinancialStatementAgent()
    result = agent.process(FinancialStatementInput(ticker=ticker))
    return result.summary

@tool
def news(query: str, k: int = 5) -> str:
    """íŠ¹ì • í‚¤ì›Œë“œì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    agent = NewsAgent()
    result = agent.process(NewsInput(query=query, k=k))
    return result.summary

@tool
def technical_analysis(tickers: list[str]) -> str:
    """ì¢…ëª©ë“¤ì˜ ê¸°ìˆ ì  ì§€í‘œ (RSI, MACD, EMA)ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    agent = TechnicalAnalysisAgent()
    results = agent.process(TechnicalAnalysisInput(tickers=tickers))
    return "\n".join([r.summary for r in results])

@tool
def macro_economic(series_ids: list[str]) -> str:
    """ê±°ì‹œê²½ì œ ì§€í‘œ (ê¸ˆë¦¬, CPI ë“±)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    agent = MacroEconomicAgent()
    result = agent.process(MacroEconomicInput(series_ids=series_ids))
    return result.summary

@tool
def sector_analysis(sector_name: str) -> str:
    """ì„¹í„° PER/PBR ë° ëŒ€í‘œ ì¢…ëª©ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    agent = SectorAnalysisAgent()
    result = agent.process(SectorAnalysisInput(sector_name=sector_name))
    return result.summary

TOOLS = [
    financial_statement,
    news,
    technical_analysis,
    macro_economic,
    sector_analysis
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. LLM + íˆ´ ë°”ì¸ë”©
llm = ChatOpenAI(
    model="gpt-4o-mini",
    api_key=OPENAI_API_KEY,
    temperature=0,
)
llm_with_tools = llm.bind_tools(TOOLS)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. LangGraph ë…¸ë“œ ì •ì˜

def should_continue(state: MessagesState):
    last = state["messages"][-1]
    tool_calls = getattr(last, "tool_calls", None)
    if not tool_calls:
        return END

    called_names = set()
    for msg in state["messages"]:
        for tc in getattr(msg, "tool_calls", []):
            if hasattr(tc, "name"):
                called_names.add(tc.name)

    for tc in tool_calls:
        if hasattr(tc, "name") and tc.name in called_names:
            return END

    return "tools"

def call_model(state: MessagesState):
    print("ðŸ”„ call_model: ", state["messages"])
    resp = llm_with_tools.invoke(state["messages"])
    return {"messages": state["messages"] + [resp]}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ê·¸ëž˜í”„ êµ¬ì¶• í•¨ìˆ˜
def build_workflow():
    builder = StateGraph(MessagesState)
    builder.add_node("call_model", call_model)
    builder.add_node("tools", ToolNode(TOOLS))

    from langgraph.graph import START
    builder.add_edge(START, "call_model")
    builder.add_conditional_edges("call_model", should_continue, {"tools", END})
    builder.add_edge("tools", "call_model")

    return builder.compile()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. ì™¸ë¶€ ì‹¤í–‰ í•¨ìˆ˜
def run_question(question: str) -> str:
    graph = build_workflow()
    result = graph.invoke({"messages": [{"role": "user", "content": question}]})
    return "\n".join(getattr(m, "content", str(m)) for m in result["messages"])
