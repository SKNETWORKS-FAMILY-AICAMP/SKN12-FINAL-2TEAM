import yfinance as yf
import pandas as pd
import os
import json
from datetime import datetime
import time

# --- ì„¤ì • ---
# 1. ì›í•˜ëŠ” ì¢…ëª©ì˜ í‹°ì»¤ ì‹¬ë³¼ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì„¸ìš”.
TICKER_LIST = [
    # ëŒ€í˜• í…Œí¬ì£¼ (FAANG+)
    "AAPL", "MSFT", "GOOG", "GOOGL", "AMZN", "META", "TSLA", "NVDA", "NFLX", "ORCL", "CRM", "ADBE", "INTC", "AMD", "CSCO", "IBM",
    
    # ë°˜ë„ì²´
    "QCOM", "AVGO", "TXN", "MU", "AMAT", "LRCX", "ADI", "MCHP", "KLAC", "MRVL",
    
    # ì£¼ìš” ETFë“¤
    "SPY", "QQQ", "VTI", "IWM", "VEA", "VWO", "EFA", "GLD", "SLV", "TLT", "HYG", "LQD", "XLF", "XLK", "XLE", "XLV", "XLI", "XLP", "XLU", "XLRE",
    
    # ê¸ˆìœµ (ì€í–‰, ë³´í—˜, í•€í…Œí¬)
    "JPM", "BAC", "WFC", "C", "GS", "MS", "BRK-B", "V", "MA", "PYPL", "SQ", "AXP", "USB", "PNC", "TFC", "COF",
    
    # í—¬ìŠ¤ì¼€ì–´/ì œì•½
    "JNJ", "PFE", "UNH", "ABBV", "MRK", "TMO", "ABT", "DHR", "BMY", "AMGN", "GILD", "BIIB", "CVS", "CI", "ANTM", "HUM",
    
    # ì†Œë¹„ì¬ (í•„ìˆ˜/ì„ì˜)
    "PG", "KO", "PEP", "WMT", "HD", "MCD", "NKE", "SBUX", "TGT", "LOW", "COST", "DIS", "BABA", "AMZN", "EBAY", "ETSY",
    
    # ì—ë„ˆì§€
    "XOM", "CVX", "COP", "EOG", "SLB", "PSX", "VLO", "KMI", "OKE", "WMB",
    
    # ì‚°ì—…ì¬/í•­ê³µ
    "BA", "CAT", "DE", "GE", "HON", "MMM", "UPS", "FDX", "LMT", "RTX", "AAL", "DAL", "UAL", "LUV",
    
    # í†µì‹ 
    "VZ", "T", "TMUS", "CHTR", "CMCSA", "DISH",
    
    # ìë™ì°¨
    "F", "GM", "RIVN", "LCID", "NIO", "XPEV", "LI",
    
    # ë¶€ë™ì‚° REITs
    "AMT", "PLD", "CCI", "EQIX", "SPG", "O", "WELL", "EXR", "AVB", "EQR",
    
    # ìœ í‹¸ë¦¬í‹°
    "NEE", "DUK", "SO", "D", "AEP", "EXC", "XEL", "SRE", "PEG", "ED",
    
    # ì—”í„°í…Œì¸ë¨¼íŠ¸/ë¯¸ë””ì–´
    "DIS", "NFLX", "ROKU", "SPOT", "WBD", "PARA", "FOX", "FOXA",
    
    # ì¤‘êµ­ ADR
    "BABA", "JD", "PDD", "BIDU", "BILI", "DIDI", "TME",
    
    # ì•”í˜¸í™”í ê´€ë ¨
    "COIN", "MSTR", "RIOT", "MARA", "BITB", "IBIT",
    
    # ê¸°íƒ€ ì£¼ìš” ê¸°ì—…ë“¤
    "TSLA", "UBER", "LYFT", "SNAP", "TWTR", "ZOOM", "DOCU", "PLTR", "SNOW", "CRM", "WORK", "ZM", "PTON", "ARKK", "ARKG", "ARKW"
] 

START_DATE = pd.to_datetime(datetime(2025, 7, 3)).tz_localize('UTC')
END_DATE = pd.to_datetime(datetime(2025, 7, 9, 23, 59, 59)).tz_localize('UTC')
OUTPUT_FILE = "yahoo_finance_news.json"  # JSON íŒŒì¼ë¡œ ë³€ê²½
# --- ì„¤ì • ë ---

def get_news_for_tickers():
    """yfinanceë¥¼ ì´ìš©í•´ ì—¬ëŸ¬ ì¢…ëª©ì˜ ë‰´ìŠ¤ ëª©ë¡ì„ JSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    
    all_news_list = []
    
    print("âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ëŒ€ìƒ ì¢…ëª©: {TICKER_LIST}")
    print(f"ìˆ˜ì§‘ ê¸°ê°„: {START_DATE.date()} ~ {END_DATE.date()}")
    print("-" * 50)

    # 2. ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê° ì¢…ëª©ì— ëŒ€í•´ ë°˜ë³µ ì‘ì—…
    for ticker_symbol in TICKER_LIST:
        print(f"-> '{ticker_symbol}'ì˜ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        try:
            ticker = yf.Ticker(ticker_symbol)
            news_list = ticker.news
            
            # news_listê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
            if not news_list:
                print(f"  â„¹ï¸ '{ticker_symbol}': ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # ê° ë‰´ìŠ¤ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
            parsed_count = 0
            for news_item in news_list:
                try:
                    # news_itemì´ Noneì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ìŠ¤í‚µ
                    if not news_item or not isinstance(news_item, dict):
                        continue
                    
                    content = news_item.get('content', {})
                    
                    # contentê°€ Noneì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ìŠ¤í‚µ
                    if not content or not isinstance(content, dict):
                        continue
                    
                    # ë‚ ì§œ íŒŒì‹± (ISO í˜•ì‹)
                    pub_date_str = content.get('pubDate', '')
                    if pub_date_str:
                        pub_date = pd.to_datetime(pub_date_str)
                        # íƒ€ì„ì¡´ì´ ì—†ëŠ” ê²½ìš° UTCë¡œ ì„¤ì •
                        if pub_date.tz is None:
                            pub_date = pub_date.tz_localize('UTC')
                    else:
                        continue  # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                    
                    # provider ì •ë³´ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
                    provider = content.get('provider', {})
                    if not isinstance(provider, dict):
                        provider = {}
                    
                    # clickThroughUrl ì •ë³´ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
                    click_url = content.get('clickThroughUrl', {})
                    if not isinstance(click_url, dict):
                        click_url = {}
                    
                    # í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
                    news_data = {
                        'datetime': pub_date,
                        'ticker': ticker_symbol,
                        'title': content.get('title', 'N/A'),
                        'publisher': provider.get('displayName', 'N/A'),
                        'link': click_url.get('url', 'N/A')
                    }
                    
                    all_news_list.append(news_data)
                    parsed_count += 1
                    
                except Exception as e:
                    print(f"  âš ï¸ '{ticker_symbol}' ë‰´ìŠ¤ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            print(f"  âœ… '{ticker_symbol}': {parsed_count}ê°œ ë‰´ìŠ¤ íŒŒì‹± ì™„ë£Œ")
            time.sleep(1)  # ì„œë²„ì— ë¶€ë‹´ì„ ì£¼ì§€ ì•Šê¸° ìœ„í•´ ì ì‹œ ëŒ€ê¸°

        except Exception as e:
            print(f"âŒ '{ticker_symbol}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if not all_news_list:
        print("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("-" * 50)
    print(f"ì´ {len(all_news_list)}ê°œì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë‚ ì§œ í•„í„°ë§ ë° ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # 3. DataFrameìœ¼ë¡œ ë³€í™˜í•˜ê³  ë‚ ì§œ í•„í„°ë§
    all_news_df = pd.DataFrame(all_news_list)
    
    # ë‚ ì§œ í•„í„°ë§
    mask = (all_news_df['datetime'] >= START_DATE) & (all_news_df['datetime'] <= END_DATE)
    filtered_df = all_news_df.loc[mask]

    if filtered_df.empty:
        print(f"âŒ í•´ë‹¹ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 4. JSONìœ¼ë¡œ ì €ì¥í•˜ê¸° ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    final_df = filtered_df[['datetime', 'ticker', 'title', 'publisher', 'link']].copy()
    
    # ë‚ ì§œ ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
    final_df['datetime'] = final_df['datetime'].dt.tz_convert('UTC').dt.tz_localize(None)
    final_df['datetime'] = final_df['datetime'].dt.strftime('%Y-%m-%d %H:%M')
    
    # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
    final_df = final_df.sort_values(by='datetime', ascending=False)
    
    # JSON êµ¬ì¡° ìƒì„±: {"articles": [ë‰´ìŠ¤ ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸]}
    articles_list = []
    for _, row in final_df.iterrows():
        article = {
            "ë‚ ì§œ": row['datetime'],
            "í‹°ì»¤": row['ticker'],
            "ì œëª©": row['title'],
            "ì–¸ë¡ ì‚¬": row['publisher'],
            "ë§í¬": row['link']
        }
        articles_list.append(article)
    
    # ìµœì¢… JSON êµ¬ì¡°
    json_data = {
        "articles": articles_list,
        "metadata": {
            "total_count": len(articles_list),
            "collection_period": {
                "start": START_DATE.strftime('%Y-%m-%d'),
                "end": END_DATE.strftime('%Y-%m-%d')
            },
            "tickers_covered": len(TICKER_LIST),
            "generated_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
    }

    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” í´ë”(crawling)ì— JSON íŒŒì¼ë¡œ ì €ì¥
    current_dir = os.path.dirname(os.path.abspath(__file__))
    output_path = os.path.join(current_dir, OUTPUT_FILE)

    # JSON íŒŒì¼ ì €ì¥ (í•œê¸€ ê¹¨ì§ ë°©ì§€: ensure_ascii=False, ë“¤ì—¬ì“°ê¸° ì ìš©: indent=2)
    with open(output_path, 'w', encoding='utf-8') as json_file:
        json.dump(json_data, json_file, ensure_ascii=False, indent=2)

    print("-" * 50)
    print(f"âœ… ì´ {len(articles_list)}ê°œì˜ í•„í„°ë§ëœ ë‰´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ JSON íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤!")
    print(f"   -> íŒŒì¼ ìœ„ì¹˜: {output_path}")
    print(f"   -> JSON êµ¬ì¡°:")
    print(f"      ğŸ“ articles: {len(articles_list)}ê°œ ë‰´ìŠ¤ ê°ì²´")
    print(f"      ğŸ“ metadata: ìˆ˜ì§‘ ì •ë³´ ë° í†µê³„")
    
    # JSON êµ¬ì¡° ë¯¸ë¦¬ë³´ê¸°
    print("\nğŸ” JSON êµ¬ì¡° ë¯¸ë¦¬ë³´ê¸°:")
    print("```json")
    print("{")
    print('  "articles": [')
    print('    {')
    print(f'      "ë‚ ì§œ": "{articles_list[0]["ë‚ ì§œ"]}",')
    print(f'      "í‹°ì»¤": "{articles_list[0]["í‹°ì»¤"]}",')
    print(f'      "ì œëª©": "{articles_list[0]["ì œëª©"][:50]}...",')
    print(f'      "ì–¸ë¡ ì‚¬": "{articles_list[0]["ì–¸ë¡ ì‚¬"]}",')
    print(f'      "ë§í¬": "{articles_list[0]["ë§í¬"][:50]}..."')
    print('    },')
    print('    ...')
    print('  ],')
    print('  "metadata": { ... }')
    print('}')
    print("```")

if __name__ == "__main__":
    get_news_for_tickers() 